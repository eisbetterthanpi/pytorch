{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JEPA_text.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "4w5m_JAyK1wW",
        "BLW1TAw6K7s5",
        "75SRBabzK-6P",
        "oEr6soVkqbQU",
        "2gLKjKZej5L_"
      ],
      "authorship_tag": "ABX9TyN49SBwsrLMpSISAQZTA/nY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/JEPA_text.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### setup"
      ],
      "metadata": {
        "id": "4w5m_JAyK1wW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "# import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "import collections\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "!pip install optuna\n",
        "import optuna\n"
      ],
      "metadata": {
        "id": "btQjTpnUd95O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cae10326-73a3-4955-bdc2-b8d18530b77e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.7/dist-packages (2.10.1)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.7/dist-packages (from optuna) (6.6.0)\n",
            "Requirement already satisfied: cliff in /usr/local/lib/python3.7/dist-packages (from optuna) (3.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from optuna) (1.21.6)\n",
            "Requirement already satisfied: cmaes>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from optuna) (0.8.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.4.39)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (21.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from optuna) (4.64.0)\n",
            "Requirement already satisfied: alembic in /usr/local/lib/python3.7/dist-packages (from optuna) (1.8.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from optuna) (3.13)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.7/dist-packages (from optuna) (1.7.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->optuna) (3.0.9)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (4.12.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy>=1.1.0->optuna) (1.1.2)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (1.2.1)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->optuna) (5.9.0)\n",
            "Requirement already satisfied: cmd2>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (2.4.2)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.3.0)\n",
            "Requirement already satisfied: stevedore>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (3.5.0)\n",
            "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (5.9.0)\n",
            "Requirement already satisfied: autopage>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from cliff->optuna) (0.5.1)\n",
            "Requirement already satisfied: wcwidth>=0.1.7 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (4.1.1)\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (22.1.0)\n",
            "Requirement already satisfied: pyperclip>=1.6 in /usr/local/lib/python3.7/dist-packages (from cmd2>=1.0.0->cliff->optuna) (1.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->sqlalchemy>=1.1.0->optuna) (3.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from Mako->alembic->optuna) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### data"
      ],
      "metadata": {
        "id": "RCu-4JfUn-wT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# data = open('input.txt', 'r').read()\n",
        "# data = list(data)\n",
        "\n",
        "# https://edisciplinas.usp.br/pluginfile.php/3403095/mod_resource/content/1/56ViktorFrankl_Mans%20Search.pdf\n",
        "text='''\n",
        "Only slowly could these men be guided back to the commonplace truth that no one has the right to do wrong, not\n",
        "even if wrong has been done to them. We had to strive to\n",
        "lead them back to this truth, or the consequences would\n",
        "have been much worse than the loss of a few thousand stalks\n",
        "of oats. I can still see the prisoner who rolled up his shirt\n",
        "sleeves, thrust his right hand under my nose and shouted,\n",
        "\"May this hand be cut off if I don't stain it with blood\n",
        "on the day when I get home!\" I want to emphasize that the\n",
        "man who said these words was not a bad fellow. He had\n",
        "been the best of comrades in camp and afterwards.\n",
        "Apart from the moral deformity resulting from the sudden release of mental pressure, there were two other\n",
        "fundamental experiences which threatened to damage the\n",
        "character of the liberated prisoner: bitterness and disillusionment when he returned to his former life.\n",
        "Bitterness was caused by a number of things he came up\n",
        "against in his former home town. When, on his return, a\n",
        "man found that in many places he was met only with a\n",
        "shrug of the shoulders and with hackneyed phrases, he\n",
        "tended to become bitter and to ask himself why he had\n",
        "gone through all that he had. When he heard the same\n",
        "phrases nearly everywhereâ€”\"We did not know about it,\"\n",
        "and \"We, too, have suffered,\" then he asked himself, have\n",
        "they really nothing better to say to me?\n",
        "The experience of disillusionment is different. Here it\n",
        "was not one's fellow man (whose superficiality and lack of\n",
        "feeling was so disgusting that one finally felt like creeping\n",
        "into a hole and neither hearing nor seeing human beings\n",
        "any more) but fate itself which seemed so cruel. A man who\n",
        "Experiences in a Concentration Camp 99\n",
        "for years had thought he had reached the absolute limit of\n",
        "all possible suffering now found that suffering has no limits,\n",
        "and that he could suffer still more, and still more intensely.\n",
        "When we spoke about attempts to give a man in camp\n",
        "mental courage, we said that he had to be shown something\n",
        "to look forward to in the future. He had to be reminded\n",
        "that life still waited for him, that a human being waited for\n",
        "his return. But after liberation? There were some men who\n",
        "found that no one awaited them. Woe to him who found\n",
        "that the person whose memory alone had given him courage\n",
        "in camp did not exist any more! Woe to him who, when the\n",
        "day of his dreams finally came, found it so different from all\n",
        "he had longed for! Perhaps he boarded a trolley, traveled\n",
        "out to the home which he had seen for years in his mind,\n",
        "and only in his mind, and pressed the bell, just as he has\n",
        "longed to do in thousands of dreams, only to find that the\n",
        "person who should open the door was not there, and would\n",
        "never be there again.\n",
        "'''\n",
        "\n",
        "# # make dataset\n",
        "# text=text.replace('\\n','')\n",
        "# data=list(text)\n",
        "# # print(data)\n",
        "# # data=sorted([ord(x) for x in set(data)])\n",
        "# dataset=[ord(x)-31 for x in data]\n",
        "# # dataset = map(lambda x:x.strip(\"8\"), lst)\n",
        "# # [f(x) if condition else g(x) for x in sequence]\n",
        "# dataset=[0 if x>91 else x for x in dataset] # 0 unk, 1-91\n",
        "# vocab_size=92\n",
        "# print(dataset)\n",
        "# 32space;A65-Z90;a97-z122\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "class Datasetme(Dataset): #https://www.kaggle.com/code/pinocookie/pytorch-dataset-and-dataloader/notebook\n",
        "    def __init__(self, text, embed_size=4):\n",
        "        super().__init__()\n",
        "        text=text.replace('\\n','')\n",
        "        data=list(text)\n",
        "        dataset=[ord(x)-31 for x in data]\n",
        "        dataset=[0 if x>91 else x for x in dataset] # 0 unk, 1-91\n",
        "        self.vocab_size=vocab_size=92\n",
        "        self.embed_size=embed_size\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = 1\n",
        "        self.embed=nn.Embedding(vocab_size, embed_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)-1\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # return self.dataset[index], self.dataset[index+1]\n",
        "        return self.embed(self.dataset[index]), self.embed(self.dataset[index+1])\n",
        "\n",
        "dataset=Datasetme(text)\n"
      ],
      "metadata": {
        "id": "0Hz09uxCn-Eb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### functions"
      ],
      "metadata": {
        "id": "BLW1TAw6K7s5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def off_diagonal(x):\n",
        "    # print(\"off_diagonal\",x.shape)\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n"
      ],
      "metadata": {
        "id": "QHmNYpcUK95w"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### jepa"
      ],
      "metadata": {
        "id": "75SRBabzK-6P"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6_Xjga__gdeY"
      },
      "outputs": [],
      "source": [
        "\n",
        "class JEPA(nn.Module):\n",
        "    # def __init__(self, xin_channels, dim_sx, dim_sy, dim_z, dim_v, n_actions, space_dims, hidden_dims):\n",
        "    def __init__(self, in_dimx, in_dimy, dim_sx, dim_sy, dim_z, dim_v):\n",
        "    # def __init__(self, vocab_size, dim_sx, dim_sy, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc_x = nn.Sequential(\n",
        "            nn.Embedding(vocab_size, dim_sx),\n",
        "            # nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(in_dimx*embed_size, dim_sx),\n",
        "            )\n",
        "        self.enc_y = nn.Sequential(\n",
        "            nn.Embedding(vocab_size, dim_sy),\n",
        "            # nn.Flatten(start_dim=1),\n",
        "            # nn.Linear(in_dimx*embed_size, dim_sx),\n",
        "            )\n",
        "        self.pred = nn.Sequential(\n",
        "            nn.Linear(dim_sx + dim_z, dim_sy),\n",
        "            nn.ReLU(True),\n",
        "            )\n",
        "        self.exp_x = nn.Sequential(\n",
        "            nn.Linear(dim_sx, dim_v),\n",
        "            nn.ReLU(True),\n",
        "            )\n",
        "        self.exp_y = nn.Sequential(\n",
        "            nn.Linear(dim_sy, dim_v),\n",
        "            nn.ReLU(True),\n",
        "            )    \n",
        "\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y)\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        # # covariance loss\n",
        "        # cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
        "        # cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
        "        # cov_loss = off_diagonal(cov_x).pow_(2).sum().div(self.num_features)\\\n",
        "        #  + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
        "\n",
        "        # loss = (self.args.sim_coeff * repr_loss + self.args.std_coeff * std_loss + self.args.cov_coeff * cov_loss)\n",
        "\n",
        "        batch_size=3\n",
        "        num_features=3\n",
        "        sim_coeff=1\n",
        "        std_coeff=1\n",
        "        cov_coeff=1\n",
        "\n",
        "        # print(\"x.dim()\",x.dim())\n",
        "        if x.dim() == 1:\n",
        "            x = x.view(-1, 1)\n",
        "        \n",
        "        if y.dim() == 1:\n",
        "            y = y.view(-1, 1)\n",
        "        x=x.T\n",
        "        y=y.T\n",
        "        # print(\"x\",x.shape)\n",
        "        cov_x = (x.T @ x) / (batch_size - 1)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        # print(\"cov_x\",cov_x.shape)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features)\n",
        "\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        return loss\n",
        "\n",
        "    # def argm(self, sx, sy):\n",
        "    def argm(self, SX, SY):\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        sampler = optuna.samplers.NSGAIISampler()\n",
        "        # sampler = optuna.samplers.MOTPESampler()\n",
        "        pruner = optuna.pruners.MedianPruner()\n",
        "        batch_size=1\n",
        "        # if sx.dim() == 2: batch_size,_=sx.shape\n",
        "        if SX.dim() == 2: batch_size,_=SX.shape\n",
        "        s=[]\n",
        "        for i in range(batch_size):\n",
        "            sx, sy = SX[i],SY[i]\n",
        "            study = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
        "            # study = optuna.create_study()\n",
        "            def objective(trial):\n",
        "                z = trial.suggest_uniform('z', -1, 1)\n",
        "                # print(\"z trail\",sx,z)\n",
        "                # z=torch.tensor(z).to(device)\n",
        "                z=torch.tensor(z).view(1).to(device)\n",
        "                # print(\"sx, z\",sx.shape, z.shape) #[500, 20] [1]\n",
        "                sxz = torch.cat([sx, z], dim=-1)\n",
        "                sy_ = self.pred(sxz)\n",
        "                mseloss = nn.MSELoss()(sy, sy_)\n",
        "                return mseloss\n",
        "            study.optimize(objective, n_trials=10)\n",
        "            st=study.best_params\n",
        "            # print(\"st\",st['z'])\n",
        "            st=torch.tensor([st['z']])\n",
        "            s.append(st)\n",
        "        return torch.tensor(s)\n",
        "\n",
        "    def loss(self, x, y):\n",
        "        if x.dim()==2: batch_size,_=x.shape\n",
        "        # print(\"loss\",x,x.shape,x.dtype)\n",
        "        sx = self.enc_x(x)\n",
        "        sy = self.enc_y(y)\n",
        "        sx=sx.flatten(start_dim=1)\n",
        "        sy=sy.flatten(start_dim=1)\n",
        "        # print(\"sx, sy\",sx.shape, sy.shape) #10000\n",
        "        z = self.argm(sx, sy).to(device)\n",
        "        # z=np.array(z)\n",
        "        z=torch.tensor(z).view(-1,1)\n",
        "        # print(\"sx, z\",sx.device, z.device) #[500, 20] [1]\n",
        "        sxz = torch.cat([sx, z], dim=-1)\n",
        "        sy_ = self.pred(sxz)\n",
        "        # loss(sy, sy_)\n",
        "        mseloss = nn.MSELoss()(sy, sy_)\n",
        "\n",
        "        vx = self.exp_x(sx)\n",
        "        vy = self.exp_y(sy)\n",
        "        # print(\"vx\",vx.shape) #[40]\n",
        "        vicloss = self.vicreg(vx, vy)\n",
        "        return mseloss + vicloss\n",
        "\n",
        "    def forward(self, sx, a):\n",
        "        # sx = self.enc_x(x)\n",
        "        # sx=sx.flatten()\n",
        "        sxz = torch.cat([sx, a], dim=-1)\n",
        "        sy_ = self.pred(sxz)\n",
        "        return sy_\n",
        "\n",
        "vocab_size=dataset.vocab_size\n",
        "embed_size=dataset.embed_size\n",
        "# embed_size=4\n",
        "in_dimx=embed_size # embedding size\n",
        "in_dimy=embed_size\n",
        "dim_sx=2\n",
        "dim_sy=2\n",
        "dim_z=1\n",
        "dim_v=5\n",
        "\n",
        "model = JEPA(in_dimx, in_dimy, dim_sx, dim_sy, dim_z, dim_v).to(device)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train eval"
      ],
      "metadata": {
        "id": "oEr6soVkqbQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "grad_clip_norm=1\n",
        "lr=1e-4\n",
        "betas=(0.9, 0.95)\n",
        "batch_size=1\n",
        "def train(loader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    pbar = tqdm(enumerate(loader), total = len(loader))\n",
        "    for it, (x, y) in pbar:\n",
        "        print(\"x,y\",x.dtype,y.dtype) #torch.int64\n",
        "        print(\"x,y\",x.shape,y.shape)\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # print(\"x\",x)\n",
        "        # with torch.set_grad_enabled(True):\n",
        "\n",
        "        # logits = model(x)\n",
        "        # # loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "        # loss = loss_fn(logits, y)\n",
        "        loss = model.loss(x,y)\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip_norm)\n",
        "        optimizer.step()\n",
        "        # lr = lr\n",
        "        # pbar.set_description(f\"epoch {epoch + 1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n",
        "        pbar.set_description(f\"epoch {epoch + 1} iter {it}: train loss {loss.item():.5f}\")\n",
        "\n",
        "\n",
        "def eval(loader, model, loss_fn):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    pbar = enumerate(loader)\n",
        "    for it, (x, y) in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        # with torch.set_grad_enabled(False):\n",
        "        with torch.no_grad():\n",
        "            # logits = model(x)\n",
        "            # # loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "            # loss = loss_fn(logits, y)\n",
        "            loss = model.loss(x,y)\n",
        "            losses.append(loss.item())\n",
        "    test_loss = float(np.mean(losses))\n",
        "    logger.info(\"test loss: %f\", test_loss)\n",
        "    return test_loss\n"
      ],
      "metadata": {
        "id": "V_EUHNNBgxuw"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### wwwwwwwwwww"
      ],
      "metadata": {
        "id": "nsKk_OKSqfTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr = lr, betas = betas)\n",
        "\n",
        "def loss_fn(logits, y):\n",
        "    return nn.CrossEntropyLoss()(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "\n"
      ],
      "metadata": {
        "id": "Yu4L88zkjA79"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.dataloader import DataLoader\n",
        "# train_loader = DataLoader(train_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 4)\n",
        "# test_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "loader = DataLoader(dataset, shuffle = False, batch_size = batch_size, num_workers = 0)\n",
        "\n",
        "epochs=1\n",
        "for epoch in range(epochs):\n",
        "    # run_epoch(train_loader)\n",
        "    train(loader, model, loss_fn, optimizer)\n",
        "    if test is not None:\n",
        "        test_loss = eval(loader, model, loss_fn)\n",
        "        print('Test Loss:', test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WNxuQST8jGeu",
        "outputId": "19ac2b4c-44d0-45d8-e177-4612fc0f5de6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/2663 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c5fed77fc1a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# run_epoch(train_loader)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-45-0ceef10895a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mlosses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    650\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    651\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 652\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    653\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    654\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-42-5fe1676f7612>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;31m# return self.dataset[index], self.dataset[index+1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDatasetme\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    158\u001b[0m         return F.embedding(\n\u001b[1;32m    159\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2197\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2198\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2199\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: embedding(): argument 'indices' (position 2) must be Tensor, not int"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### inference"
      ],
      "metadata": {
        "id": "2gLKjKZej5L_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "context = \"This is what \"\n",
        "\n",
        "def encode(char):\n",
        "    x = ord(char)-31\n",
        "    if x>91: x=0\n",
        "    return x\n",
        "def decode(x): return chr(x+31)\n",
        "\n",
        "out=[]\n",
        "for _ in range(20):\n",
        "    a=torch.zeros(1,1).to(device)\n",
        "    x=encode(\"w\")\n",
        "    x=torch.tensor(x).view(1,-1).to(device)\n",
        "    print(x.shape, a.shape)\n",
        "    x = model(x, a)\n",
        "    out.append(x)\n",
        "print(''.join(out))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0H2ER22wNahP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def inference(model, x, max_steps = 512, seq_len=seq_len):\n",
        "    # seq_len = model.seq_len\n",
        "    # seq_len = seq_len\n",
        "    model.eval()\n",
        "    print(\"test\",x)\n",
        "    for n in range(max_steps):\n",
        "        if x.shape[1] <= seq_len:\n",
        "            x_bar = x\n",
        "        else:\n",
        "            x_bar = x[:, -seq_len:]\n",
        "        # print(\"test\",x_bar)\n",
        "        # output = model(x_bar)\n",
        "        a=torch.zeros(1,1)\n",
        "        print(x_bar.shape, a.shape)\n",
        "        output = model(x_bar, a)\n",
        "        # print(\"output\",output)\n",
        "        output = output[:, -1, :]\n",
        "        output = F.softmax(output, dim = -1)\n",
        "        ix = torch.multinomial(output, num_samples = 1)\n",
        "        x = torch.cat((x, ix), dim = 1)\n",
        "    return x\n",
        "\n",
        "context = \"This is what \"\n",
        "#context = 'There are many things about horses that have been discovered in recent'\n",
        "# print([train_dataset.stoi[s] for s in context])\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype = torch.long)[None,...].to(device)\n",
        "y = inference(model, x)[0]\n",
        "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "print(completion)\n",
        "\n"
      ],
      "metadata": {
        "id": "TZTuCdvLjprk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embed_dim = 512\n",
        "\n",
        "Embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "position_embedding = torch.zeros(1, seq_len, embed_dim)\n",
        "lin=nn.Linear(embed_dim * 2, embed_dim)\n",
        "\n",
        "\n",
        "context = \"This is what \"\n",
        "#context = 'There are many things about horses that have been discovered in recent'\n",
        "# print([train_dataset.stoi[s] for s in context])\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype = torch.long)[None,...].to(device)\n",
        "max_steps = 20#512\n",
        "x=x.cpu()\n",
        "# model.eval()\n",
        "print(\"test\",x)\n",
        "for n in range(max_steps):\n",
        "    if x.shape[1] <= seq_len:\n",
        "        x_bar = x\n",
        "    else:\n",
        "        x_bar = x[:, -seq_len:]\n",
        "    # print(\"test\",x_bar)\n",
        "    # output = model(x_bar)\n",
        "    a=torch.zeros(1,1)\n",
        "    print(x_bar.shape, a.shape)\n",
        "    # output = mod(x_bar)\n",
        "\n",
        "    idx=x_bar\n",
        "    batch_size = idx.shape[0] # 1\n",
        "    seq_len = idx.shape[1] # len(contex)+\n",
        "    print(\"Embedding\",Embedding)\n",
        "    embedding = Embedding(idx) # [1, len(contex)+, embed_size]\n",
        "    position_embedding = position_embedding[:, :seq_len, :].repeat(batch_size, 1, 1)\n",
        "    # Concats token and position and embeddings then projects them onto the embedding dimension\n",
        "    x = torch.concat((embedding, position_embedding), dim = -1)\n",
        "    print(\"wp.s\",embedding.shape, position_embedding.shape)\n",
        "    # output=x[0]\n",
        "    x=lin(x)\n",
        "    print(x.shape)\n",
        "    output=x\n",
        "    # # output = mod(x_bar, a)\n",
        "    # print(\"test\",x_bar.shape) # [1, len(contex)+] int to 277+\n",
        "    # output = model(x_bar)\n",
        "    # print(\"output\",output.shape) # [1, len(contex)+, vocab_size=283] float\n",
        "    output = output[:, -1, :] #get logit for last character\n",
        "    output = F.softmax(output, dim = -1) #vocab_size to char\n",
        "    ix = torch.multinomial(output, num_samples = 1)\n",
        "    x = torch.cat((x, ix), dim = 1)\n",
        "\n",
        "# y = inference(model, x)[0]\n"
      ],
      "metadata": {
        "id": "D7JjUZlo8Gst"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
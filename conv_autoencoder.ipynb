{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/conv_autoencoder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## top"
      ],
      "metadata": {
        "id": "kRd8qZZ-GsvZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Wi4ODp-XlZoU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60fba1d8-e866-49c0-fd67-0c337cd1fbfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 39.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.20MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 10.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.82MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "# https://www.geeksforgeeks.org/implementing-an-autoencoder-in-pytorch/\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "test_data = torchvision.datasets.MNIST(root=\"data\", train=False, download=True, transform=transforms.ToTensor(),) #opt no download\n",
        "batch_size = 4 # 512\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, shuffle=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "r0mXVAUnVYX-"
      },
      "outputs": [],
      "source": [
        "# @title torchvision resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "# model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "# model = get_res(256).to(device)\n",
        "# print(model)\n",
        "# input = torch.rand(16,3,64,64)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "# out = model(input)\n",
        "# print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oqycJZ5s3RR",
        "outputId": "3d1287bb-7f30-4e80-fcc1-a0c7d5613575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23296\n",
            "23265\n",
            "torch.Size([4, 32])\n",
            "torch.Size([4, 1, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # self.encoder = torch.nn.Sequential(\n",
        "        #     nn.Linear(28 * 28, 512), nn.ReLU(),\n",
        "        #     nn.Linear(512, 128), nn.ReLU(),\n",
        "        #     nn.Linear(128, 64), nn.ReLU(),\n",
        "        #     nn.Linear(64, 32),  nn.ReLU(), # 32>10 to account for variation of members within the same class\n",
        "        # )\n",
        "\n",
        "        self.encoder = nn.Sequential( # 28 # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0),\n",
        "            nn.Conv2d(1, 16, 3, stride=1, padding=1), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2), # 14\n",
        "            nn.Conv2d(16, 32, 3, stride=1, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), # 7\n",
        "            nn.Conv2d(32, 32, 3, stride=1, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), # 3\n",
        "            nn.Conv2d(32, 32, 3, stride=1, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2), # 1\n",
        "            # nn.Conv2d(32, 32, 3, stride=1, padding=1), # 1\n",
        "            # nn.Conv2d(16, 8, 3, stride=1, padding=1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.AdaptiveAvgPool2d(output_size=(1, 1)),\n",
        "            nn.Flatten(start_dim=1),\n",
        "        )\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Unflatten(-1, (32,1,1)),\n",
        "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=0, output_padding=0), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 32, 3, stride=2, padding=0, output_padding=0), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # self.decoder = nn.Sequential( # 'nearest', 'linear', 'bilinear', 'bicubic', 'trilinear'. # https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html\n",
        "        #     nn.Upsample((3,3)), nn.ConvTranspose2d(32, 32, 3, 1, padding=1), nn.ReLU(),\n",
        "        #     nn.Upsample((7,7)), nn.ConvTranspose2d(32, 32, 3, 1, padding=1), nn.ReLU(),\n",
        "        #     nn.Upsample(scale_factor=2), nn.ConvTranspose2d(32, 16, 3, 1, padding=1), nn.ReLU(),\n",
        "        #     nn.Upsample(scale_factor=2), nn.ConvTranspose2d(16, 1, 3, 1, padding=1), nn.Sigmoid()\n",
        "        # )\n",
        "\n",
        "        # self.decoder = torch.nn.Sequential(\n",
        "        #     nn.Linear(32, 64), nn.ReLU(),\n",
        "        #     nn.Linear(64, 128), nn.ReLU(),\n",
        "        #     nn.Linear(128, 512), nn.ReLU(),\n",
        "        #     nn.Linear(512, 28 * 28), nn.ReLU(),\n",
        "        # )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.encoder(x)\n",
        "    def decode(self, x): return self.decoder(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder().to(device)\n",
        "print(sum(p.numel() for p in model.encoder.parameters() if p.requires_grad))\n",
        "print(sum(p.numel() for p in model.decoder.parameters() if p.requires_grad))\n",
        "\n",
        "# 477920\n",
        "# 23296, 23265\n",
        "\n",
        "input = torch.rand((4,1,28,28), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t46jFUzstGAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "f06be6ba-ae10-4628-c31f-238ff9e9143f",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss:  0.008434731513261795\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'item' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-362f64222b1a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mencoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoded: \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mreconstructed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'item' is not defined"
          ]
        }
      ],
      "source": [
        "# @title train\n",
        "loss_function = torch.nn.MSELoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 1e-1, momentum=0.9)\n",
        "# optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-8)\n",
        "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma=0.7)\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-3\n",
        "\n",
        "\n",
        "def train(model, train_loader, loss_function, optimizer):\n",
        "    outputs = []\n",
        "    losses = []\n",
        "    model.train()\n",
        "    for image, _ in train_loader:\n",
        "        image = image.to(device)#.reshape(-1, 28*28)\n",
        "        reconstructed = model(image)\n",
        "        loss = loss_function(reconstructed, image)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.cpu())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        except: pass\n",
        "    # scheduler.step()\n",
        "    lr=optimizer.param_groups[0][\"lr\"]\n",
        "    # print(lr)\n",
        "    print(\"loss: \",sum(losses[-batch_size:]).item()/batch_size)\n",
        "    outputs.append((epochs, image, reconstructed))\n",
        "\n",
        "# loss:  0.013260149396955967\n",
        "# loss:  0.010282933712005615\n",
        "# loss:  0.009744454175233841\n",
        "# loss:  0.008946227841079235\n",
        "# loss:  0.006832938175648451\n",
        "# loss:  0.007862974889576435\n",
        "# loss:  0.0076667130924761295\n",
        "# loss:  0.005621504969894886\n",
        "# loss:  0.009382324293255806\n",
        "# loss:  0.007828746922314167\n",
        "\n",
        "epochs = 10\n",
        "for epoch in range(epochs):\n",
        "    train(model, train_loader, loss_function, optimizer)\n",
        "    encoded = model.encode(item[0].unsqueeze(0).to(device))\n",
        "    print(\"encoded: \",encoded)\n",
        "    reconstructed = model.decode(encoded.unsqueeze(0))\n",
        "\n",
        "    print(\"reconstructed:\")\n",
        "    # reconstructed = reconstructed.reshape(-1, 28, 28)\n",
        "    # reconstructed = reconstructed.unsqueeze(0)\n",
        "    plt.imshow(reconstructed.detach().cpu().squeeze())\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 915
        },
        "id": "arU-tUdktPc_",
        "outputId": "f8046ef0-8f78-4748-e175-8f4e87619c6c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "original:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAGylJREFUeJzt3X9w1PW97/HXAskKmGwMIdlEAgb8QRVIpxTSXJTGkkuIZxhQzh1QbwccL1xpcITU6omjIG3npsU56NFD8Z8W6hkBy7kCR04vHY0mjG2ChyiHy7VmSCYWGJJQcw/ZECQE8rl/cF1dScDvspt3sjwfM98Zsvv95Pv26+qTb7L5xueccwIAYIANsx4AAHB9IkAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMDECOsBvq63t1cnT55USkqKfD6f9TgAAI+cc+rs7FROTo6GDev/OmfQBejkyZPKzc21HgMAcI2OHz+ucePG9fv8oAtQSkqKJOlu3acRSjKeBgDg1QX16H39Pvz/8/7ELUCbNm3SCy+8oNbWVuXn5+uVV17RzJkzr7ruiy+7jVCSRvgIEAAMOf//DqNX+zZKXN6E8MYbb6i8vFzr1q3Thx9+qPz8fJWUlOjUqVPxOBwAYAiKS4A2btyo5cuX65FHHtGdd96pV199VaNGjdJvfvObeBwOADAExTxA58+fV319vYqLi788yLBhKi4uVm1t7WX7d3d3KxQKRWwAgMQX8wB99tlnunjxorKysiIez8rKUmtr62X7V1ZWKhAIhDfeAQcA1wfzH0StqKhQR0dHeDt+/Lj1SACAARDzd8FlZGRo+PDhamtri3i8ra1NwWDwsv39fr/8fn+sxwAADHIxvwJKTk7W9OnTVVVVFX6st7dXVVVVKiwsjPXhAABDVFx+Dqi8vFxLly7Vd7/7Xc2cOVMvvfSSurq69Mgjj8TjcACAISguAVq8eLH++te/au3atWptbdW3v/1t7du377I3JgAArl8+55yzHuKrQqGQAoGAirSAOyEAwBB0wfWoWnvU0dGh1NTUfvczfxccAOD6RIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMQ8QM8//7x8Pl/ENnny5FgfBgAwxI2Ixye966679M4773x5kBFxOQwAYAiLSxlGjBihYDAYj08NAEgQcfke0NGjR5WTk6OJEyfq4Ycf1rFjx/rdt7u7W6FQKGIDACS+mAeooKBAW7du1b59+7R582Y1NzfrnnvuUWdnZ5/7V1ZWKhAIhLfc3NxYjwQAGIR8zjkXzwOcPn1aEyZM0MaNG/Xoo49e9nx3d7e6u7vDH4dCIeXm5qpICzTClxTP0QAAcXDB9ahae9TR0aHU1NR+94v7uwPS0tJ0++23q7Gxsc/n/X6//H5/vMcAAAwycf85oDNnzqipqUnZ2dnxPhQAYAiJeYCefPJJ1dTU6NNPP9Wf/vQn3X///Ro+fLgefPDBWB8KADCExfxLcCdOnNCDDz6o9vZ2jR07Vnfffbfq6uo0duzYWB8KADCExTxAO3bsiPWnBAAkIO4FBwAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYiPsvpMPAal9e6HnN+B/2/csCr+aTU1me15zv9v5bbm/e7n3NqBNnPK+RpN5DH0e1DoB3XAEBAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABHfDTjBP/WSb5zWLRv9HdAebFN0yz4q8L/n0wtmoDvUPf703qnUYOB+cmuB5zei/D0R1rBFV9VGtwzfDFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkSaYl59Z4nnN2mnR/T3kpj87z2v+41s+z2uSp532vGbDlDc9r5GkF7MPeF7zr2dv9Lzmb0ad8bxmIH3uzntec6B7tOc1RTf0eF6jKP4d3br4v3s/jqTbq6Jahm+IKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3I00wo//Z+40aR/9zHAbpR+oAHeeVYFFU634+6xbPa1JrGj2v2VB0q+c1A2nE572e14w+3OJ5zZj9/9PzmqnJSZ7XjPrU+xrEH1dAAAATBAgAYMJzgPbv36/58+crJydHPp9Pu3fvjnjeOae1a9cqOztbI0eOVHFxsY4ePRqreQEACcJzgLq6upSfn69Nmzb1+fyGDRv08ssv69VXX9WBAwc0evRolZSU6Ny5c9c8LAAgcXh+E0JpaalKS0v7fM45p5deeknPPvusFixYIEl67bXXlJWVpd27d2vJEu+/rRMAkJhi+j2g5uZmtba2qri4OPxYIBBQQUGBamtr+1zT3d2tUCgUsQEAEl9MA9Ta2ipJysrKing8Kysr/NzXVVZWKhAIhLfc3NxYjgQAGKTM3wVXUVGhjo6O8Hb8+HHrkQAAAyCmAQoGg5Kktra2iMfb2trCz32d3+9XampqxAYASHwxDVBeXp6CwaCqqqrCj4VCIR04cECFhYWxPBQAYIjz/C64M2fOqLHxy1uPNDc369ChQ0pPT9f48eO1evVq/fznP9dtt92mvLw8Pffcc8rJydHChQtjOTcAYIjzHKCDBw/q3nvvDX9cXl4uSVq6dKm2bt2qp556Sl1dXVqxYoVOnz6tu+++W/v27dMNN9wQu6kBAEOezznnrIf4qlAopEAgoCIt0AgfNxAEhor2/+b9y+y16//R85qN/3ey5zX7507yvEaSLrT0/e5dXNkF16Nq7VFHR8cVv69v/i44AMD1iQABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACY8/zoGAIlvxIRcz2v+8Rnvd7ZO8g33vGbnPxR7XjOmpdbzGsQfV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRgrgMp+sudnzmhl+n+c1/+f8557XpH981vMaDE5cAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJrgZKZDAuv9mRlTrPvzbF6NY5fe8YuUTT3heM/JPH3heg8GJKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwUS2LHS6P6OeaPP+41FH2z+z57XjNr3757XOM8rMFhxBQQAMEGAAAAmPAdo//79mj9/vnJycuTz+bR79+6I55ctWyafzxexzZs3L1bzAgAShOcAdXV1KT8/X5s2bep3n3nz5qmlpSW8bd++/ZqGBAAkHs9vQigtLVVpaekV9/H7/QoGg1EPBQBIfHH5HlB1dbUyMzN1xx13aOXKlWpvb+933+7uboVCoYgNAJD4Yh6gefPm6bXXXlNVVZV++ctfqqamRqWlpbp48WKf+1dWVioQCIS33NzcWI8EABiEYv5zQEuWLAn/eerUqZo2bZomTZqk6upqzZkz57L9KyoqVF5eHv44FAoRIQC4DsT9bdgTJ05URkaGGhsb+3ze7/crNTU1YgMAJL64B+jEiRNqb29XdnZ2vA8FABhCPH8J7syZMxFXM83NzTp06JDS09OVnp6u9evXa9GiRQoGg2pqatJTTz2lW2+9VSUlJTEdHAAwtHkO0MGDB3XvvfeGP/7i+zdLly7V5s2bdfjwYf32t7/V6dOnlZOTo7lz5+pnP/uZ/H7v95YCACQuzwEqKiqSc/3fDvAPf/jDNQ0EoG/DUlI8r/nhPe9HdaxQ7znPa079j4me1/i7/83zGiQO7gUHADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEzH/ldwA4uPo83d5XrM341dRHWvB0UWe1/h/z52t4Q1XQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GChjo+K/f87zm8OKXPa9putDjeY0knfnlOM9r/GqJ6li4fnEFBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCY4GakwDUacXOO5zWrn3vD8xq/z/t/rkv+/Yee10jS2P/1b1GtA7zgCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMMHNSIGv8I3w/p9E/t4Tntf8lxvbPa95vTPT85qs56L7O2ZvVKsAb7gCAgCYIEAAABOeAlRZWakZM2YoJSVFmZmZWrhwoRoaGiL2OXfunMrKyjRmzBjdeOONWrRokdra2mI6NABg6PMUoJqaGpWVlamurk5vv/22enp6NHfuXHV1dYX3WbNmjd566y3t3LlTNTU1OnnypB544IGYDw4AGNo8fcd13759ER9v3bpVmZmZqq+v1+zZs9XR0aFf//rX2rZtm37wgx9IkrZs2aJvfetbqqur0/e+973YTQ4AGNKu6XtAHR0dkqT09HRJUn19vXp6elRcXBzeZ/LkyRo/frxqa2v7/Bzd3d0KhUIRGwAg8UUdoN7eXq1evVqzZs3SlClTJEmtra1KTk5WWlpaxL5ZWVlqbW3t8/NUVlYqEAiEt9zc3GhHAgAMIVEHqKysTEeOHNGOHTuuaYCKigp1dHSEt+PHj1/T5wMADA1R/SDqqlWrtHfvXu3fv1/jxo0LPx4MBnX+/HmdPn064iqora1NwWCwz8/l9/vl9/ujGQMAMIR5ugJyzmnVqlXatWuX3n33XeXl5UU8P336dCUlJamqqir8WENDg44dO6bCwsLYTAwASAieroDKysq0bds27dmzRykpKeHv6wQCAY0cOVKBQECPPvqoysvLlZ6ertTUVD3++OMqLCzkHXAAgAieArR582ZJUlFRUcTjW7Zs0bJlyyRJL774ooYNG6ZFixapu7tbJSUl+tWvfhWTYQEAicPnnHPWQ3xVKBRSIBBQkRZohC/JehxcZ3zT7/K85l//5Z/iMMnl/lNFmec1aa/1/eMPQDxdcD2q1h51dHQoNTW13/24FxwAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMRPUbUYHBbvidt0e1bsWOPTGepG93/sb7na1v+ae6OEwC2OEKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IkZA++dFNUa2bPyoU40n6Nq76vPdFzsV+EMAQV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRopB79z8mZ7XVM3/+yiPNirKdQC84goIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADDBzUgx6J2cNdzzmvEjBu6moq93ZnpekxQ673mN87wCGNy4AgIAmCBAAAATngJUWVmpGTNmKCUlRZmZmVq4cKEaGhoi9ikqKpLP54vYHnvssZgODQAY+jwFqKamRmVlZaqrq9Pbb7+tnp4ezZ07V11dXRH7LV++XC0tLeFtw4YNMR0aADD0eXoTwr59+yI+3rp1qzIzM1VfX6/Zs2eHHx81apSCwWBsJgQAJKRr+h5QR0eHJCk9PT3i8ddff10ZGRmaMmWKKioqdPbs2X4/R3d3t0KhUMQGAEh8Ub8Nu7e3V6tXr9asWbM0ZcqU8OMPPfSQJkyYoJycHB0+fFhPP/20Ghoa9Oabb/b5eSorK7V+/fpoxwAADFFRB6isrExHjhzR+++/H/H4ihUrwn+eOnWqsrOzNWfOHDU1NWnSpEmXfZ6KigqVl5eHPw6FQsrNzY12LADAEBFVgFatWqW9e/dq//79Gjdu3BX3LSgokCQ1Njb2GSC/3y+/3x/NGACAIcxTgJxzevzxx7Vr1y5VV1crLy/vqmsOHTokScrOzo5qQABAYvIUoLKyMm3btk179uxRSkqKWltbJUmBQEAjR45UU1OTtm3bpvvuu09jxozR4cOHtWbNGs2ePVvTpk2Lyz8AAGBo8hSgzZs3S7r0w6ZftWXLFi1btkzJycl655139NJLL6mrq0u5ublatGiRnn322ZgNDABIDJ6/BHclubm5qqmpuaaBAADXB+6GDXxFZfudntfUltzieY1r+d+e1wCJhpuRAgBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmuBkpBr2Jf1frec19f/edOEzSn9YBPBaQOLgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYGLQ3QvOOSdJuqAeyRkPAwDw7IJ6JH35//P+DLoAdXZ2SpLe1++NJwEAXIvOzk4FAoF+n/e5qyVqgPX29urkyZNKSUmRz+eLeC4UCik3N1fHjx9Xamqq0YT2OA+XcB4u4Txcwnm4ZDCcB+ecOjs7lZOTo2HD+v9Oz6C7Aho2bJjGjRt3xX1SU1Ov6xfYFzgPl3AeLuE8XMJ5uMT6PFzpyucLvAkBAGCCAAEATAypAPn9fq1bt05+v996FFOch0s4D5dwHi7hPFwylM7DoHsTAgDg+jCkroAAAImDAAEATBAgAIAJAgQAMDFkArRp0ybdcsstuuGGG1RQUKAPPvjAeqQB9/zzz8vn80VskydPth4r7vbv36/58+crJydHPp9Pu3fvjnjeOae1a9cqOztbI0eOVHFxsY4ePWozbBxd7TwsW7bsstfHvHnzbIaNk8rKSs2YMUMpKSnKzMzUwoUL1dDQELHPuXPnVFZWpjFjxujGG2/UokWL1NbWZjRxfHyT81BUVHTZ6+Gxxx4zmrhvQyJAb7zxhsrLy7Vu3Tp9+OGHys/PV0lJiU6dOmU92oC766671NLSEt7ef/9965HirqurS/n5+dq0aVOfz2/YsEEvv/yyXn31VR04cECjR49WSUmJzp07N8CTxtfVzoMkzZs3L+L1sX379gGcMP5qampUVlamuro6vf322+rp6dHcuXPV1dUV3mfNmjV66623tHPnTtXU1OjkyZN64IEHDKeOvW9yHiRp+fLlEa+HDRs2GE3cDzcEzJw505WVlYU/vnjxosvJyXGVlZWGUw28devWufz8fOsxTElyu3btCn/c29vrgsGge+GFF8KPnT592vn9frd9+3aDCQfG18+Dc84tXbrULViwwGQeK6dOnXKSXE1NjXPu0r/7pKQkt3PnzvA+f/7zn50kV1tbazVm3H39PDjn3Pe//333xBNP2A31DQz6K6Dz58+rvr5excXF4ceGDRum4uJi1dbWGk5m4+jRo8rJydHEiRP18MMP69ixY9YjmWpublZra2vE6yMQCKigoOC6fH1UV1crMzNTd9xxh1auXKn29nbrkeKqo6NDkpSeni5Jqq+vV09PT8TrYfLkyRo/fnxCvx6+fh6+8PrrrysjI0NTpkxRRUWFzp49azFevwbdzUi/7rPPPtPFixeVlZUV8XhWVpY++eQTo6lsFBQUaOvWrbrjjjvU0tKi9evX65577tGRI0eUkpJiPZ6J1tZWSerz9fHFc9eLefPm6YEHHlBeXp6ampr0zDPPqLS0VLW1tRo+fLj1eDHX29ur1atXa9asWZoyZYqkS6+H5ORkpaWlReybyK+Hvs6DJD300EOaMGGCcnJydPjwYT399NNqaGjQm2++aThtpEEfIHyptLQ0/Odp06apoKBAEyZM0O9+9zs9+uijhpNhMFiyZEn4z1OnTtW0adM0adIkVVdXa86cOYaTxUdZWZmOHDlyXXwf9Er6Ow8rVqwI/3nq1KnKzs7WnDlz1NTUpEmTJg30mH0a9F+Cy8jI0PDhwy97F0tbW5uCwaDRVINDWlqabr/9djU2NlqPYuaL1wCvj8tNnDhRGRkZCfn6WLVqlfbu3av33nsv4te3BINBnT9/XqdPn47YP1FfD/2dh74UFBRI0qB6PQz6ACUnJ2v69OmqqqoKP9bb26uqqioVFhYaTmbvzJkzampqUnZ2tvUoZvLy8hQMBiNeH6FQSAcOHLjuXx8nTpxQe3t7Qr0+nHNatWqVdu3apXfffVd5eXkRz0+fPl1JSUkRr4eGhgYdO3YsoV4PVzsPfTl06JAkDa7Xg/W7IL6JHTt2OL/f77Zu3eo+/vhjt2LFCpeWluZaW1utRxtQP/7xj111dbVrbm52f/zjH11xcbHLyMhwp06dsh4trjo7O91HH33kPvroIyfJbdy40X300UfuL3/5i3POuV/84hcuLS3N7dmzxx0+fNgtWLDA5eXluc8//9x48ti60nno7Ox0Tz75pKutrXXNzc3unXfecd/5znfcbbfd5s6dO2c9esysXLnSBQIBV11d7VpaWsLb2bNnw/s89thjbvz48e7dd991Bw8edIWFha6wsNBw6ti72nlobGx0P/3pT93Bgwddc3Oz27Nnj5s4caKbPXu28eSRhkSAnHPulVdecePHj3fJyclu5syZrq6uznqkAbd48WKXnZ3tkpOT3c033+wWL17sGhsbrceKu/fee89JumxbunSpc+7SW7Gfe+45l5WV5fx+v5szZ45raGiwHToOrnQezp496+bOnevGjh3rkpKS3IQJE9zy5csT7i9pff3zS3JbtmwJ7/P555+7H/3oR+6mm25yo0aNcvfff79raWmxGzoOrnYejh075mbPnu3S09Od3+93t956q/vJT37iOjo6bAf/Gn4dAwDAxKD/HhAAIDERIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACb+H8dQZycw7KffAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "encoded:  torch.Size([1, 64, 7, 7])\n",
            "reconstructed:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title evaluate\n",
        "\n",
        "dataiter = iter(test_data)\n",
        "item, labels = next(dataiter) # images, labels\n",
        "print(\"original:\")\n",
        "plt.imshow(item.cpu()[0])\n",
        "plt.show()\n",
        "\n",
        "model.eval()\n",
        "encoded = model.encode(item.unsqueeze(0).to(device))\n",
        "# print(\"encoded: \",encoded.shape)\n",
        "reconstructed = model.decode(encoded)\n",
        "\n",
        "print(\"reconstructed:\")\n",
        "plt.imshow(reconstructed.detach().cpu().squeeze())\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIiOf4BeOCC4"
      },
      "outputs": [],
      "source": [
        "\n",
        "name='agent_convt.pth'\n",
        "# name='agent_upsample.pth'\n",
        "folder = '/content/'\n",
        "torch.save(model.state_dict(), folder+name)\n",
        "# model.load_state_dict(torch.load(folder+name), strict=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "2Nd-sGe6Ku4S",
        "outputId": "08a1d88c-e06b-43ba-f69c-5e6b9a696281"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbobdole\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250227_232927-j53ams9r</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/bobdole/lfm/runs/j53ams9r' target=\"_blank\">ancient-totem-40</a></strong> to <a href='https://wandb.ai/bobdole/lfm' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/bobdole/lfm' target=\"_blank\">https://wandb.ai/bobdole/lfm</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/bobdole/lfm/runs/j53ams9r' target=\"_blank\">https://wandb.ai/bobdole/lfm/runs/j53ams9r</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title wandb\n",
        "!pip install -q wandb\n",
        "import wandb # https://docs.wandb.ai/quickstart\n",
        "wandb.login(key='487a2109e55dce4e13fc70681781de9f50f27be7')\n",
        "try: run.finish()\n",
        "except NameError: pass\n",
        "run = wandb.init(project=\"conv_ae\", config={\"model\": \"res18\",})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShHQ_ynlwoyJ",
        "outputId": "b9363fb2-0a90-42e7-aaa4-257c846d97a9",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# @title save/load\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "folder='/content/drive/MyDrive/jepa/'\n",
        "import pickle\n",
        "\n",
        "# torch.save(model.state_dict(), folder+name)\n",
        "# model.load_state_dict(torch.load(folder+name, map_location=device), strict=False)\n",
        "# torch.save(model.state_dict(), '/content/'+name)\n",
        "# model.load_state_dict(torch.load('/content/'+name, map_location=device), strict=False)\n",
        "\n",
        "# name='agent.pth'\n",
        "# print(folder+name)\n",
        "# torch.load(folder+name, map_location='o')\n",
        "# with open(folder+'buffer_rand512.pkl', 'wb') as f: pickle.dump((buffer), f)\n",
        "# with open(folder+'buffer512down.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "with open(folder+'buffer512.pkl', 'rb') as f: buffer = pickle.load(f)\n",
        "# https://drive.google.com/file/d/1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY/view?usp=drive_link\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## now"
      ],
      "metadata": {
        "id": "DHVOjDdAGqfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title gdown\n",
        "import pickle\n",
        "!gdown 1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY -O buffer512.pkl # S\n",
        "with open('buffer512.pkl', 'rb') as f: buffer = pickle.load(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BmGrmjAcJb-2",
        "outputId": "a06dae86-ccd1-4599-ac92-a898d80ef525"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY\n",
            "From (redirected): https://drive.google.com/uc?id=1fYC7rJswDFpLeyywD56bu9ZjCQEyzRvY&confirm=t&uuid=f813beb9-71a0-4c00-b789-357482caded8\n",
            "To: /content/buffer512.pkl\n",
            "100% 706M/706M [00:08<00:00, 85.3MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "9UKkkuorG_b9",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title buffer dataloader\n",
        "# RNNs https://colab.research.google.com/drive/16DZRFsBEPMTHnjDED1xlxBDZpCmp5XGR#scrollTo=IV5HmCFv_ITo\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision.transforms as transforms\n",
        "# import faiss\n",
        "import random\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "class BufferDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, buffer, seq_len):\n",
        "        self.data = [step for episode in buffer for step in episode] # 0.00053\n",
        "        self.seq_len = seq_len\n",
        "        self.transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        state, action, reward = self.data[idx]\n",
        "        state = self.transform(state)\n",
        "        return state\n",
        "\n",
        "    def add(self, episode):\n",
        "        self.data.append(episode)\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "def imshow(img):\n",
        "    # img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.figure(figsize=(3, 3))\n",
        "    # print(npimg.shape) # (3, 64, 64)\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "seq_len = 50 # 50\n",
        "train_data = BufferDataset(buffer, seq_len) # one line of poem is roughly 50 characters\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 128 #512\n",
        "train_loader = DataLoader(train_data, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2, drop_last=True) # num_workers = 4\n",
        "\n",
        "# train_data.data = train_data.data + episode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYgDCUJtHSc1",
        "outputId": "0c19dd71-133f-41b4-ecf6-591f51e20084"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 168MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([16, 512])\n",
            "11176512\n"
          ]
        }
      ],
      "source": [
        "# @title resnet\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models # https://pytorch.org/vision/0.12/models.html#id10\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def get_res(dim_embd):\n",
        "    model = models.resnet18(weights='DEFAULT') # 18 34 50 101 152\n",
        "    # model = models.resnet101(weights='DEFAULT') # 18 34 50 101 152\n",
        "    num_ftrs = model.fc.in_features # 1000\n",
        "    # model.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "    # model.layer3 = nn.Sequential()\n",
        "    # model.layer4 = nn.Sequential()\n",
        "    model.fc = nn.Sequential( # og\n",
        "        # nn.Linear(num_ftrs, dim_embd, bias=None),\n",
        "        # nn.Linear(512, dim_embd, bias=None),\n",
        "        # nn.Softmax(dim=1),\n",
        "        )\n",
        "    return model\n",
        "\n",
        "model = get_res(256).to(device)\n",
        "# print(model)\n",
        "input = torch.rand((16,3,64,64),device=device)\n",
        "# input = torch.rand(16,1,256,256)\n",
        "out = model(input)\n",
        "print(out.shape)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "\n",
        "# res18/34 11,176,512/21,284,672 lyr4 64,64->512\n",
        "# res18/34 2,782,784/ 8,170,304 nolyr4 64,64->256\n",
        "# res18/34 683,072/ 1,347,904 nolyr34 64,64->128\n",
        "# res50 lyr4 23508032 64,64->2048\n",
        "# res50 nolyr4 8543296 64,64->1024\n",
        "# res50 nolyr34 1444928 64,64->512\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bNh_1XBHHMQI",
        "outputId": "7ecde56a-e3dd-44a6-c2e4-06b4c0e7a1d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11812867\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title conv deconv\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Deconv(torch.nn.Module):\n",
        "    def __init__(self, d_model):\n",
        "        super().__init__()\n",
        "        # d_model = 32\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(d_model, d_model, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_model, d_model, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_model, d_model, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            nn.ConvTranspose2d(d_model, d_model, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            # nn.ConvTranspose2d(d_model, d_model, 3, stride=2, padding=1, output_padding=1), nn.ReLU(),\n",
        "            # nn.ConvTranspose2d(d_model, 3, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid()\n",
        "            nn.ConvTranspose2d(d_model, 1, 3, stride=2, padding=1, output_padding=1), nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential( # 'nearest', 'linear', 'bilinear', 'bicubic', 'trilinear'. # https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_model, d_model, 3, 1, padding=1), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_model, d_model, 3, 1, padding=1), nn.ReLU(),\n",
        "            # nn.Upsample((7,7)), nn.ConvTranspose2d(32, 32, 3, 1, padding=1), nn.ReLU(),\n",
        "            # nn.ConvTranspose2d(d_model, d_model, 3, 1, padding=1), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_model, d_model, 3, 1, padding=1), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_model, d_model, 3, 1, padding=1), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_model, d_model, 3, 1, padding=1), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_model, 3, 3, 1, padding=1), nn.Sigmoid()\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        x = self.decoder(x.unsqueeze(-1).unsqueeze(-1))\n",
        "        return x\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "conv = Deconv(512).to(device)\n",
        "print(sum(p.numel() for p in conv.parameters() if p.requires_grad)) # 19683\n",
        "input = torch.rand((4,512), device=device)\n",
        "out = conv(input)\n",
        "print(out.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-_r1P15L9Um",
        "outputId": "4874ca42-2beb-45cf-9111-20ea7bce5cf8",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1278976\n",
            "1278979\n",
            "torch.Size([4, 256])\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # self.enc = get_res(d_model)\n",
        "        # # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024]\n",
        "        # d_list=[32, 64, 128, 256, 512, 256]\n",
        "        d_list=[32, 64, 128, 256, 256, 256]\n",
        "        # d_list=[128, 256, 512, 1024]\n",
        "        # d_list=[64, 128, 256, 512, 1024, 2048]\n",
        "        # r_list=[(360,640), (240,426), (144,256)] # https://en.wikipedia.org/wiki/Low-definition_television\n",
        "        self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), nn.MaxPool2d(kernel_size=2, stride=2), # SiLU ReLU\n",
        "            # nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # good\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 3, 2, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Conv2d(d_list[3], d_list[4], 3, 2, 1), nn.BatchNorm2d(d_list[4]), nn.ReLU(), #nn.Dropout(),\n",
        "            # nn.Conv2d(d_list[4], d_list[5], 3, 2, 1), nn.ReLU(),\n",
        "\n",
        "\n",
        "            # nn.Conv2d(3, d_list[0], 7, 1, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 1, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 1, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 1, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[3], d_list[3], 3, 1, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[3], d_list[3], 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # nn.Conv2d(3, d_list[0], 7, 1, 3), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 1, 2), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[1], d_list[2], 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[2], d_list[3], 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[3], d_list[3], 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            # nn.Conv2d(d_list[3], d_list[3], 3, 1, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "\n",
        "            # nn.AdaptiveMaxPool2d(1), # AdaptiveAvgPool2d AdaptiveMaxPool2d\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(4*d_list[4],d_list[5]), nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.deconv = nn.Sequential( # 'nearest', 'linear', 'bilinear', 'bicubic', 'trilinear'. # https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[5], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1), nn.Sigmoid(),\n",
        "\n",
        "            nn.Linear(d_list[5],4*d_list[4]), nn.ReLU(),\n",
        "            nn.Unflatten(-1, (d_list[4],2,2)),\n",
        "            # nn.Unflatten(-1, (d_list[5],1,1)),\n",
        "            # good\n",
        "            # nn.ConvTranspose2d(d_list[5], d_list[4], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[4]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[4], d_list[3], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[3]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[2]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "\n",
        "\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[3], d_list[3], 3, 1, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[3], d_list[3], 3, 1, 1), nn.BatchNorm2d(d_list[3]), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[3], d_list[2], 3, 1, 1), nn.BatchNorm2d(d_list[2]), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[2], d_list[1], 3, 1, 1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], d_list[0], 5, 1, 2), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[3], d_list[3], 3, 1, 1), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[3], d_list[3], 3, 1, 1), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[3], d_list[2], 3, 1, 1), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[2], d_list[1], 3, 1, 1), nn.ReLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], d_list[0], 5, 1, 2), nn.ReLU(),\n",
        "\n",
        "            # nn.Upsample((16,16))\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[0], 3, 7, 1, 3), nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"fwd1\",x.shape)\n",
        "        x = self.encode(x)\n",
        "        # print(\"fwd2\",x.shape)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x)#.squeeze()\n",
        "    def decode(self, x):\n",
        "        # return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "        # x= self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "        x= self.deconv(x)\n",
        "        # x = x / 2 + 0.5  # unnormalize\n",
        "        return x\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model = autoencoder(256).to(device)\n",
        "# model = autoencoder(1024).to(device)\n",
        "model = autoencoder().to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "162e2b85-8561-423a-f8af-36c3a318ad26",
        "id": "NAHP-MSY62ZF",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12583936\n",
            "12595200\n",
            "torch.Size([4, 1024])\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ],
      "source": [
        "# @title lin autoencoder\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        d_list=[32, 64, 128, 256, 512, 1024]\n",
        "        # d_list=[32, 64, 128, 256, 256, 256]\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(64*64*3,d_list[5]), nn.ReLU(),\n",
        "        )\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.Linear(d_list[5],64*64*3),\n",
        "            nn.Unflatten(-1, (3,64,64)),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"fwd1\",x.shape)\n",
        "        x = self.encode(x)\n",
        "        # print(\"fwd2\",x.shape)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x)#.squeeze()\n",
        "    def decode(self, x):\n",
        "        x= self.deconv(x)\n",
        "        return x\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model = autoencoder(256).to(device)\n",
        "# model = autoencoder(1024).to(device)\n",
        "model = autoencoder().to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title autoencoder dreamer\n",
        "\n",
        "# https://github.com/abhayraw1/planet-torch/blob/master/rssm_model.py\n",
        "# https://github.com/cross32768/PlaNet_PyTorch/blob/master/model.py\n",
        "# https://github.com/abhayraw1/planet-torch/blob/master/rssm_model.py\n",
        "# https://github.com/NM512/dreamerv3-torch/blob/main/networks.py#L448\n",
        "\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # self.enc = get_res(d_model)\n",
        "        # # self.enc.conv1 = nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1, bias=False)\n",
        "        # self.enc.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        d_list=[32, 64, 128, 1024]\n",
        "        self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), nn.MaxPool2d(kernel_size=2, stride=2), # SiLU ReLU\n",
        "            nn.Conv2d(3, d_list[0], 4, 2, 0), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 4, 2), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 4, 2), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Conv2d(d_list[2], d_list[3], 4, 2), nn.ReLU(), #nn.Dropout(),\n",
        "            # nn.AdaptiveMaxPool2d(1), # AdaptiveAvgPool2d AdaptiveMaxPool2d\n",
        "            nn.Flatten(start_dim=1),\n",
        "            nn.Linear(4*1024,1024), nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.deconv = nn.Sequential( # 'nearest', 'linear', 'bilinear', 'bicubic', 'trilinear'. # https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html\n",
        "            # nn.Upsample(scale_factor=2),\n",
        "            nn.Linear(1024,4*1024), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.Unflatten(-1, (1024,2,2)),\n",
        "            nn.ConvTranspose2d(d_list[3], d_list[2], 5, 2, 1, output_padding=1), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[2], d_list[1], 5, 2, 1, output_padding=1), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[1], d_list[0], 6, 2, 1, output_padding=1), nn.ReLU(), #nn.Dropout(),\n",
        "            nn.ConvTranspose2d(d_list[0], 3, 6, 2, 1, output_padding=0),# nn.Sigmoid(),\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"fwd1\",x.shape)\n",
        "        x = self.encode(x)\n",
        "        # print(\"fwd2\",x.shape)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x)#.squeeze()\n",
        "    # def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# model = autoencoder(256).to(device)\n",
        "# model = autoencoder(1024).to(device)\n",
        "model = autoencoder().to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k45F0_Fj8xoz",
        "outputId": "4fe91a14-0ec8-47c4-b611-bfd63b2224f1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6459104\n",
            "7757411\n",
            "torch.Size([4, 1024])\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "a3gZpScIPrPw"
      },
      "outputs": [],
      "source": [
        "# @title jepa\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# from torch.optim.swa_utils import AveragedModel, get_ema_multi_avg_fn, update_bn # https://pytorch.org/docs/stable/optim.html#putting-it-all-together-ema\n",
        "\n",
        "def off_diagonal(x):\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    # def __init__(self, in_dim, d_model, dim_a, dim_z, dim_v):\n",
        "    def __init__(self, d_model, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        # d_list=[32, 64, 128, 256, 512, 1024]\n",
        "        d_list=[32, 64, d_model]\n",
        "        self.enc = nn.Sequential(\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.AdaptiveMaxPool2d(1), nn.Flatten(start_dim=1),\n",
        "        )\n",
        "        self.deconv = nn.Sequential(\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1), nn.Sigmoid(),\n",
        "        )\n",
        "        self.exp = nn.Sequential(\n",
        "            nn.Linear(d_model, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v), nn.ReLU(),\n",
        "            nn.Linear(dim_v, dim_v),# nn.ReLU(),\n",
        "            )\n",
        "        self.d_model = d_model\n",
        "        # self.dim_z = dim_z\n",
        "        # self.sim_coeff=10.0 # 25.0 # λ\n",
        "        self.std_coeff=10.0 # 25.0 # µ\n",
        "        self.cov_coeff=1.0 # 1.0 # ν\n",
        "        # self.z=torch.zeros((1,dim_z),device=device)\n",
        "        # self.enc_ema = AveragedModel(self.enc, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "        # self.exp_ema = AveragedModel(self.exp, multi_avg_fn=get_ema_multi_avg_fn(0.999))\n",
        "\n",
        "    def v_creg(self, x): # vx [batch_size, d_model]\n",
        "        x = x - x.mean(dim=0)\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001) #ϵ=0.0001\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2\n",
        "        batch_size, num_features = x.shape\n",
        "        cov_x = (x.T @ x) / (batch_size - 1) #C(Z)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\n",
        "        return self.std_coeff * std_loss, self.cov_coeff * cov_loss\n",
        "        # return std_loss, cov_loss\n",
        "\n",
        "    # def argm(self, sx, a, sy):\n",
        "    #     batch=sx.size(dim=0)\n",
        "    #     z = nn.Parameter(torch.rand((batch,self.dim_z),device=device)*2 -1)#*self.dim_z**(-0.5) # 1/d^(1/2)\n",
        "    #     optim = torch.optim.SGD([z], lr=3e3)\n",
        "    #     lossfn = torch.nn.MSELoss()\n",
        "    #     sx, a, sy = sx.detach(), a.detach(), sy.detach()\n",
        "    #     num_steps = 10\n",
        "    #     for i in range(num_steps):\n",
        "    #         sxaz = torch.cat([sx, a, z], dim=-1)\n",
        "    #         sy_ = self.pred(sxaz)\n",
        "    #         # print(\"y_, y\",y_.shape, y.shape)\n",
        "    #         loss = lossfn(sy_, sy)\n",
        "    #         loss.backward()\n",
        "    #         optim.step()\n",
        "    #         optim.zero_grad()\n",
        "    #     if loss.item()>0.1: print(\"argm\",loss.item(), z[0].item())\n",
        "    #     return z#.detach()\n",
        "\n",
        "    def loss(self, x):\n",
        "        sx = self.enc(x)\n",
        "        std_loss, cov_loss = self.v_creg(self.exp(sx))\n",
        "        dec_loss = F.mse_loss(self.decode(sx.detach()), x)\n",
        "        return std_loss, cov_loss, dec_loss\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(\"fwd1\", x.shape)\n",
        "        x = self.encode(x)\n",
        "        # print(\"fwd2\", x.shape)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x)#.squeeze()\n",
        "    def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    # def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "d_model=128 # 128\n",
        "dim_v=32\n",
        "model = JEPA(d_model, dim_v).to(device)\n",
        "# x=torch.rand(1, in_dimx)\n",
        "# loss = model.loss(x,y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title test balls bins\n",
        "out_ch=3\n",
        "balls=6\n",
        "\n",
        "# dim_scales = [int(out_ch / (2 ** i)) for i in range(1, balls)] # [64, 32]\n",
        "# dim_scales = [round(out_ch / (2 ** i)) for i in range(1, balls)] # [64, 32]\n",
        "# dim_scales = [round((balls-out_ch) / (2.5 ** i))+1 for i in range(1, out_ch)] # [64, 32]\n",
        "# dim_scales = [*dim_scales, out_ch - sum(dim_scales)] # [64, 32, 32] # more channels for smaller kernels\n",
        "\n",
        "mult = [1/(1.4**i) for i in range(out_ch)]\n",
        "mul = balls/sum(mult)\n",
        "mult = [m*mul for m in mult]\n",
        "# print(mult)\n",
        "print([floor(m) for m in mult])\n",
        "dim_scales = [0]*out_ch\n",
        "# for i in range(balls):\n",
        "#     ind = mult.index(max(mult))\n",
        "#     dim_scales[ind] += 1\n",
        "#     mult[ind] -= 1\n",
        "\n",
        "# r=2\n",
        "# dim_scales = [int((out_ch/r**2) / (2 ** i)) for i in range(1, len(kernel_sizes))] # [64, 32]\n",
        "# dim_scales = [*dim_scales, int(out_ch/r**2) - sum(dim_scales)] # [64, 32, 32]\n",
        "# dim_scales = [d*r**2 for d in dim_scales]\n",
        "print('dim_scales',dim_scales)\n"
      ],
      "metadata": {
        "id": "FjCGzyEq5feN",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "B8Pm-Fw6jn4A",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title mha me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "def zero_module(module):\n",
        "    \"\"\"Zero out the parameters of a module and return it.\"\"\"\n",
        "    for p in module.parameters():\n",
        "        p.detach().zero_()\n",
        "    return module\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, n_heads=None, d_head=8, cond_dim=None, dropout=0):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_head = d_head\n",
        "        self.n_heads = d_model // d_head\n",
        "        # self.d_head = d_model // n_heads\n",
        "        self.cond_dim = cond_dim\n",
        "        self.q = nn.Linear(d_model, d_model, bias=False)\n",
        "        self.kv = nn.Linear(cond_dim or d_model, 2*d_model, bias=False)\n",
        "        # self.k = nn.Sequential(nn.Dropout(dropout), nn.Linear(cond_dim, d_model, bias=False))\n",
        "        # self.lin = nn.Linear(d_model, d_model)\n",
        "        self.lin = zero_module(nn.Linear(d_model, d_model))\n",
        "        self.drop = nn.Dropout(dropout) # indp before q,k,v; after linout\n",
        "        self.scale = self.d_head ** -.5\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [batch, T, d_model]=[batch, h*w, c], [batch, num_tok, cond_dim], [batch,T]\n",
        "        batch = x.shape[0]\n",
        "        if self.cond_dim==None: cond=x # is self attn\n",
        "        Q = self.q(x).view(batch, -1, self.n_heads, self.d_head).transpose(1, 2) # [batch, T, d_model] -> [batch, n_heads, T, d_head]\n",
        "        # K = self.k(x).view(batch, -1, self.n_heads, self.d_head).transpose(1, 2)\n",
        "        K, V = self.kv(cond).view(batch, -1, self.n_heads, 2*self.d_head).transpose(1, 2).chunk(2, dim=-1) # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # linear attention # Softmax(Q) @ (Softmax(K).T @ V)\n",
        "        if mask != None:\n",
        "            mask = mask[:, None, :, None] # [batch,T] -> [batch,1,T,1]\n",
        "            K, V = K.masked_fill(mask, -torch.finfo(x.dtype).max), V.masked_fill(mask, -torch.finfo(x.dtype).max)\n",
        "        Q, K = Q.softmax(dim=-1)*self.scale, K.softmax(dim=-2)\n",
        "        context = K.transpose(-2,-1) @ V # [batch, n_heads, d_head, d_head]\n",
        "        out = Q @ context # [batch, n_heads, T/num_tok, d_head]\n",
        "\n",
        "        # # (quadratic) attention # Softmax(Q @ K.T) @ V\n",
        "        # attn = Q @ K.transpose(-2,-1) * self.scale # [batch, n_heads, T] # [batch, n_heads, T, T/num_tok]\n",
        "        # if mask != None: attn = attn.masked_fill(mask[:, None, :, None], -torch.finfo(attn.dtype).max) # [batch,T]->[batch,1,T,1]\n",
        "        # attention = torch.softmax(attn, dim=-1)\n",
        "        # out = self.drop(attention) @ V # [batch, n_heads, T, d_head]\n",
        "\n",
        "        out = out.transpose(1, 2).flatten(2)\n",
        "        return self.lin(out) # [batch, T, d_model]\n",
        "\n",
        "# if self, dont pass cond_dim in init, dont pass cond in fwd\n",
        "# Softmax(Q @ K.T) @ V ~ Softmax(Q) @ Softmax(K).T @ V\n",
        "\n",
        "\n",
        "class AttentionBlock(nn.Module):\n",
        "    def __init__(self, d_model, d_head, cond_dim=None, ff_dim=None, dropout=0.):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.norm1 = nn.RMSNorm(d_model) # LayerNorm RMSNorm\n",
        "        self.norm2 = nn.RMSNorm(d_model)\n",
        "        self.drop = nn.Dropout(dropout)\n",
        "        self.cond_dim = cond_dim\n",
        "        self.self = MultiHeadAttention(d_model, d_head=d_head, dropout=0)\n",
        "        if self.cond_dim!=None: self.cross = MultiHeadAttention(d_model, d_head=d_head, cond_dim=cond_dim, dropout=0)\n",
        "        act = nn.ReLU()\n",
        "        if ff_dim==None: ff_dim=d_model*4\n",
        "        self.ff = nn.Sequential(\n",
        "            nn.RMSNorm(d_model), nn.Linear(d_model, ff_dim), nn.ReLU(), # ReLU GELU\n",
        "            nn.RMSNorm(ff_dim), nn.Dropout(dropout), nn.Linear(ff_dim, d_model)\n",
        "            # nn.RMSNorm(d_model), act, nn.Linear(d_model, ff_dim),\n",
        "            # nn.RMSNorm(ff_dim), act, nn.Linear(ff_dim, d_model)\n",
        "            # nn.RMSNorm(d_model), nn.Linear(d_model, ff_dim), nn.ReLU(), nn.Dropout(dropout), # ReLU GELU\n",
        "            # nn.Linear(ff_dim, d_model), nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, cond=None, mask=None): # [b,c,h,w], [batch, num_tok, cond_dim], [batch,T]\n",
        "        bchw = x.shape\n",
        "        x = x.flatten(2).transpose(1,2) # [b,h*w,c]\n",
        "        # if self.cond_dim==None: cond=None # is self attn\n",
        "        x = x + self.self(self.norm1(x))\n",
        "        if self.cond_dim!=None: x = x + self.cross(self.norm2(x), cond, mask)\n",
        "        x = x + self.ff(x)\n",
        "        return x.transpose(1,2).reshape(*bchw)\n",
        "\n",
        "\n",
        "\n",
        "# d_model=8\n",
        "# d_head=4\n",
        "# batch=4\n",
        "# h,w=5,6\n",
        "# x=torch.rand(batch,d_model,h,w)\n",
        "# cond_dim=10\n",
        "# model = AttentionBlock(d_model=d_model, d_head=d_head,cond_dim=cond_dim)\n",
        "# num_tok=1\n",
        "# cond=torch.rand(batch,num_tok,cond_dim)\n",
        "# mask=torch.rand(batch,h*w)>0.5\n",
        "# out = model(x, cond, mask)\n",
        "# print(out.shape)\n",
        "# # print(out)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title PixelShuffleConv\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "class CrossEmbedLayer(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_sizes, stride=1):\n",
        "        super().__init__()\n",
        "        kernel_sizes = sorted(kernel_sizes)\n",
        "\n",
        "        r=2\n",
        "        balls = out_ch//r**2\n",
        "        mult = [1/(1.6**i) for i in range(len(kernel_sizes))]\n",
        "        mul = balls/sum(mult)\n",
        "        mult = [m*mul for m in mult]\n",
        "        dim_scales = [0]*len(kernel_sizes)\n",
        "        for i in range(balls):\n",
        "            ind = mult.index(max(mult))\n",
        "            dim_scales[ind] += 1\n",
        "            mult[ind] -= 1\n",
        "        dim_scales = [d*r**2 for d in dim_scales]\n",
        "        if 0 in dim_scales: print('dim_scales',dim_scales)\n",
        "        # 1/2 + 1/4 + 1/8 + ... + 1/2^num_kernels + 1/2^num_kernels of out_ch; smaller kernel allocated more channels\n",
        "        self.convs = nn.ModuleList([nn.Conv2d(in_ch, dim_scale, kernel, stride=stride, padding=(kernel-stride)//2) for kernel, dim_scale in zip(kernel_sizes, dim_scales)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # return torch.cat([conv(x) for conv in self.convs], dim = 1)\n",
        "        out = torch.cat([conv(x) for conv in self.convs], dim = 1)\n",
        "        b,c,h,w = out.shape\n",
        "        out = out.reshape(b, -1, 4, h, w).transpose(1,2).reshape(b, c, h, w)\n",
        "        return out\n",
        "\n",
        "class PixelShuffleConv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch = None, kernel_size=3, r=2):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch = in_ch\n",
        "        self.in_ch, self.out_ch, self.r = in_ch, out_ch, r\n",
        "        r = max(r, int(1/r))\n",
        "        if self.r>1: self.net = nn.Sequential(nn.Conv2d(in_ch, out_ch * r**2, kernel_size, 1, padding=kernel_size//2), nn.PixelShuffle(r)) # PixelShuffle: [b,c*r^2,h,w] -> [b,c,h*r,w*r] # upscale by upscale factor r # https://arxiv.org/pdf/1609.05158v2\n",
        "        elif self.r<1: self.net = nn.Sequential(nn.PixelUnshuffle(r), nn.Conv2d(in_ch * r**2, out_ch, kernel_size, 1, padding=kernel_size//2)) # PixelUnshuffle: [b,c,h*r,w*r] -> [b,c*r^2,h,w]\n",
        "        else: self.net = nn.Conv2d(in_ch, out_ch, kernel_size, 1, padding=kernel_size//2)\n",
        "        self.net.apply(self.init_conv_)\n",
        "\n",
        "    def init_conv_(self, conv): # weight initialisation very important for the performance of pixelshuffle!\n",
        "        if isinstance(conv, nn.Conv2d):\n",
        "            o, i, h, w = conv.weight.shape\n",
        "            conv_weight = torch.empty(self.out_ch, self.in_ch, h, w)\n",
        "            nn.init.kaiming_uniform_(conv_weight)\n",
        "            # print(conv.weight.shape, conv_weight.shape,max(self.r, int(1/self.r)), (0 if self.r>1 else 1))\n",
        "            conv.weight.data.copy_(conv_weight.repeat_interleave(max(self.r, int(1/self.r))**2, dim=(0 if self.r>1 else 1)))\n",
        "            nn.init.zeros_(conv.bias.data)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "4ACs_g4rlZxp"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title unet me\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# torch.set_default_dtype(torch.float16)\n",
        "\n",
        "import inspect\n",
        "class Seq(nn.Sequential):\n",
        "    def __init__(self, *args):\n",
        "        super().__init__(*args)\n",
        "        for layer in self:\n",
        "            params = inspect.signature(layer.forward).parameters.keys()\n",
        "            layer._fwdparams = ','.join(params)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        for layer in self:\n",
        "            args = [x]\n",
        "            if 'emb' in layer._fwdparams: args.append(emb)\n",
        "            if 'cond' in layer._fwdparams: args.append(cond)\n",
        "            x = layer(*args)\n",
        "        return x\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch=None, emb_dim=None, drop=0.):\n",
        "        super().__init__()\n",
        "        if out_ch==None: out_ch=in_ch\n",
        "        act = nn.SiLU() #\n",
        "        self.block1 = nn.Sequential(nn.BatchNorm2d(in_ch), act, nn.Conv2d(in_ch, out_ch, 3, padding=1))\n",
        "        self.block2 = Seq(nn.BatchNorm2d(out_ch), scale_shift(out_ch, emb_dim) if emb_dim != None else nn.Identity(), act, nn.Conv2d(out_ch, out_ch, 3, padding=1))\n",
        "        # self.res_conv = nn.Conv2d(in_ch, out_ch, 1) if in_ch != out_ch else nn.Identity()\n",
        "        self.res_conv = zero_module(nn.Conv2d(in_ch, out_ch, 1)) if in_ch != out_ch else nn.Identity()\n",
        "\n",
        "    def forward(self, x, emb=None): # [b,c,h,w], [batch, emb_dim]\n",
        "        h = self.block1(x)\n",
        "        h = self.block2(h, emb)\n",
        "        return h + self.res_conv(x)\n",
        "\n",
        "        # nn.PixelUnshuffle(2), init_conv(nn.Conv2d(3 * 2**2, d_list[0], 7, 1, padding=7//2), in_r=2), act, # good\n",
        "        init_conv(nn.Conv2d(d_list[1], d_list[0] * 2**2, 5, 1, padding=5//2), out_r=2), nn.PixelShuffle(2), act, # good\n",
        "\n",
        "\n",
        "class scale_shift(nn.Module): # FiLM\n",
        "    def __init__(self, x_dim, t_dim):\n",
        "        super().__init__()\n",
        "        self.time_mlp = nn.Sequential(nn.SiLU(), nn.Linear(t_dim, x_dim*2),)\n",
        "\n",
        "    def forward(self, x, emb): # [b,c,h,w], [b,emb_dim]\n",
        "        scale, shift = self.time_mlp(emb)[..., None, None].chunk(2, dim=1) # [b,t_dim]->[b,2*x_dim,1,1]->[b,x_dim,1,1]\n",
        "        return x * (scale + 1) + shift\n",
        "\n",
        "class levelBlock(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, emb_dim=None, cond_dim=None, n_head=None, d_head=8, updown=False, r=2):\n",
        "        super().__init__()\n",
        "        if updown=='down': in_ch = in_ch*r**2\n",
        "        elif updown=='up': out_ch = out_ch*r**2\n",
        "        # if n_head==None: n_head = out_ch // d_head\n",
        "        # self.op = nn.Conv2d(in_ch, out_ch, 3, stride=2, padding=1) # optional # stride = 2 if conv_dim != 3 else (1, 2, 2) # If 3D, then downsampling occurs in the inner-two dimensions\n",
        "        # self.op = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, stride=2, padding=1), act)\n",
        "        # # self.op = avg_pool_nd(conv_dim, kernel_size=stride, stride=stride) # alternative\n",
        "    # return nn.Sequential(nn.PixelUnshuffle(2), nn.Conv2d(in_ch * 4, out_ch, 1)) # PixelUnshuffle: [b,c,h*r,w*r] -> [b,c*r^2,h,w]\n",
        "\n",
        "        layers = [\n",
        "            nn.PixelUnshuffle(r) if updown=='down' else nn.Identity(),\n",
        "            ResBlock(in_ch, out_ch, emb_dim=emb_dim),\n",
        "            AttentionBlock(out_ch, d_head, cond_dim),\n",
        "            nn.PixelShuffle(r) if updown=='up' else nn.Identity(),\n",
        "            ]\n",
        "\n",
        "        # layers = [\n",
        "        #     PixelShuffleConv(in_ch, out_ch, kernel_size=1, r=1/2) if updown=='down' else nn.Identity(),\n",
        "        #     ResBlock(out_ch if updown=='down' else in_ch, emb_dim=emb_dim),\n",
        "        #     AttentionBlock(out_ch if updown=='down' else in_ch, d_head, cond_dim),\n",
        "        #     PixelShuffleConv(in_ch, out_ch, kernel_size=1, r=2) if updown=='up' else nn.Identity(),\n",
        "        #     ]\n",
        "\n",
        "        # x = F.interpolate(x, scale_factor=2, mode=\"nearest\") # if self.conv_dim == 3: x = F.interpolate(x, (x.shape[2], x.shape[3] * 2, x.shape[4] * 2), mode=\"nearest\")\n",
        "        # return nn.Sequential(nn.Interpolate(scale_factor = 2, mode = 'nearest'), nn.Conv2d(in_ch, out_ch, 3, padding=1))\n",
        "\n",
        "        self.seq = Seq(*layers)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        return self.seq(x, emb, cond)\n",
        "\n",
        "\n",
        "\n",
        "class levelBlock(nn.Module):\n",
        "    def __init__(self, in_ch, d_model, out_ch, emb_dim=None, cond_dim=None, n_head=None, d_head=8, updown=False, r=1):\n",
        "        super().__init__()\n",
        "        # if n_head==None: n_head = out_ch // d_head\n",
        "    # return nn.Sequential(nn.PixelUnshuffle(2), nn.Conv2d(in_ch * 4, out_ch, 1)) # PixelUnshuffle: [b,c,h*r,w*r] -> [b,c*r^2,h,w]\n",
        "\n",
        "        # layers = [\n",
        "        #     nn.PixelUnshuffle(r) if updown=='down' else nn.Identity(),\n",
        "        #     ResBlock(in_ch, out_ch, emb_dim=emb_dim),\n",
        "        #     AttentionBlock(out_ch, d_head, cond_dim),\n",
        "        #     nn.PixelShuffle(r) if updown=='up' else nn.Identity(),\n",
        "        #     ]\n",
        "\n",
        "        layers = [\n",
        "            # PixelShuffleConv(in_ch, d_model, kernel_size=1, r=1/2) if updown=='down' else nn.Identity(),\n",
        "            # PixelShuffleConv(in_ch, d_model, kernel_size=1, r=1/2 if updown=='down' else 1) if in_ch != d_model else nn.Identity(),\n",
        "            PixelShuffleConv(in_ch, d_model, kernel_size=1, r=r) if in_ch != d_model else nn.Identity(),\n",
        "            ResBlock(d_model, emb_dim=emb_dim),\n",
        "            AttentionBlock(d_model, d_head, cond_dim),\n",
        "            # PixelShuffleConv(d_model, out_ch, kernel_size=1, r=2) if updown=='up' else nn.Identity(),\n",
        "            # PixelShuffleConv(d_model, out_ch, kernel_size=1, r=2 if updown=='up' else 1) if out_ch != d_model else nn.Identity(),\n",
        "            PixelShuffleConv(d_model, out_ch, kernel_size=1, r=r) if out_ch != d_model else nn.Identity(),\n",
        "            ]\n",
        "\n",
        "        # x = F.interpolate(x, scale_factor=2, mode=\"nearest\") # if self.conv_dim == 3: x = F.interpolate(x, (x.shape[2], x.shape[3] * 2, x.shape[4] * 2), mode=\"nearest\")\n",
        "        # return nn.Sequential(nn.Interpolate(scale_factor = 2, mode = 'nearest'), nn.Conv2d(in_ch, out_ch, 3, padding=1))\n",
        "\n",
        "        self.seq = Seq(*layers)\n",
        "\n",
        "    def forward(self, x, emb=None, cond=None):\n",
        "        return self.seq(x, emb, cond)\n",
        "\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, d_model=16, out_ch=None, cond_dim=16, depth=4, num_res_blocks=1, n_head=-1, d_head=4):\n",
        "        super().__init__()\n",
        "        self.in_ch = in_ch\n",
        "        self.d_model = d_model # base channel count for the model\n",
        "        out_ch = out_ch or in_ch\n",
        "        n_head = d_model // d_head\n",
        "\n",
        "        self.rotemb = RotEmb(d_model)\n",
        "        emb_dim = d_model# * 4\n",
        "        self.time_emb = nn.Sequential(nn.Linear(d_model, emb_dim), nn.SiLU(), nn.Linear(emb_dim, emb_dim))\n",
        "\n",
        "        self.in_block = nn.Sequential(nn.Conv2d(in_ch, d_model, 3, padding=1))\n",
        "        # self.init_conv = CrossEmbedLayer(in_ch, dim_out=d_model, kernel_sizes=(3, 7, 15), stride=1) #if init_cross_embed else nn.Conv2d(in_ch, d_model, 7, padding = 7//2)\n",
        "\n",
        "        mult = [1,2,3,4] # [1,2,3,4] [1,2,2,2]\n",
        "        ch_list = [d_model * m for m in mult[:depth+1]] # [128, 256, 384, 512]\n",
        "\n",
        "        self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], emb_dim, cond_dim, updown=None if i==0 else 'down') for i in range(depth)])\n",
        "        # self.down_list = nn.ModuleList([levelBlock(ch_list[i], ch_list[i+1], emb_dim, cond_dim, updown='down') for i in range(depth)])\n",
        "\n",
        "        ch = ch_list[-1]*2**2 # 512\n",
        "        self.middle_block = Seq(\n",
        "            nn.PixelUnshuffle(2), ResBlock(ch, ch, emb_dim),\n",
        "            AttentionBlock(ch, d_head, cond_dim),\n",
        "            ResBlock(ch, ch, emb_dim), nn.PixelShuffle(2),\n",
        "        )\n",
        "        self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], emb_dim, cond_dim, updown=None if i==0 else 'up') for i in reversed(range(depth))])\n",
        "        # self.up_list = nn.ModuleList([levelBlock(2*ch_list[i+1], ch_list[i], emb_dim, cond_dim, updown='up') for i in reversed(range(depth))])\n",
        "\n",
        "        # self.out_block = nn.Sequential(nn.BatchNorm2d(d_model), nn.SiLU(), nn.Conv2d(d_model, out_ch, 3, padding=1)) # zero\n",
        "        self.out_block = nn.Sequential(nn.BatchNorm2d(d_model), nn.SiLU(), zero_module(nn.Conv2d(d_model, out_ch, 3, padding=1))) # zero\n",
        "        # self.final_conv = nn.Conv2d(d_model, self.out_ch, 3, padding = 3//2) # lucid; or prepend final res block\n",
        "\n",
        "    def forward(self, x, t=None, cond=None): # [N, c,h,w], [N], [N, cond_dim]\n",
        "        t_emb = self.rotemb(t)\n",
        "        emb = self.time_emb(t_emb) #+ self.label_emb(y) # class conditioning nn.Embedding(num_classes, emb_dim)\n",
        "\n",
        "        blocks = []\n",
        "        x = self.in_block(x) if self.in_ch!=self.d_model else x\n",
        "        for i, down in enumerate(self.down_list):\n",
        "            x = down(x, emb, cond)\n",
        "            blocks.append(x)\n",
        "        x = self.middle_block(x, emb, cond)\n",
        "        for i, up in enumerate(self.up_list):\n",
        "            # print(\"unet fwd\", x.shape,blocks[-i-1].shape)\n",
        "            x = torch.cat([x, blocks[-i-1]*2**.5], dim=1) # scale residuals by 1/sqrt2\n",
        "            x = up(x, emb, cond) # x = up(x, blocks[-i - 1])\n",
        "        return self.out_block(x) if self.out_ch!=self.d_model else x\n",
        "\n",
        "\n",
        "\n",
        "# # 64,64 -vae-> 16,16 -unet->\n",
        "# batch = 4\n",
        "# cond_dim=10\n",
        "# in_ch = 3\n",
        "# model = UNet(in_ch=in_ch, d_model=16, cond_dim=cond_dim, depth=3).to(device)\n",
        "# print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 19683\n",
        "# # print(model)\n",
        "\n",
        "# x=torch.rand((batch,in_ch,16,16),device=device)\n",
        "# t = torch.rand((batch,), device=device) # in [0,1] [N]\n",
        "# cond=torch.rand((batch,cond_dim),device=device)\n",
        "# out = model(x, t, cond)\n",
        "# print(out.shape)\n",
        "\n",
        "# optim = torch.optim.AdamW(model.parameters(), lr=1e-3) # 1e-3 3e-3\n",
        "# # cond_emb = nn.Embedding(10, cond_dim).to(device)\n"
      ],
      "metadata": {
        "id": "B4R77KQvNgj4"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title EpicAE\n",
        "\n",
        "def init_conv(conv, out_r=1, in_r=1):\n",
        "    o, i, h, w = conv.weight.shape\n",
        "    conv_weight = torch.empty(o//out_r**2, i//in_r**2, h, w)\n",
        "    nn.init.kaiming_uniform_(conv_weight)\n",
        "    conv.weight.data.copy_(conv_weight.repeat_interleave(out_r**2, dim=0).repeat_interleave(in_r**2, dim=1))\n",
        "    # conv.weight.data.copy_(conv_weight.repeat_interleave(out_r**2, dim=0).repeat_interleave(in_r, dim=1).repeat(1,in_r, 1,1))\n",
        "    # conv.weight.data.copy_(conv_weight.repeat_interleave(out_r**2, dim=0).repeat(1,in_r**2, 1,1))\n",
        "    if conv.bias is not None: nn.init.zeros_(conv.bias)\n",
        "    return conv\n",
        "\n",
        "\n",
        "\n",
        "class EpicAE(torch.nn.Module):\n",
        "    def __init__(self, in_ch=3, d_model=16, drop=0.):\n",
        "        super().__init__()\n",
        "        # d_list=[32, 64, 128, 256, 256, 256] # 1278976\n",
        "        # d_list=[32, 64] # 849126\n",
        "        d_list=[16, 16] # 849126\n",
        "        in_list=[in_ch, *d_list[:-1]]\n",
        "        # kernels = [(7,5,3), (3, 5)]\n",
        "        # kernels = [(7,3), (5,3)]\n",
        "        # kernels = [(7,), (5,)]\n",
        "        # kernels = [(3,), (3,)]\n",
        "        # kernels = [7,5]\n",
        "        # kernels = [3,3]\n",
        "        kernels = [4,4]\n",
        "        # kernels = [(1,), (1,)]\n",
        "        act = nn.GELU() # ReLU GELU SiLU\n",
        "\n",
        "        self.encoder = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), # SiLU ReLU\n",
        "            # *[nn.Sequential(PixelShuffleConvDown(in_dim, out_dim, kernel, r=2), nn.BatchNorm2d(out_dim) if i!=len(d_list) else nn.Identity(), act,) for i, (in_dim, out_dim, kernel) in enumerate(zip(in_list, d_list, kernels))],\n",
        "\n",
        "            # PixelShuffleConvDown(in_ch, d_list[0], 7, r=2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # PixelShuffleConvDown(d_list[0], d_list[1], 5, r=2), act,\n",
        "\n",
        "            # nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # nn.Dropout2d(drop), nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), act,\n",
        "            # nn.Dropout2d(drop), nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), act,\n",
        "\n",
        "            # nn.Conv2d(in_ch, d_list[1], 7, 2, 7//2), nn.MaxPool2d(2, 2),\n",
        "            # nn.MaxPool2d(2, 2), nn.Conv2d(in_ch, d_list[1], 7, 1, 7//2), nn.MaxPool2d(2, 2),\n",
        "\n",
        "\n",
        "            # nn.Conv2d(in_ch, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.GELU(),\n",
        "            # nn.Dropout2d(drop), nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.GELU(),\n",
        "\n",
        "            # nn.Conv2d(in_ch, d_list[0], 7, 2, 3), nn.GELU(),\n",
        "            # nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.GELU(),\n",
        "\n",
        "\n",
        "            # nn.PixelUnshuffle(2), init_conv(nn.Conv2d(3 * 2**2, d_list[0], 7, 1, padding=7//2), in_r=2), act, # good\n",
        "            # nn.PixelUnshuffle(2), init_conv(nn.Conv2d(d_list[0] * 2**2, d_list[1], 5, 1, padding=5//2), in_r=2), act, # good\n",
        "\n",
        "            # nn.PixelUnshuffle(2), nn.Conv2d(3 * 2**2, d_list[0], 7, 1, padding=7//2), act, # good\n",
        "            # nn.PixelUnshuffle(2), nn.Conv2d(d_list[0] * 2**2, d_list[1], 5, 1, padding=5//2), act, # good\n",
        "\n",
        "\n",
        "            # nn.PixelUnshuffle(2),\n",
        "            # init_conv(nn.Conv2d(3*2**2, 3//1**2, 1, 1, padding=1//2), out_r=1, in_r=2)\n",
        "\n",
        "\n",
        "\n",
        "            # nn.PixelUnshuffle(4), ResBlock(in_ch*4**2, d_list[1]), AttentionBlock(d_list[1], d_head=2),\n",
        "            # levelBlock(in_ch, d_list[1], d_head=4, updown='down', r=1/4)\n",
        "            levelBlock(in_ch, d_model, d_list[0], d_head=4, updown='down', r=1/2),\n",
        "            levelBlock(d_list[0], d_model, d_list[1], d_head=4, updown='down', r=1/2)\n",
        "\n",
        "            # nn.PixelUnshuffle(4), init_conv(nn.Conv2d(in_ch*4**2, d_list[0]//1**2, 7, 1, padding=7//2), out_r=1, in_r=4),\n",
        "            # nn.PixelUnshuffle(2), init_conv(nn.Conv2d(in_ch*2**2, d_list[0]//2**2, 7, 1, padding=7//2), out_r=2, in_r=1), nn.PixelUnshuffle(2),\n",
        "            # init_conv(nn.Conv2d(in_ch*1**2, d_list[0]//4**2, 7, 1, padding=7//2), out_r=4, in_r=1), nn.PixelUnshuffle(4),\n",
        "\n",
        "            # nn.PixelUnshuffle(4), nn.Conv2d(in_ch*4**2, d_list[0]//1**2, 7, 1, padding=7//2),\n",
        "            # nn.PixelUnshuffle(2), nn.Conv2d(in_ch*2**2, d_list[0]//2**2, 7, 1, padding=7//2), nn.PixelUnshuffle(2),\n",
        "            # init_conv(nn.Conv2d(in_ch*1**2, d_list[0]//4**2, 7, 1, padding=7//2), out_r=4, in_r=1), nn.PixelUnshuffle(4),\n",
        "\n",
        "            # PixelShuffleConv(in_ch, d_list[0], 7, r=1/2), nn.BatchNorm2d(d_list[1]), act,\n",
        "            # PixelShuffleConv(d_list[0], d_list[1], 5, r=1/2),\n",
        "\n",
        "\n",
        "            # levelBlock(ch_list[i], ch_list[i+1]\n",
        "\n",
        "            # nn.Flatten(start_dim=1),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # nn.Unflatten(-1, (d_model,1,1)),\n",
        "\n",
        "            # *[nn.Sequential(PixelShuffleConvUp(in_dim, out_dim, kernel, r=2), nn.BatchNorm2d(out_dim) if i!=len(d_list) else nn.Identity(), act if i!=len(d_list) else nn.Identity()) for i, (in_dim, out_dim, kernel) in enumerate(zip(reversed(d_list), reversed(in_list), reversed(kernels)))],\n",
        "\n",
        "            # PixelShuffleConvUp(d_list[1], d_list[0], 5, r=2), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # PixelShuffleConvUp(d_list[0], in_ch, 7, r=2), act,\n",
        "\n",
        "            # nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), act,\n",
        "            # nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), act,\n",
        "            # nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], in_ch, 7, 2, 7//2, output_padding=1),# nn.BatchNorm2d(d_list[1]), nn.SiLU(),\n",
        "            # nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], in_ch, 7, 1, 7//2, output_padding=0), nn.Upsample(scale_factor=2)\n",
        "\n",
        "            # nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            # nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1),\n",
        "\n",
        "            # init_conv(nn.Conv2d(d_list[1], d_list[0] * 2**2, 5, 1, padding=5//2), out_r=2), nn.PixelShuffle(2), act, # good\n",
        "            # init_conv(nn.Conv2d(d_list[0], 3 * 2**2, 7, 1, padding=7//2), out_r=2), nn.PixelShuffle(2), # good\n",
        "\n",
        "\n",
        "            # ResBlock(d_list[1], in_ch*4**2), AttentionBlock(in_ch*4**2, d_head=2), nn.PixelShuffle(4),\n",
        "            # levelBlock(d_list[1], in_ch, d_head=4, updown='up', r=4)\n",
        "            levelBlock(d_list[1], d_model, d_list[0], d_head=4, updown='up', r=2),\n",
        "            levelBlock(d_list[0], d_model, in_ch, d_head=4, updown='up', r=2)\n",
        "\n",
        "            # init_conv(nn.Conv2d(3*1**2, 3*2**2, 1, 1, padding=1//2), out_r=2, in_r=1),\n",
        "            # nn.PixelShuffle(2),\n",
        "\n",
        "\n",
        "            # init_conv(nn.Conv2d(d_list[0]//1**2, in_ch*4**2, 7, 1, padding=7//2), out_r=4, in_r=1), nn.PixelShuffle(4),\n",
        "            # nn.PixelShuffle(2), init_conv(nn.Conv2d(d_list[0]//2**2, in_ch*2**2, 7, 1, padding=7//2), out_r=1, in_r=2), nn.PixelShuffle(2),\n",
        "            # nn.PixelShuffle(4), init_conv(nn.Conv2d(d_list[0]//4**2, in_ch*1**2, 7, 1, padding=7//2), out_r=1, in_r=4),\n",
        "\n",
        "\n",
        "            # PixelShuffleConv(d_list[1], d_list[0], 5, r=2), nn.BatchNorm2d(d_list[1]), act,\n",
        "            # PixelShuffleConv(d_list[0], in_ch, 7, r=2), act,\n",
        "\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.encoder(x)\n",
        "    def decode(self, x): return self.decoder(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = EpicAE(in_ch=3).to(device)\n",
        "print(sum(p.numel() for p in model.parameters() if p.requires_grad)) # 16x16 conv 17651 ; pixel(3)(3)  ; (1)(1)  ; (3,7,15)(3,7)  ; (3,5,7)(3,5) 42706 ; 7,5 70226\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "in_ = model.decode(out)\n",
        "print(in_.shape)\n",
        "\n",
        "optim = torch.optim.AdamW(model.parameters(), 1e-3) #\n"
      ],
      "metadata": {
        "id": "B0sa_kP-ggPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "128d820e-e6c7-49d1-8f14-24bcc7576815"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32348\n",
            "torch.Size([4, 16, 32, 32])\n",
            "torch.Size([4, 3, 64, 64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = PixelShuffleConvDown(in_ch=2, out_ch = 2, kernel_sizes=3)\n",
        "for name, param in model.named_parameters():\n",
        "    try: print(name, param.shape, param[:,:,0,0])\n",
        "    except: print(name, param.shape, param)\n",
        "    # break\n",
        "# net.1.weight torch.Size([2, 8, 3, 3]) tensor([[ 0.0092, -0.1583,  0.0092, -0.1583,  0.0092, -0.1583,  0.0092, -0.1583],\n",
        "#         [ 0.1778,  0.2973,  0.1778,  0.2973,  0.1778,  0.2973,  0.1778,  0.2973]],\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDMuYliiHgfo",
        "outputId": "aae78ce6-1523-49aa-c8f5-6b963f63c5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net.1.weight torch.Size([2, 8, 3, 3]) tensor([[ 0.0092, -0.1583,  0.0092, -0.1583,  0.0092, -0.1583,  0.0092, -0.1583],\n",
            "        [ 0.1778,  0.2973,  0.1778,  0.2973,  0.1778,  0.2973,  0.1778,  0.2973]],\n",
            "       grad_fn=<SelectBackward0>)\n",
            "net.1.bias torch.Size([2]) Parameter containing:\n",
            "tensor([0., 0.], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = torch.rand(1,8,2,2)\n",
        "print(x)\n",
        "out= nn.PixelShuffle(2)(x)\n",
        "print(out)\n",
        "\n",
        "x = torch.rand(1,2,4,4)\n",
        "print(x)\n",
        "out= nn.PixelUnshuffle(2)(x)\n",
        "print(out)\n"
      ],
      "metadata": {
        "id": "iXVZjuvASlNW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzzjgoXCnhT7",
        "outputId": "154726d1-ee39-4cf5-c6b0-05f57b0ddc48",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "loss: 10.519956  [    0/  447]\n"
          ]
        }
      ],
      "source": [
        "# @title train autoencoder\n",
        "# optim = torch.optim.AdamW(model.parameters(), 1e-3, (0.9, 0.95)) # 256 lr = 1e-3\n",
        "# optim = torch.optim.AdamW(model.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-3\n",
        "# optim = torch.optim.AdamW(model.parameters(), 1e-3) #\n",
        "\n",
        "def train(dataloader, model, optimizer, scheduler=None, verbose=True):\n",
        "    size = len(dataloader)\n",
        "    model.train()\n",
        "    for batch, state in enumerate(dataloader):\n",
        "        state = state.to(device)\n",
        "        # sx_ = agent.jepa.enc(state)\n",
        "        # state_ = agent.conv(sx_)\n",
        "        state_ = model(state)\n",
        "        # # s1,s2,state_ = model(state)\n",
        "        loss = F.mse_loss(state_, state)\n",
        "        # std_loss, cov_loss, dec_loss = model.loss(state)\n",
        "        # loss = std_loss + cov_loss + dec_loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        if scheduler is not None: scheduler.step()\n",
        "        # print(\"loss std,cov,dec\", std_loss.item(), cov_loss.item(), dec_loss.item())\n",
        "        try: wandb.log({\"loss\": loss.item()})\n",
        "        # try: wandb.log({\"std\": std_loss.item(), \"cov\": cov_loss.item(), \"dec\": dec_loss.item()})\n",
        "        except: pass\n",
        "        if batch % (size//10) == 0:\n",
        "            loss, current = loss.item(), batch\n",
        "            if verbose: print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print(i)\n",
        "    # print(optim.param_groups[0]['lr'])\n",
        "    train(train_loader,model,optim)\n",
        "    state = buffer[12][40][0]\n",
        "    transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "    state = transform(state).unsqueeze(0).to(device)[0]\n",
        "    # print(state.shape)\n",
        "    # sx_ = model.encode(state.unsqueeze(0))\n",
        "    # # print(sx_.shape)\n",
        "    # out= model.decode(sx_.unsqueeze(0)).squeeze(0)\n",
        "    out =model(state.unsqueeze(0)).squeeze(0)\n",
        "    # out= model.decode(sx_)\n",
        "    # print(out, state)\n",
        "    # print(out.shape)\n",
        "    imshow(state.detach().cpu())\n",
        "    imshow(out.detach().cpu())\n",
        "    # imshow(out[0].squeeze(0).detach().cpu())\n",
        "    # imshow(out[1].squeeze(0).detach().cpu())\n",
        "    # imshow(out[2].squeeze(0).detach().cpu())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "train_iter = iter(train_data)\n",
        "img = next(train_iter)\n",
        "imshow(img)\n",
        "\n",
        "def init_conv(conv, out_r=1, in_r=1):\n",
        "    o, i, h, w = conv.weight.shape\n",
        "    conv_weight = torch.empty(o//out_r**2, i//in_r**2, h, w)\n",
        "    nn.init.kaiming_uniform_(conv_weight)\n",
        "    # conv.weight.data.copy_(conv_weight.repeat_interleave(out_r**2, dim=0).repeat_interleave(in_r**2, dim=1))\n",
        "    conv.weight.data.copy_(conv_weight.repeat_interleave(out_r**2, dim=0).repeat(1,in_r**2, 1,1))\n",
        "    if conv.bias is not None: nn.init.zeros_(conv.bias)\n",
        "    return conv\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    # out = PixelShuffleConv(3, 3, kernel_size=1, r=1/2)(img)\n",
        "    # out = nn.Conv2d(3, 3, kernel_size=1)(img)\n",
        "\n",
        "    img = nn.PixelUnshuffle(2)(img)\n",
        "    # img = nn.Conv2d(3*2**2, 3*1**2, 1, 1, padding=1//2)(img)\n",
        "    img = init_conv(nn.Conv2d(3*2**2, 3//1**2, 1, 1, padding=1//2), out_r=1, in_r=2)(img)\n",
        "\n",
        "\n",
        "    img = init_conv(nn.Conv2d(3*1**2, 3*2**2, 1, 1, padding=1//2), out_r=2, in_r=1)(img)\n",
        "    # # img = nn.Conv2d(3*1**2, 3*2**2, 1, 1, padding=1//2)(img)\n",
        "    img = nn.PixelShuffle(2)(img)\n",
        "\n",
        "    # img = nn.Conv2d(12, 3, kernel_size=1)(img)\n",
        "    # out = PixelShuffleConv(3, 3, kernel_size=1, r=2)(img)\n",
        "\n",
        "    imshow(img)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "qpeg-cfjsopF",
        "outputId": "21e91c30-9c49-4525-af24-28cdf8d6d25c"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-1.0..1.0].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [-9.653884..10.253441].\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAEWCAYAAACjTbhPAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAHeVJREFUeJzt3X9wU2W6B/BvS9sUaZPaShN6aaCuaFGsQoESYX8IdTuu48pSHNdhR3QYGdiUBaqj0z9E8bqmo7ODyw6I6yB4R2t3+wcqziiXW7Re77QF6qAgUkHZbdw2AdQmpdK027z3DzAYSJ7TpG9JCt/PzJmB8+Sc8/Y0fXqa5/2RopRSICLSKDXRDSCiyw8TCxFpx8RCRNoxsRCRdkwsRKQdEwsRacfEQkTaMbEQkXZMLESkHRMLEWk3Yoll06ZNmDx5MjIzM1FWVoa9e/eO1KWIKMmkjMRYob/97W944IEHsGXLFpSVleGFF15AQ0MD2tvbkZ+fLx4bDAbR2dmJ7OxspKSk6G4aEcVJKYWenh4UFBQgNdXgmUSNgNmzZyun0xn6/+DgoCooKFAul8vwWLfbrQBw48YtSTe32234c5wGzfr7+9HW1oaamprQvtTUVJSXl6O5ufmi1wcCAQQCgdD/1bkHKLcbMJt1t45oZHQLMZPBsSeE2BdCLEuIfWdwzV4h5o2yv88P/GchkJ2dbXB2QHtiOXXqFAYHB2G1WsP2W61WHDly5KLXu1wurF+//qL9ZjMTC40eQSFmlFjOCLFxccYCQgw4++gRTabBsUP5iCLhVaGamhr4fL7Q5na7E90kIhom7U8s11xzDcaMGQOvN/yByuv1wmazXfR6k8kEk8kopxPRaKL9iSUjIwOlpaVobGwM7QsGg2hsbITD4dB9OSJKQtqfWACguroaS5cuxcyZMzF79my88MIL6O3txUMPPTQSlyOiJDMiieW+++7DyZMnsW7dOng8Htx666147733LvpAV/IOgKsi7J8qHPMPg3OeEmJlQuw6g/PSleG0EJO6f35pcN4eITZBiHULsX8bXLNPiLVH2d9vcM4fG5HEAgBVVVWoqqoaqdMTURJLeFWIiC4/TCxEpB0TCxFpx8RCRNoxsRCRdiNWFRquJVH2FwjHSIOyAGB6nDEiQH5/SZOBGJVpO4TYq0KsW4jdbnBNSbRStVEJ+8f4xEJE2jGxEJF2TCxEpB0TCxFpx8RCRNoxsRCRdkwsRKRd0vZjweC57QKdTwnHSJ1cAHyxMnrse+G4PCG2WL4krhdik4RYhsF5KblIk1Mb9f/wxXlsW5yxS4FPLESkHRMLEWnHxEJE2jGxEJF2TCxEpB0TCxFpl7zl5jHntgt9LhyzyuCcF6/wGrJTWo72P6KHPjG4pDTD/31CrNLgvDQy/inEpO4B0opZtQbXlGbxl9qDB4XYq0brK0uLBEZbgDUI41Whz+ITCxFpx8RCRNoxsRCRdkwsRKRdzInlww8/xN13342CggKkpKTgzTffDIsrpbBu3TpMmDABY8eORXl5OY4ePaqrvUQ0CsScWHp7e3HLLbdg06ZNEePPPfccNm7ciC1btqC1tRXjxo1DRUUF+vqk1WKJ6HKSopSKVlsyPjglBTt27MDChQsBnH1aKSgowCOPPIJHH30UAODz+WC1WrF9+3b89re/NTyn3++HxWIBcAeA9AivkJZ2N5oPXVjWWx2LGrpVOKM0KhqQR6feK8RuEWJXC7FIFfqhHmsWYtIo7WTjMYh/I8S6hdi3QuwnQmyj2BqgUYhJxV3p65C6VgCQp/+vHRsloAD0wefzwWyW3i2aP2M5fvw4PB4PysvLQ/ssFgvKysrQ3Nwc8ZhAIAC/3x+2EdHopjWxeDxnf1dYrdaw/VarNRS7kMvlgsViCW2FhYU6m0RECZDwqlBNTQ18Pl9oc7vdiW4SEQ2T1sRis9kAAF6vN2y/1+sNxS5kMplgNpvDNiIa3bQmlqKiIthsNjQ2nv84yu/3o7W1FQ6HNJqCiC4nMQ9CPH36NI4dO19BOX78OA4cOIDc3FzY7XasWbMGzzzzDKZMmYKioiI88cQTKCgoCFWOiOjyF3Ni2b9/P26//fyS09XV1QCApUuXYvv27XjsscfQ29uL5cuXo7u7G/PmzcN7772HzMzMGK+Ui8hTSkujNr1CDBCLvym3Rg0dkAqNswyKm3ujl8C3CodFbw0wQYjdLLdGjB8UYtIo2zsMrjkSpMmrTxgcK3VY+EqISRVcqZY5Tm4OBoSYVFKWxicHig0uKv0B8cyZyPv7ADxjcN5zYk4sv/jFLyB1fUlJScHTTz+Np59+OtZTE9FlIuFVISK6/DCxEJF2TCxEpB0TCxFpx8RCRNoxsRCRdsk7Sz8mIHKlvkc4RqrsA4BViEk9I4Tz7jPIzbdH7wFy6r+jl+3/53XhnEujh8anyM2R+pxI/WNukk8bN2mii31CTJqOwqg3U5YQk76b/yvEIo/dP8toKotug3g0ASFm9IP9b6lzzYEob6KBoc+wwicWItKOiYWItGNiISLtmFiISDsmFiLSjomFiLRL4nJzAYBIs4XHO5AcAAaFmFT4lGIGi2S/L5TopBXlpZrobdG/bSdLpEIs0PaScFrhOOmr7BJikSa++DFpxSlpGgdpsoqTBteU3vRSCVe6pjRVg9EKBz4pKL3da6KH/r3B4KILhFh5tKlJFOTuHufxiYWItGNiISLtmFiISDsmFiLSjomFiLRjYiEi7ZK43GxG5HKztKCZQelXnA9dKlJKo6INxq6mxLkW9XxhLvl/Ctdsibww3A/av45eHG7/WfRy/H89Hv2ci4TrSbP7A8B4IdYhxKSOBV8YXPNGIdYtxKSxvX1C7FOxNQakOek9wlB2S7SF3c8ZL3VLiPb+4uhmIkogJhYi0o6JhYi0Y2IhIu1iSiwulwuzZs1CdnY28vPzsXDhQrS3t4e9pq+vD06nE3l5ecjKykJlZSW8XqPJAonochJTYmlqaoLT6URLSwt2796NgYEB/PKXv0Rv7/n5YteuXYudO3eioaEBTU1N6OzsxKJFUt2AiC43KUpaiNnAyZMnkZ+fj6amJvzsZz+Dz+fD+PHjUVdXh8WLFwMAjhw5gqlTp6K5uRlz5swxPKff74fFYgHwGoCrIrxCKpNJo5cBeRypFJMKmNIy4gDwDyEmjaWVSCVui8GxUvk7ymLgALBRKMevMrik5BUh9q0QaxFKrXcYvKUfEmJGw7GjkWrjXxocK02cvlXqXpErxKTjALl0HO1nIQjga/h8PpjN8vmH9RmLz3e2Abm5Z7/AtrY2DAwMoLy8PPSa4uJi2O12NDdHnsc8EAjA7/eHbUQ0usWdWILBINasWYO5c+di2rRpAACPx4OMjAzk5OSEvdZqtcLjiTybhcvlgsViCW2FhYXxNomIkkTcicXpdOLQoUOor68fVgNqamrg8/lCm9vtHtb5iCjx4urSX1VVhXfeeQcffvghJk6cGNpvs9nQ39+P7u7usKcWr9cLmy1yV3OTyQSTyWjmNyIaTWJ6YlFKoaqqCjt27MCePXtQVFQUFi8tLUV6ejoaGxtD+9rb29HR0QGHw6GnxUSU9GJ6YnE6nairq8Nbb72F7Ozs0OcmFosFY8eOhcViwbJly1BdXY3c3FyYzWasWrUKDodjSBUhIro8xFRuTkmJXOLbtm0bHnzwQQBnO8g98sgjeOONNxAIBFBRUYHNmzdH/VPoQufLzW8DiLTAbLpw9PdGZxdi8U7PLE0HDcgl8ENCTBqJLZWpjUrY0u8SaUSs0J7HhFrrcwajbMWR40Yl02gM7sFPjkePrRAmTpfqCtIc0w/ny+1BiRC7Voh1C7FMg2tK769oH030A6gbUrk5pieWoeSgzMxMbNq0CZs2bYrl1ER0GeFYISLSjomFiLRjYiEi7ZhYiEg7JhYi0o6JhYi0G9a0CSPhfD+W/0PkldGl6Q2kcfYAcFqISR0RpCW/uw2uKc3fLrVHIvXXEaY+ACD3yZHaKt33SP2NfhBp6ouhHisN9RCmTRCPMzpW6s8kzakg9dyQpjcA5KkupN/9Up+u4dyDaCkhAGDLyE+bQEQUCRMLEWnHxEJE2jGxEJF2TCxEpB0TCxFpl8SLwo9F5GH8wrB2/IfBOb8RYlJ5TipFG5VTpYXqJwgxqRQtlZu7xdbIUxFIKyBI5WZpOlGj+9MrxKQl46VpAaQpAQBgshCbKMSktkrTY0jvAUC+79cIsTwhJq3kAMg/+tG6HUjdEcLxiYWItGNiISLtmFiISDsmFiLSjomFiLRjYiEi7ZK43JyLyKVRaYSp0UBtaUSnVJ6bJMSMRhNLs9RLo1Ol8qVUMjaaFV+6f9LXIpWbpdG7UokWkL8n8ZbccwyuKR17gxDrEmKRRuL/4JTcHLF0LpWipR9fo9HNUjeAaN02jFbBOI9PLESkHRMLEWnHxEJE2jGxEJF2MSWWF198ESUlJTCbzTCbzXA4HHj33XdD8b6+PjidTuTl5SErKwuVlZXwer3aG01EyS2mxDJx4kTU1taira0N+/fvx/z583HPPffgs88+AwCsXbsWO3fuRENDA5qamtDZ2YlFixaNSMOJKHkNezLt3NxcPP/881i8eDHGjx+Puro6LF68GABw5MgRTJ06Fc3NzZgzZ86Qznd+Mu0ORC6rSrnQaHJqqWQqxaSSqdETmVG5NRqptCeN8JbK1AAQFGJSabNbiElfY4HYGvlYqWQqLfwulX4BeSF6qfwtje6VRlRL1wPkeyCNgJe6DkiTlAPy+yRaefx7AA+M7GTag4ODqK+vR29vLxwOB9ra2jAwMIDy8vLQa4qLi2G329Hc3Bz1PIFAAH6/P2wjotEt5sRy8OBBZGVlwWQyYcWKFdixYwduvPFGeDweZGRkICcnJ+z1VqsVHk/0JRVcLhcsFktoKywsjPmLIKLkEnNiueGGG3DgwAG0trZi5cqVWLp0KQ4fPhx3A2pqauDz+UKb2y1NGkREo0HMXfozMjJw3XXXAQBKS0uxb98+/PnPf8Z9992H/v5+dHd3hz21eL1e2Gy2qOczmUwwmYy6HxPRaDLsfizBYBCBQAClpaVIT09HY2NjKNbe3o6Ojg44HI7hXoaIRpGYnlhqampw5513wm63o6enB3V1dfjggw+wa9cuWCwWLFu2DNXV1cjNzYXZbMaqVavgcDiGXBEiostDTInlxIkTeOCBB9DV1QWLxYKSkhLs2rULd9xxBwBgw4YNSE1NRWVlJQKBACoqKrB58+Y4m5Z9bruQVB03egCTyqlSCVc6LvqfeWdJt1iaZFmKDWdyb2kUt1T2lMrUOULMqNQqlT2lUb/Sn89GPSik74lUqpbKzdI1I72Pf0waHS6NgM8RYnI5WC5VT46yX3rfhUviReG/Q+SbIzXXaBZxadH4eH+QpYQEXD6JRVpMXkroTCzGiUVK2olILNH68vQAuJmLwhNRYjCxEJF2TCxEpB0TCxFpx8RCRNoxsRCRdkk8S38qYs97UnkSkBfRlspn0uzsRjOXS3FpaLtUxpa+bUaLgUvlXWmGf6lkKpVLjb4nUnultkrvDWkhdaNrGk03EI00jYPUDwoAxgsxaToPqWRsNH2GVDqP9nNidM7z+MRCRNoxsRCRdkwsRKQdEwsRacfEQkTaMbEQkXZJXG6OhzTDOhD/IuzSiFejWyjFpRKl1Fbp6zQqCUplbGmm+XjLzUalX+ma8Y5ClsrmgLyag/S79moh9qUQs8jNEeXHeZxUwgbkUnW0keNDTxd8YiEi7ZhYiEg7JhYi0o6JhYi0Y2IhIu2YWIhIu8us3GyUJ6UyrTQ5szQa1mg0sVT6lNorlXCla0plREAucUvXlCbwlkYw54itiX+RemlmeyPS90Rqj/QeuV6IGb0vpQnQpW4H0uTwRpOqG71PIjF6r5/HJxYi0o6JhYi0Y2IhIu2YWIhIu2ElltraWqSkpGDNmjWhfX19fXA6ncjLy0NWVhYqKyvh9XqH204iGkXiTiz79u3DSy+9hJKSkrD9a9euxc6dO9HQ0ICmpiZ0dnZi0aJFw24oEY0ecZWbT58+jSVLluDll1/GM888E9rv8/mwdetW1NXVYf78+QCAbdu2YerUqWhpacGcOXP0tDpuUrlZKqVJE20brRMslfWk0qY0kla65kj1IJDaKl1zpCbTlkrGRmVRqYwtjZqOt8wvlfiNjpWuKd2DxC7JHtcTi9PpxF133YXy8vKw/W1tbRgYGAjbX1xcDLvdjubm5ojnCgQC8Pv9YRsRjW4x/3qrr6/Hxx9/jH379l0U83g8yMjIQE5OTth+q9UKj8cT8Xwulwvr16+PtRlElMRiemJxu91YvXo1Xn/9dWRmGj3iDk1NTQ18Pl9oc7vdWs5LRIkTU2Jpa2vDiRMnMGPGDKSlpSEtLQ1NTU3YuHEj0tLSYLVa0d/fj+7u7rDjvF4vbDZbxHOaTCaYzeawjYhGt5j+FFqwYAEOHjwYtu+hhx5CcXExHn/8cRQWFiI9PR2NjY2orKwEALS3t6OjowMOh0Nfq4koqcWUWLKzszFt2rSwfePGjUNeXl5o/7Jly1BdXY3c3FyYzWasWrUKDocjCSpCRHSpaK9NbtiwAampqaisrEQgEEBFRQU2b96s+zJElMRSlFKJLXhfwO/3w2Kx4Oxi2Jfy85ahL3gdTpr1HpBnoe8VYtK3ZTjfMqm90nlHYjZ9QP6YT2qP9N4w6scitTfe6SqSjdF7xGhFi0j8ACzw+XyGn4VyrBARacfEQkTaMbEQkXZMLESkHRMLEWnHxEJE2l1ms/QPR7ylRGkWdUAu+0kLrcdbUjYaoi/N3n5GiEntkUrKRguiS1MYSCVRaaqB4fy+HE0lZUk85WR9+MRCRNoxsRCRdkwsRKQdEwsRacfEQkTaMbEQkXYsNw+b0S2UyrTSSFqJVEo0+l0R76zvvjjPadSeeGeop2TGJxYi0o6JhYi0Y2IhIu2YWIhIOyYWItKOiYWItGO5ecQZjX6ORhr1K33bjK4nlaqlCcXHCbHTcV4PAC5eqvc8qT3SOlX8fZlo/A4QkXZMLESkHRMLEWnHxEJE2sWUWJ566imkpKSEbcXFxaF4X18fnE4n8vLykJWVhcrKSni9Xu2NJqLkFvMTy0033YSurq7Q9tFHH4Via9euxc6dO9HQ0ICmpiZ0dnZi0aJFWhtMRMkv5nJzWloabDbbRft9Ph+2bt2Kuro6zJ8/HwCwbds2TJ06FS0tLZgzZ87wW3tFibcnwHAmUZZGE0uTdEsjlI3MEmLxluop0WJ+Yjl69CgKCgpw7bXXYsmSJejo6AAAtLW1YWBgAOXl5aHXFhcXw263o7m5WV+LiSjpxfRrsaysDNu3b8cNN9yArq4urF+/Hj/96U9x6NAheDweZGRkICcnJ+wYq9UKj8cT9ZyBQACBwPnfhn6/P7avgIiSTkyJ5c477wz9u6SkBGVlZZg0aRL+/ve/Y+xYaZKg6FwuF9avXx/XsUSUnIZVbs7JycH111+PY8eOwWazob+/H93d3WGv8Xq9ET+T+UFNTQ18Pl9oc7vdw2kSESWBYSWW06dP48svv8SECRNQWlqK9PR0NDY2huLt7e3o6OiAwxF9XIfJZILZbA7biGh0i+lPoUcffRR33303Jk2ahM7OTjz55JMYM2YM7r//flgsFixbtgzV1dXIzc2F2WzGqlWr4HA4WBEiusLElFi+/vpr3H///fjmm28wfvx4zJs3Dy0tLRg/fjwAYMOGDUhNTUVlZSUCgQAqKiqwefPmEWk4ESWvFKVUvKuPjwi/3w+LxYKzs8LzzyKi5OEHYIHP5zP8yIJjhYhIOyYWItKOiYWItGNiISLtmFiISDsmFiLSjomFiLRjYiEi7ZhYiEg7JhYi0o6JhYi0Y2IhIu2YWIhIOyYWItKOiYWItGNiISLtmFiISDsmFiLSjomFiLRjYiEi7eJdeZyItNktxO4VYt2a26EPn1iISDsmFiLSjomFiLRjYiEi7ZhYiEi7mBPLv/71L/zud79DXl4exo4di5tvvhn79+8PxZVSWLduHSZMmICxY8eivLwcR48e1dpoIkpuMSWW7777DnPnzkV6ejreffddHD58GH/6059w9dVXh17z3HPPYePGjdiyZQtaW1sxbtw4VFRUoK+vT3vjiShJqRg8/vjjat68eVHjwWBQ2Ww29fzzz4f2dXd3K5PJpN54440hXcPn8ykACvApQHHjdoVvJ4TtUrfl7M+mz+cz/DmO6Ynl7bffxsyZM3HvvfciPz8f06dPx8svvxyKHz9+HB6PB+Xl5aF9FosFZWVlaG5ujnjOQCAAv98fthHR6BZTYvnqq6/w4osvYsqUKdi1axdWrlyJP/zhD3j11VcBAB6PBwBgtVrDjrNaraHYhVwuFywWS2grLCyM5+sgoiQSU2IJBoOYMWMGnn32WUyfPh3Lly/Hww8/jC1btsTdgJqaGvh8vtDmdrvjPhcRJYeYEsuECRNw4403hu2bOnUqOjo6AAA2mw0A4PV6w17j9XpDsQuZTCaYzeawjYhGt5gSy9y5c9He3h6274svvsCkSZMAAEVFRbDZbGhsbAzF/X4/Wltb4XA4NDSXiEaFIZVqztm7d69KS0tTf/zjH9XRo0fV66+/rq666ir12muvhV5TW1urcnJy1FtvvaU+/fRTdc8996iioiJ15swZVoW4cYt5G51VIcSSWJRSaufOnWratGnKZDKp4uJi9de//jUsHgwG1RNPPKGsVqsymUxqwYIFqr29fcjnZ2Lhxi1Zt6EnlhSllErsM1M4v98Pi8UCwAeAn7cQJQ8/AAt8Pp/hZ6EcK0RE2jGxEJF2TCxEpB0TCxFpl3STaZ//LJljhoiSy9mfyaHUe5IusfT09Jz7F8cMESWjnp6ec5Xb6JKu3BwMBtHZ2QmlFOx2O9xuN7v5R+D3+1FYWMj7I+A9ksV6f5RS6OnpQUFBAVJT5U9Rku6JJTU1FRMnTgxNn8DxQzLeH2O8R7JY7o/Rk8oP+OEtEWnHxEJE2iVtYjGZTHjyySdhMpkS3ZSkxPtjjPdINpL3J+k+vCWi0S9pn1iIaPRiYiEi7ZhYiEg7JhYi0i5pE8umTZswefJkZGZmoqysDHv37k10kxLC5XJh1qxZyM7ORn5+PhYuXHjRvMN9fX1wOp3Iy8tDVlYWKisrL5rQ/EpQW1uLlJQUrFmzJrSP9yZByyIPec7IS6i+vl5lZGSoV155RX322Wfq4YcfVjk5Ocrr9Sa6aZdcRUWF2rZtmzp06JA6cOCA+tWvfqXsdrs6ffp06DUrVqxQhYWFqrGxUe3fv1/NmTNH3XbbbQls9aW3d+9eNXnyZFVSUqJWr14d2n+l35tvv/1WTZo0ST344IOqtbVVffXVV2rXrl3q2LFjodfU1tYqi8Wi3nzzTfXJJ5+oX//61zHNUx1JUiaW2bNnK6fTGfr/4OCgKigoUC6XK4GtSg4nTpxQAFRTU5NS6uwStunp6aqhoSH0ms8//1wBUM3NzYlq5iXV09OjpkyZonbv3q1+/vOfhxIL782lWRY5kqT7U6i/vx9tbW1hy7SmpqaivLw86jKtVxKfzwcAyM3NBQC0tbVhYGAg7H4VFxfDbrdfMffL6XTirrvuCrsHAO8NMDLLIg9F0iWWU6dOYXBwMKZlWq8UwWAQa9aswdy5czFt2jQAZ5e1zcjIQE5OTthrr5T7VV9fj48//hgul+ui2JV+b4CRWRZ5KJJudDNF53Q6cejQIXz00UeJbkpScLvdWL16NXbv3o3MzMxENycpBYNBzJw5E88++ywAYPr06Th06BC2bNmCpUuXjth1k+6J5ZprrsGYMWNiWqb1SlBVVYV33nkH77//PiZOnBjab7PZ0N/fj+7u7rDXXwn3q62tDSdOnMCMGTOQlpaGtLQ0NDU1YePGjUhLS4PVar1i780PRmJZ5KFIusSSkZGB0tLSsGVag8EgGhsbr8hlWpVSqKqqwo4dO7Bnzx4UFRWFxUtLS5Genh52v9rb29HR0XHZ368FCxbg4MGDOHDgQGibOXMmlixZEvr3lXpvfpCwZZHj/th3BNXX1yuTyaS2b9+uDh8+rJYvX65ycnKUx+NJdNMuuZUrVyqLxaI++OAD1dXVFdq+//770GtWrFih7Ha72rNnj9q/f79yOBzK4XAksNWJ8+OqkFK8N5diWeRIkjKxKKXUX/7yF2W321VGRoaaPXu2amlpSXSTEgJAxG3btm2h15w5c0b9/ve/V1dffbW66qqr1G9+8xvV1dWVuEYn0IWJhfdm5JdFjoTTJhCRdkn3GQsRjX5MLESkHRMLEWnHxEJE2jGxEJF2TCxEpB0TCxFpx8RCRNoxsRCRdkwsRKQdEwsRacfEQkTa/T9Tvs68uLwqGAAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "b-zq1HgoMSH1"
      },
      "outputs": [],
      "source": [
        "# @title autoencoder down\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        d_list=[64, 512, 4096]\n",
        "        # r_list=[(360,640), (240,426), (144,256)] # https://en.wikipedia.org/wiki/Low-definition_television\n",
        "        self.enc = nn.Sequential( # nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0), nn.ReLU(), nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.AdaptiveMaxPool2d(1), # AdaptiveAvgPool2d AdaptiveMaxPool2d\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear()\n",
        "        )\n",
        "\n",
        "        self.deconv = nn.Sequential( # 'nearest', 'linear', 'bilinear', 'bicubic', 'trilinear'. # https://pytorch.org/docs/stable/generated/torch.nn.Upsample.html\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),\n",
        "            nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1), nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x\n",
        "\n",
        "    def encode(self, x): return self.enc(x).squeeze()\n",
        "    def decode(self, x): return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    # def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder().to(device)\n",
        "print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "print(out.shape)\n",
        "i2= model.decode(out)\n",
        "print(i2.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6S7-iCGE13Yb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch_xla\n",
        "import torch_xla.core.xla_model as xm\n",
        "# https://pytorch.org/xla/release/2.3/index.html\n",
        "# https://github.com/pytorch/xla\n",
        "\n",
        "xm.xla_device()\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "xm.mark_step()\n",
        "xm.optimizer_step(optimizer)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIlxDkaGuRW3"
      },
      "source": [
        "### trash"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "YciLCug9_2pN"
      },
      "outputs": [],
      "source": [
        "# @title vit\n",
        "# https://arxiv.org/pdf/2010.11929.pdf\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "# https://pytorch.org/vision/main/models/vision_transformer.html\n",
        "# https://pytorch.org/vision/main/models/generated/torchvision.models.vit_b_16.html#torchvision.models.vit_b_16\n",
        "# model = models.vit_l_16(weights='DEFAULT') # small vit_b_16 vit_b_32 vit_l_16 vit_l_32 vit_h_14 big\n",
        "# # VisionTransformer(image_size, patch_size, num_layers, num_heads, hidden_dim, mlp_dim)\n",
        "# num_ftrs = model.heads.head.in_features\n",
        "# # num_ftrs = model.heads[-1].in_features\n",
        "# model.heads = nn.Sequential(\n",
        "#     # nn.Dropout(0.2),\n",
        "#     nn.Linear(num_ftrs, 6, bias=False),\n",
        "#     nn.Softmax(dim=1),\n",
        "#     )\n",
        "\n",
        "\n",
        "!pip install timm\n",
        "# https://github.com/huggingface/pytorch-image-models/issues/908\n",
        "import timm\n",
        "# model = timm.create_model('vit_base_patch16_224', pretrained=True)\n",
        "model = timm.create_model('vit_base_patch16_224', img_size=(400, 640), pretrained=True)\n",
        "# [print(x) for x in timm.list_models('vit*',pretrained=True)]\n",
        "# https://huggingface.co/google/vit-base-patch16-224\n",
        "# https://github.com/huggingface/pytorch-image-models/blob/main/timm/models/vision_transformer.py\n",
        "# vit_base_patch16_224 compile,no ckpt # patch_size=16, embed_dim=768, depth=12, num_heads=12\n",
        "# vit_base_patch16_384\n",
        "# vit_large_patch16_224 explodesgpu # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "# vit_large_patch16_384 # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "\n",
        "# or fine tune huge\n",
        "# vit_large_patch14_224 # patch_size=16, embed_dim=1024, depth=24, num_heads=16\n",
        "# vit_large_patch16_384\n",
        "\n",
        "\n",
        "num_ftrs = model.head.in_features\n",
        "model.head = nn.Sequential(\n",
        "    nn.Linear(num_ftrs, 6, bias=False),\n",
        "    nn.Softmax(dim=1),\n",
        "    )\n",
        "# model.set_grad_checkpointing()\n",
        "\n",
        "# print(model.patch_embed.grid_size) # (25, 40)\n",
        "# print(model.pos_embed.shape) # [1, 1001, 768]\n",
        "# https://github.com/rwightman/pytorch-image-models/blob/master/timm/models/vision_transformer.py\n",
        "\n",
        "# print(model)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "# model = model.to(device)\n",
        "model = torch.compile(model.to(device))\n",
        "# model = torch.compile(model.to(device),mode='reduce-overhead')\n",
        "# model = torch.compile(model.to(device),mode='max-autotune')\n",
        "\n",
        "# vit_base_patch16_224 batch16 maxcompile nockpt gradacc lr1e-5,1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "NT1oOipu8IwG",
        "outputId": "f6d0b434-08e3-4c3a-b18e-3f89a46a1ff9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARYAAAEWCAYAAACjTbhPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAxhElEQVR4nO2df3Ac1ZXvvzOSZvRbY8m2ZGELm8VgiOMQbLAV2PAStPEjvCzGJkvqJQWkqGwBwmBMqrKq2kBctbtyweaFhbVD2GIh9YJx1lULrKllHSKCeeTJNhbPCeaHMODECrLkH3hGv2ekmfv+MEyf+x1Na0ZqeUb2+VS1qu/cnu7bt3uO7vlxz/UZYwwURVE8xJ/rBiiKcvahgkVRFM9RwaIoiueoYFEUxXNUsCiK4jkqWBRF8RwVLIqieI4KFkVRPEcFi6IonqOCRVEUz5k2wbJlyxYsXLgQxcXFWLlyJfbt2zddl1IUJc/wTcdcoV/+8pe45ZZb8Pjjj2PlypV45JFHsGPHDnR2dmLu3Lmu300kEuju7kZFRQV8Pp/XTVMUZZIYY9Df34/6+nr4/ROMScw0cOWVV5rm5uZkOR6Pm/r6etPa2jrhd7u6ugwA3XTTLU+3rq6uCX/HhfCYWCyGjo4OtLS0JD/z+/1oampCe3t7yvHRaBTRaDRZNp8OoGaVAP5PByxjMef4+Jj9fTmmMTTAGTR2mYozC/EPooCemuyTAN3k6CT7gMeKZQV2eSCe/li38xTSB3K8nKBj6ZIIiO+WBuy6hGjPIL0jo3Qeqs4Y/h9dIfb5hySagwjVpTwDX5p9AMXF6b8c5Sp5Y3zTHlJRUTHhMZ7bWE6cOIF4PI7a2lrr89raWvT09KQc39raiqqqquTW0NBwumE+Z/PJDS7bBMfOKFxuhqvc6ibbBxP1bTbXdH1GmX6Pvuv3+dJu0/UeuLXNT1s2feB2sGt/uZ1nGsnERJFzr1BLSwsikUhy6+rqynWTFEWZIp6rQrNnz0ZBQQF6e3utz3t7e1FXV5dyfDAYRDAYTPn85BAcyZvh+N1HY+msBLc4uIiuV1xklwvFGH2Irlkct8tydBqgBvn9zgfDdJNDcT5WnJP7Q5w36tF/Kz+dJ8YHiPoE6zAuxLM4llWWUfHdMeqEqOgvdkdMlwo8KPbpFcGI2E+5ZW6QSwOHB9PXZQO3L+FSJ/u9oszZNwYID2V2Pc9HLIFAAMuXL0dbW1vys0Qigba2NjQ2Nnp9OUVR8hDPRywAsHHjRtx6661YsWIFrrzySjzyyCMYHBzEd7/73em4nKIoeca0CJabb74Zx48fxwMPPICenh5cdtll+K//+q8Ug64rJXCG28Pic5dhYxYjzFRET4ySGjBaQAM7OY6M2wdHWS8Q4/LBFOVMnJerCuwPEvJuDA+uzbi7KW3NAlZDxrh9OXCxyVsZ5uvLR0TupJSulXWsnkrXIulUJuGjY2W/04m8Cg9jncLlPiU++mXza+kXD5jVZ9nyU5NUraclQG4q9PX1oaqqalKCZUpIRTPlTXQRLPyLcxEsqSfOXLDAJ8/jcg3uH7LVTJo8ECwWLj+qXAgWPwmWEVE3Sdn+6YldylkIFr+LYOFX2LrrAFUMApFIBJWVlekvjjzwCimKcvahgkVRFM+ZFhuLJwxPfIinuEYqug1muQtt512BGEuW0tC1oNCR62H2IaeoVKKc8tRE4/1kHWHdXwx02aVcJMp++p9TUJje5kNmJowlnDpD9+Wj23RzP5ezmiL6r6LIruwX5xmmc47F7YuOWfUu6inpe0XUJ1FRb1J0Q3led71Rdu0YHctzcmSEMeI0LjBOpYna52GN2CpTFHNA9HNCNM4Yk7FmrSMWRVE8RwWLoiiek7eqUGFxcXJOgl+Ml/2jpLMYRzamRGqmDNzk8HRKtnqX89jXlM6dBB3rF2Z9VjXiPESXRT+rTU65gL5XyMeK5rG2NSbUpjjf1wjOOAOsQYgH3JfVTML06mA5/W8NimMH6VnGSE1JVX/SXdNdFUqJpBbwOyM1bX+RrVtLtSnlFeE2iNmpBRQSPirep4T0hJnknwnREYuiKJ6jgkVRFM9RwaIoiufkrY1lbOSzrBaAZRhIyQXh4oYtcotr5vBM3/j7AEDuSrhEZ/KxMb/jy4v5yDBgTQ2wv1debuvWPqHbBhP2saUxp39mketwjLIB/VF05QCY3IbTsju3mlytRSWOgeGYsW1tMdF0fnzFAfs8lcK+MDpm21EGRH8lqD0J9staqZbSTyjh/96z6NU7KZrgp7oE25Ism53dB4mUKeiZMRZN/9zLReYwY+wZ3W7oiEVRFM9RwaIoiueoYFEUxXPy1saColLA96nciwld1nCsv0ytRgrpmFveLFu3LhHnGaY6P5Vt6wdPMWX7jGyTmxy3zxoftI8tFbpuMWXMjhQ714yRzWCkgMLZZWtSUg/ImH77+j62IYhwcj/NDSgSNqhKv/2KVRTadgq/r1js288rQQaGQtGEIuqDo8OOvWEkZhuWhkft8wzLvmajhkwXyOkpojxFWGS6TjFwOM+BI51OusTFJyaKmZe3Pdms4ADkIjxlJfbzCxQ5z7ZYpEuMG4ODpzLL0q0jFkVRPEcFi6IonpO3qlCZGYbvU7VChqWHE+xulmNHHnTyyity2GuPOYddzuMe/D/ReHRy49VhGhIPSw3QZeZ3ZFJXO02BcGPPSpl+YCPD3Tmbm0x6PUQu0Z6YfWM+19nEFFLvF+eK0ZB8TJZ5YaFspm84cxd8tKZPilM2x8muKumhyLWfEuRzH6WwiKj4HY2Qu7lYdGVViZjFnkVOOB2xKIriOSpYFEXxHBUsiqJ4Tt7aWIYL48m0CZXCZVrms916AaE+99NCxbPJ2xwXq1pxaLI86xS8eFkhO5+9jCzx3Sbhu3ko+QEXCz28gDytIqFdykJsbPOx2uBmwghQZdzOv1BW7ZyYI8sTw5w6QjQixr3gVRoMBzNRqogc2FisNbTp+mHx4nKaBM4WKO0l7CjvEz7vY/2Ty8auIxZFUTxHBYuiKJ6Tt6pQwh9NTlMdFNmPaSRtJTbjFaB72Nvsii/NPlIyQPuEK6+E1hyKF9rHlhTILqYEx8YZ18YoynSM0ruNSTUvwWPw9GNyVusGrGTMdl1Zmn0AIM8rwmLfVQmhcXbKUjgiknN2mf06hspsXXZ4xOlrQ1OEY2L4Pjhku6KHY3YLR2XKNkP/W/3imkF6gSaZ4L2AfmXzS+33Syb3jtK7Nuqz2+cXoRf8evtFXxfSO+JjVVa8GBR4awUcTzZxoI5YFEXxnKwFy2uvvYZvfOMbqK+vh8/nw/PPP2/VG2PwwAMPYN68eSgpKUFTUxMOHTrkVXsVRZkBZC1YBgcH8YUvfAFbtmwZt/6hhx7Co48+iscffxx79+5FWVkZVq9ejZGRHGRjVhQlJ0xp7Wafz4fnnnsOa9asAXB6tFJfX4/7778f3//+9wGcXue1trYWTz/9NL71rW9NeM7P1m72oSAZ0p+wNHOXBdFTNPisjCyToiolK75drihzZLeP12MWDJON5RTp8/IpFZAePizCswtoynKKs1D8K5lFmdUCCccYMEru3NFR+0z9k3bvUh+UiDZQe3xBeyZ0kfCBc7a5YeEPN3HbxlJNi8jJs/rJJnY06FiTEoMUlBCktlv+8TMVpODgp3AKyxxDD56flrUENL2XpQH5zgq7ljEIR8bO/NrNhw8fRk9PD5qampKfVVVVYeXKlWhvbx/3O9FoFH19fdamKMrMxlPB0tPTAwCora21Pq+trU3WMa2traiqqkpuCxYs8LJJiqLkgJx7hVpaWhCJRJJbV1dXrpukKMoU8TSOpa6uDgDQ29uLefPmJT/v7e3FZZddNu53gsEggkGOQAEqKpyVEPvFlPjioG1HGZIhx6zm+um8Ce9tLhGOIaH4gT6xWjmFZVgZ3MicgCrSkX1CSebbLBRtIFMIOIeeTJjm99mad3GBEwgRojejkBc8EI1gs3xUXDRGZq+BfrLdxJ0Gxwep8VH7TguEDW3QRx2WSB+gc5INDiVinwN0isQ7wp0XRl6RyCyZ2/jfFfs+WoqxQGQhjAeE7SoLa6ynI5ZFixahrq4ObW1tyc/6+vqwd+9eNDY2enkpRVHymKxHLAMDA/jggw+S5cOHD+PAgQOorq5GQ0MDNmzYgL/7u7/D4sWLsWjRIvzwhz9EfX190nOkKMrZT9bu5ldffRVf+cpXUj6/9dZb8fTTT8MYgwcffBBPPPEEwuEwrr76amzduhUXXXRRRuf/zN2cMXJEXEF15B2U6gYP1WJhZz8+lPnlp4Js+jyqq6VypRiW99EQOCY0vhH6V0HaBD4RYd8Rl7XfsiLkch63JH6AHfLPddweWWY1Rb7FPF03x5neeHpEJaV+Kwg4N94/Zj+UYUqOLm+Ff7pjUqWZaFKyVNnpxxAUIRPRlFnkyMjdPKU4lulABctpVLCM0x4VLDNGsOTcK6QoytmHChZFUTwnb9MmnB7rfjokk6nO4iQL5VCxn8b9lbTQmEgnP4fUgDlCnSig4XuYhpXSveqWiQ4ApFbFg0p57B+p7mMqy2T3pVQVEu2NUtvL6VipQdRRg2LCDTvIa3UZelVioq/D8IZsouL5zZWRBRXUQzGaHyEXGvPTw5UpFgwpqIMDdFFHmQ0GKQt+3Hm6gxXk1i+1wyASQmePF9oPsIBSPgREiMAY6TuzxDUTtDJBIb2YcVF9gp+1B7qjjlgURfEcFSyKoniOChZFUTwnj93NIaT4iwGME7cv9jnGmS0e3k9tr6YyzThAtUhj2U8pDaKi6aV0r0EyEwyJKfq0xjn6hVrO2RMnl2M9E2R7KbxeXrXIrquppPssdKw+80vsY2cX2//39oed8mjAPnZI9MkY9eVsWrB9JO4cHORwdvG8esiuVE7Pr18aKsY4BkBONaGfGKUztZpLaRxAKxqiQBpE7KdbH3UsfpVkJymm5snFE07RJbrFV8ezEaq7WVGUnKCCRVEUz8lbVWhuaBH8n6bEGhRDyf6UTOnOMDcYsF11fr9dXup3hooJmoU8HHfKg7Ry1p94zS3XOzgT2PqWXDx9orZJR2dBqR2+WjzXKccD9jWGC23VYyQmxs88NVuubjZE/m92/Yrsd4jyKmk0fvfNFo21w6MfGXaeLSvQ6fP2AffwB37xv7aQ9Fpe4S0kypTVDyfkAvbcArfl6Hiu+PT8POeIff5JsVOdUVVIUZScoIJFURTPUcGiKIrn5K2NBRcsS6Y7KxPZwnwFtg5aKDKMjxbZbsWhETsxtzn2iVOIkTVCLhFYRP5c9mJLL2Q16d2f0Hkz9XDzbF324MrLcJy+2xNko8spsc+qf8oyhQIOoa8RYfF8ngHxjDg3+hSS+P0Mzqz32WL/dBOcDjwPi6w64wvTsTIrmn1jq+DkGvqx1Vmpr8HfFIsbL6aHEHXq/DRDuJT+nxcUOralYT+t8MjvqVt0xRlCbSyKouQEFSyKonhO/s5uLvo8UHBaHxgsEkNOSgCNEuEcK/jErhspsQ+tcobo8WF7eFpU4nRFPGy7MkeD9nB0rlBTaimq8kiR3b5+MV4d5QhMSYJkPJ2nSnz1/EH7PJUi/Nd/wj7NR6SK/clt+CxH4RP5rfvP/MqWtaJR/44jVt1aoR8ehf0e1Bv7PbAzRtk3ukeUf03f4hnoK0ac57A/RumcCp13NkGrrg+UcmYl0Z4h+4GVVtrvwZC4JkbsOr+Y0ZxIZJ61i4WAjCaXPWmQeaiFjlgURfEcFSyKoniOChZFUTwnb93NJwqBzybCblvo1N/WT18ovcXZH/zQriug4OTjor6M9G4jZGwRaZKFZJgok65pks0nyL8aEfu5cA+yK1g+7RC1fUBMqebw9QKaKV4gThQje4tYXD5lKjavEFYmDFazyOdeYZeff3f8ZXqZEOXYK03x3cs28evvlPdgKE3NaaQV474aSn8uu8RQP5eT/UO4m1NWnPNRwL1Y+b2A7CiFUeFGj9rnidMUloCYmV1caL8kVT7n2cuF5hPG4I8jcXU3K4qSG1SwKIriOSpYFEXxnLy1sYQBjKfFve/y3SUpse6cQz+vbtUdFvnSNEFmC78IoUhR38m8MCZMQENBqpPnZXvQGbAPNdTaDfrSInsFuhWiERfuiVh19a5ntu1FPaJz/+ZrdhTHOyOOLenR19yjNu5ZKGw5x8kGNSKuWU7vXSE9pH7RhjGyM/nIfiVTwY3aba8OiAfIM014KsUUwpA8t7G0trbiiiuuQEVFBebOnYs1a9ags7PTOmZkZATNzc2oqalBeXk51q1bh97e3uxbryjKjCUrwbJ79240Nzdjz549ePnllzE6Ooqvfe1rGBx0Rgb33Xcfdu7ciR07dmD37t3o7u7G2rVrPW+4oij5y5RUoePHj2Pu3LnYvXs3vvzlLyMSiWDOnDnYtm0bbrrpJgDAe++9h0suuQTt7e1YtWrVhOccTxWSg8ztVy+1ji8scsZ4iRJ7ONpzwnY37zvluA9f+5PtxjuWkpnOe3ihsblinweWfKyEM3ydSLMPeJc+nJzEltLJdYVpjgNSVZYLxI2Xltnj9yHK4HZCJMX+ZJb9P7FbLOz1Pmklj/wBabmHGyQvyZnxxihs/5RowwAt+F0gvsvR9eTeRVSoNynTDyJIT+b6KT+HkNhnrUgGTHA6euAMzG6ORE7fdHX16dkFHR0dGB0dRVNTU/KYJUuWoKGhAe3t7eOeIxqNoq+vz9oURZnZTFqwJBIJbNiwAVdddRWWLj09iujp6UEgEEAoFLKOra2tRU/P+MFNra2tqKqqSm4LFiyYbJMURckTJi1YmpubcfDgQWzfvn1KDWhpaUEkEkluXV1dUzqfoii5Z1JpE+6++268+OKLeO211zB//vzk53V1dYjFYgiHw9aopbe3F3V1deOeKxgMIhgMpnwewueRVHiLZzkV79su5ILznOssDJ+06maX2zr6mPDFlp1vy9RZYgr6qQgZXMLUODerFN+KcPMNkeGkV3gW/0iqNEeBp+jpmeKWop6NIyIJPjdghFYOH5mku/IgfyCnaPSxe9fF3fsxdUiB6MyA7bK9J0APLCFsJUfpWRtxY76Fdp2PFomX8e5xmmtSKN7TIjvbHQJkqykT9xIlq9ig/U6j3rFthPz2b+FrI46F7cLRsFU3O27/1IVXHQOl9kvy/qDTB3vEC5QwBt2j41ldUslqxGKMwd13343nnnsOr7zyChYtslMALl++HEVFRWhra0t+1tnZiSNHjqCxsTGbSymKMoPJasTS3NyMbdu24YUXXkBFRUXSblJVVYWSkhJUVVXh9ttvx8aNG1FdXY3KykqsX78ejY2NGXmEFEU5O8jK3ezjdWQ/5amnnsJtt90G4HSA3P33349nn30W0WgUq1evxtatW9OqQoyzdvNsOAMqOTykNlQI3SNlEutxugExRB6joXRCuO6GvFySTMpuPm82nn6pY7EzOuTsVtB9BWioP1v031DYrhsVehurOtx0+Uh4dJyTFd3cnNwhl+/xSyPPM8+lDgCka9jWgTtrfukU6JFcVGOXY5eKs3x4h32etx+3yl++5lvJ/WtG7eCCxX1OIGptxFahCkjFOjLoPKRfJWw17v8Nu6s7mbibsxqxZCKDiouLsWXLFmzZsiWbUyuKchahkxAVRfEcFSyKonhO3s5uhm+2485LSIU/3yNzbe2yStiE6sg+ND/k+HvrRm1dv67Kntk72++4LIvLyHU44tiHRv74u4xbeqLE9uoFioVuPWQbBooDdjnkc64ZqrL/PxX7HX1+JEah9yH7dXtTrEbw+kl7ssKpj8lYExL7vLiaPC1Huqesci5sVCmvv3wOF1LdQio7z6Fz3i/tKpNmH8BFc+2ytSo7mcTe/xhpufgL19sfFBxN7vr67XiwC4ZpJnTYedbVAfsZhcTUiZJypz9iiQS2dZ/UDHKKouQGFSyKoniOChZFUTwnf20soXLgs7iZU1JJzkFziyjWoUCEaPsp1mEOxckXXeDsc9OHxH3FGuy6OE2fH3NsLg8O/ChtU7NhE75JnxxwdtmGwWFIhWJSaYKMGGLZxhIyk1xabtuZ6sRUhkK/3UFjtAJCOOR8952gXXfqE3GhMAWOxOlmTohjOcmgZchZSnXnUZnnRDh0zvt5cv8i6rv3aT7uRSLBv+/AXfZ55my1yhcf/44oUZyWlWLhsF1VQu9wmUjzwFnqTopOCYi+MwaIJtTGoihKblDBoiiK5+SvKpQOHn3K8GiOI+bQ8j+JfZ6dIF2AcfIHls+3y0Exdh2jFGQlNESUahQN32UU+IO7W62qTX+1zT424KhGT/7iRqvqcmTOfJc6mUD0/1z3V3blKcpN1yeG2l3kE+133JWPTdCeX4n9nRMcmzE8SudnXSVeol56/WU2t5SpE4upLF8+SoItphVE1+2gayBtOdh7p113vNsuy9nXvCBfrwjbLz9q14XtsP0isRhbKXVQQP5wgo4KnjAGJ2OnVBVSFCU3qGBRFMVzVLAoiuI5eWxjmQ9H7skM6ByfPdmVl0jx9sn0C+RmLCQ7SpFwBReQm7i+2i7XiDItNv/gy7Zr0Y01GR/pjpuNRTKncZP9QWXYLo9+mNxt/M0Bq+p/GhlOnvnrtX6CemmvmehYV+S/U7aJFYr3IGFPq8AQua0Twr1bTe+TX9hnisn4FyAbngxf4AyE/fTBybCoY3eztKP8kerY0JTpc5FtNwB0UXhFUXKEChZFUTxnUsm0zwxFcOSeHMZ5lZ6MhrlGlKOUQSvK4ZlSHh+zq05y1mvnXEE8mHHr1qQ9S2rOs8nyDpUvlYX2t626F87/M/vgUeFenWWrf/XF4kz9pLr288pwTl++QWrtHryFdLAbOyvVSD6iQbfZ8qxquHDSrZLVkCNUlk80NMGF5JsQpjqZOY8SdqeoPvKatNia9X7L+A4D9wXUxj+DoiiKJ6hgURTFc1SwKIriOXlsY/kYjm7KMdCTReqVpIOGhH5aPseu43JCnGeAdNcTJKtjjk4axXXUnpfStpT5z4yPtFnjUnepSx3r78f6O63y65/8e3J/7YKrrLpucyq5X38e9V0/uWw/liH09uu4ilq4J8Uq5GC5otmn/ifkAH+a/YnKYapzs++x7UZ+l22RfE3x3hbTdIRy8VtIiONMAjiFjNARi6IonqOCRVEUz1HBoiiK5+SxjWU+nDRmIvbhQorimCvsL9UUf1JNxxYLH/wY+eNjYWd/hPz6AzR1/ZjQbU+Q/Se2wC5DLGifhRx/nsprXI6Vrf1V2qOy5L/b9oy579m2pLWV0layl74s+qeE4l+KOfN+FlMyPhr/Eikspdf6arIhFIvn4Kd3ZkzEbQzQAu0nyZ52TLQ9TG3oE8Eyg5xSgWN5uOwGx0lN9nvimiPUmSPSriNTmGQ+PSOrEctPf/pTLFu2DJWVlaisrERjYyNeeskxQI6MjKC5uRk1NTUoLy/HunXr0Nvb63JGRVHORrISLPPnz8fmzZvR0dGB/fv346tf/SpuuOEGvP326SjN++67Dzt37sSOHTuwe/dudHd3Y+3atROcVVGUs40pz26urq7Gww8/jJtuuglz5szBtm3bcNNNNwEA3nvvPVxyySVob2/HqlWrMjqfs2DZxYDv0+F2ucy4TEM6kWAZlRSmP0YqzTEx7D3GQ3B53llUx4uMSzXhYqpzWzickUNkWik8JSTb+R/wJJ61arzKIDfHpY51jxcWXitKdlh8fbXIsJcy+5yH5M55r3hzt1XzWCnrO1K1tbO7rR+iqRX5BE8EptcUZeI9KCVVkfugWPRBIalQAfHu+ckM4Kd+l69pgurGxLsYEweOJYBffzy9s5vj8Ti2b9+OwcFBNDY2oqOjA6Ojo2hqakoes2TJEjQ0NKC9vT3teaLRKPr6+qxNUZSZTdaC5a233kJ5eTmCwSDuuOMOPPfcc7j00kvR09ODQCCAUChkHV9bW4uenp7xTwagtbUVVVVVyW3BAjZ+Kooy08hasFx88cU4cOAA9u7dizvvvBO33nor3nknfUTkRLS0tCASiSS3rq6uib+kKEpek7W7ORAI4MILTy+WvXz5crzxxhv4p3/6J9x8882IxWIIh8PWqKW3txd1dbzalUMwGEQwyGmzAJhhwHwq9/rk1G1yD34idFA/6ZwJchdatgBeOVzaQjgc2s5wLifT/xp2qPt79M1N+JLLeaXLlpMhsH3BcWvzpHsuu/G/xH5/SlC/2z8I2xR3wx9+nf7QPzi7j5UuoUq+L/kK2s9kPc/mt559ykrvk4T/t07WnesCa/cp2j6/i27I3wr3ZcjlImyzk+/iJ1QnM/zL/pkmd/N4JBIJRKNRLF++HEVFRWhra0vWdXZ24siRI2hsbJzqZRRFmUFkNWJpaWnBddddh4aGBvT392Pbtm149dVXsWvXLlRVVeH222/Hxo0bUV1djcrKSqxfvx6NjY0Ze4QURTk7yEqwHDt2DLfccguOHj2KqqoqLFu2DLt27cJf/MVfAAB+8pOfwO/3Y926dYhGo1i9ejW2bt06wVnTkekAX7jqEjzcYxVLOlRDVCddzLZT9jieSXt1HuhzeQ3+b3L/earbhJtEKWVhZyo7qtAm/Deqcxu+8yOWw2e+hlTHuD08uOVoUokztF8/xMphvuGV6sOqbGzcoyaEvbg8sT8YTn+sEc8zpTm8uJnY5/UBZdNLQ85+wgDHM5venJVgefLJJ13ri4uLsWXLFmzZsiWb0yqKcpahkxAVRfEcFSyKonhO/s5u/tuvO5mtuoX7631yKR8U6dF7OFU6LR7m6i6TMzozd+A+P0G9e+CzDENPH8J/Gqk0s32jwKWOkQp0+oz5Ey8E51VWv2wQUysCdJ/zxas8l8IMKsneUSb6K0jnKRT9HCeX7RBnBxTXGaBrDIvzhovtulE6j1y54BSdx5CdUHZ7H78j8j1g2xFl7pPP+iTXCTtcv3zvMrdH6YhFURTPUcGiKIrnqGBRFMVz8tfG8uMSwPepnloecj4fs6fLo0/aTThuhXRby07hJlPtKfhzKDXCcQrjd+N+y8rCOuoel/a4xZHwfcnHyPoyH0v9ZyEDGvg4jnnJIvNbxpCdqZpsZCHRhnKyo/hF/3RTP+9hW1KmtgIOmef0GfK8bukxJrKfuf0MuQ3SBuNm5+JAFn4P+D2RyBB/GbdyBkP6FUVRGBUsiqJ4zpQzyHlNMoPcGcdtqXU3tx7D7l45i7Sf6uQwd7oeA7dHDss5U57sdx46szohXfusWvS41E0F0aYlpCbNdVnkvI/K3SK8PSXxnNsz4fAFnhU8HfDzk/fplmGPZ0zzc5D3xqqYrEvQ50PTm0FOURQlHSpYFEXxHBUsiqJ4Tv66m9PCem692Gedk7NoyanjbqHvnHmOFjez7Casy7Ldwk0nPhPmLW6ftPPw45f3HaI6tivJVPPcz9Ity3alqdyzcHG/R4vIZZOdQb5Cc6nOL9o+ROELfeyCl/YH7mdZnmQKhdMNojIvEp+OiTISymfN15D2E7a3pKT1GxcdsSiK4jkqWBRF8RwVLIqieE4e21jq4cg9qRRzjIvUe1lOsm3kQ7EfpjqvQtTZFhES+2wfkt3PejjbJqRuyzYg2Xae1sCPWKbdDFGdXI2R+87NzpRNrEUehE3JlR1S3icO25dw2L60RbBNQz4Tt2cJ2HYTfl5uqxFw37rFV/F55X3zlAP5m5LXiMPOaZkeHbEoiuI5KlgURfGcPFaFpDvxTy7HyaEaD0d5gTCpQvCty+9OxT3IWcxlKDzPRmWVxgv4GqymSJWGj/3IpY5dylIt4P9P0tXqZUi/vBcevps0+4C76himOi7nMxPdp1udVHv5dzOcpo5/T+nREYuiKJ6jgkVRFM9RwaIoiufksY0lU6SemU3meNY5pc0gRHVhKku7DnchpxuQ7WN7h/wu66/ZLBQu4ens3B55HQ4Pl9dkFynDaRTOBLJ94Sy+x6H4Mo6fn5/8X8uuZz6PPJZtUHKlh8zC4KcXtnVJOyK/lymr1qc5R3qmNGLZvHkzfD4fNmzYkPxsZGQEzc3NqKmpQXl5OdatW4fe3sx834qinB1MWrC88cYb+NnPfoZly5ZZn993333YuXMnduzYgd27d6O7uxtr166dckMVRZlBmEnQ399vFi9ebF5++WVzzTXXmHvvvdcYY0w4HDZFRUVmx44dyWPfffddA8C0t7dndO5IJGJwWn+YxOajLZvvzhJbJW3n01YttiBtC2irEdtk70u36dv8tAXEVkpbrtuaH1skEpnwdzypEUtzczOuv/56NDU1WZ93dHRgdHTU+nzJkiVoaGhAe3v7uOeKRqPo6+uzNkVRZjZZG2+3b9+ON998E2+88UZKXU9PDwKBAEKhkPV5bW0tenp6Uo4HgNbWVmzatCnbZiiKksdkNWLp6urCvffei2eeeQbFxextmBwtLS2IRCLJraury5PzKoqSO7IasXR0dODYsWO4/PLLk5/F43G89tpr+Od//mfs2rULsVgM4XDYGrX09vairq5u3HMGg0EEgzwjFwA+B2e2phQ27JaVblFDdTwbdd64bTiN24Laf6CyW2izCsaZhZsbdipTO85tshIs1157Ld566y3rs+9+97tYsmQJfvCDH2DBggUoKipCW1sb1q1bBwDo7OzEkSNH0NjY6F2rFUXJa7ISLBUVFVi6dKn1WVlZGWpqapKf33777di4cSOqq6tRWVmJ9evXo7GxEatWrfKu1Yqi5DWeR97+5Cc/gd/vx7p16xCNRrF69Wps3brV68soipLH5PFKiLVwbMthcUQuQskVRfkMXQlRUZScoIJFURTPyePZzdlPXHys7GnX+vWDt02uKWcEToTMcULFLnXy/wO7T93cqWGqyzxDmKK4oSMWRVE8RwWLoiieo4JFURTPyWMby/i8sOhVq1xfvSDtsXveez1t3WNlP7fK/zl4MLn/Eh7OokWcfYtXGZduOc5IJu0fYao7QWVZn2+2ELYPyfvkrGtclq8gZ/XjkHq5eFeY6vIqamIGIKfRsM2uJE1dAnZmvPToiEVRFM9RwaIoiufkceStwwuLdmf03frq+RMf9CkDI/aauAf/cCDtsesHb834vN4xh8pydjivAS3VCx7W8prUx8T++1Q3UQLtfEYmOOf+4QW5ZHJrXpM635hFZfkecPSrvE+2crAKyipOOuQ5RwH8u0beKoqSG1SwKIriOSpYFEXxnBnnbvaKd478Pm3d+sGHzmBL0nF8grJiI02FJ3PWiqnzZ1S+jMr1Yp/DF6Q9hMcMXJa2N3bzyzqZ3D7zjHo6YlEUxXNUsCiK4jkqWBRF8ZwZEcci4ZiWbYd/ldz/csUSq25f/ztW+edo9aCFijJVOLH85WK/nuooXsQn7Co8LIjLeBS2h3Ao/kGxv4fq3O15GseiKEpOUMGiKIrnzBBV6BKxzwufua3IeCGV5fCPXWyyzGHwA1SWM49PuVxfOXeRs94XUt2lVJbqD6sYs6ks33dWd8Jin2fHd1P5TbGf3SJ7qgopipITVLAoiuI5KlgURfGcGWJjURTlNBeLfbbVNIh9t9QagPvKDunsjVEAm723sfzoRz+Cz+eztiVLnNiRkZERNDc3o6amBuXl5Vi3bh16e7NfxkNRlJlN1qrQ5z73ORw9ejS5vf66k1f2vvvuw86dO7Fjxw7s3r0b3d3dWLt2racNVhQl/8l6dnNhYSHq6tjle9oF9eSTT2Lbtm346le/CgB46qmncMkll2DPnj1YtWrV1FurKOc8nWn2p8I8KsuE8HIGNYdopCfrEcuhQ4dQX1+PCy64AN/+9rdx5MjpUOGOjg6Mjo6iqakpeeySJUvQ0NCA9vb2bC+jKMoMJqsRy8qVK/H000/j4osvxtGjR7Fp0yb8+Z//OQ4ePIienh4EAgGEQiHrO7W1tejp6Ul7zmg0img0miz39fWlPVZRlJlBVoLluuuuS+4vW7YMK1euxPnnn49/+7d/Q0lJics309Pa2opNmzZN6ruKouQnU4pjCYVCuOiii/DBBx+grq4OsVgM4XDYOqa3t3dcm8xntLS0IBKJJLeuruzCixVFmSpHafud2H4rtr0Zn3FKgmVgYAAffvgh5s2bh+XLl6OoqAhtbW3J+s7OThw5cgSNjTxN3CEYDKKystLaFEWZ4ZgsuP/++82rr75qDh8+bH7729+apqYmM3v2bHPs2DFjjDF33HGHaWhoMK+88orZv3+/aWxsNI2NjdlcwkQiEYPTCUx10023PNwikciEv+OsBMvNN99s5s2bZwKBgDnvvPPMzTffbD744INk/fDwsLnrrrvMrFmzTGlpqbnxxhvN0aNHVbDopttZtGUiWDSkX1GUrNC0CYqi5AQVLIqieI4KFkVRPEcFi6IonqOCRVEUz1HBoiiK56hgURTFc1SwKIriOSpYFEXxHBUsiqJ4jgoWRVE8RwWLoiieo4JFURTPUcGiKIrnqGBRFMVzVLAoiuI5KlgURfEcFSyKoniOChZFUTxHBYuiKJ6jgkVRFM9RwaIoiueoYFEUxXNUsCiK4jkqWBRF8RwVLIqieE7WguXjjz/Gd77zHdTU1KCkpASf//znsX///mS9MQYPPPAA5s2bh5KSEjQ1NeHQoUOeNlpRlPwmK8Fy6tQpXHXVVSgqKsJLL72Ed955Bz/+8Y8xa9as5DEPPfQQHn30UTz++OPYu3cvysrKsHr1aoyMjHjeeEVR8pQJl40X/OAHPzBXX3112vpEImHq6urMww8/nPwsHA6bYDBonn322YyuEYlEMl71XjfddDvzWyQSmfB3nNWI5T/+4z+wYsUKfPOb38TcuXPxxS9+Ef/yL/+SrD98+DB6enrQ1NSU/KyqqgorV65Ee3v7uOeMRqPo6+uzNkVRZjZZCZaPPvoIP/3pT7F48WLs2rULd955J+655x78/Oc/BwD09PQAAGpra63v1dbWJuuY1tZWVFVVJbcFCxZM5j4URckjCrM5OJFIYMWKFfiHf/gHAMAXv/hFHDx4EI8//jhuvfXWSTWgpaUFGzduTJb7+vpUuCiK13yDyjun93JZjVjmzZuHSy+91PrskksuwZEjRwAAdXV1AIDe3l7rmN7e3mQdEwwGUVlZaW2KosxsshIsV111FTo7O63P3n//fZx//vkAgEWLFqGurg5tbW3J+r6+PuzduxeNjY0eNFdRlBlBRq6aT9m3b58pLCw0f//3f28OHTpknnnmGVNaWmp+8YtfJI/ZvHmzCYVC5oUXXjC///3vzQ033GAWLVpkhoeH1Sukm2652r5B2xTOlYlXyGeMMciCF198ES0tLTh06BAWLVqEjRs34nvf+16y3hiDBx98EE888QTC4TCuvvpqbN26FRdddFFG5+/r60NVVVU2TVIUhfkfVF5E5bDY/wLVfd/91JFIZEKTRdaCZbpRwaIoHpBjwaJzhRRF8Zys3M2KoswQXqTyP1L5MbH/v72/vI5YFEXxHBUsiqJ4Tt6pQnlmS1aUswMPkwtk8hvNO8HS39+f6yYoytnH33p3qv7+/gk9t3nnbk4kEuju7oYxBg0NDejq6tIw/3H4bE6V9k96tI/cybZ/jDHo7+9HfX09/H53K0rejVj8fj/mz5+fTJ+g84fc0f6ZGO0jd7Lpn0xjzNR4qyiK56hgURTFc/JWsASDQTz44IMIBoO5bkpeov0zMdpH7kxn/+Sd8VZRlJlP3o5YFEWZuahgURTFc1SwKIriOSpYFEXxnLwVLFu2bMHChQtRXFyMlStXYt++fbluUk5obW3FFVdcgYqKCsydOxdr1qxJyTs8MjKC5uZm1NTUoLy8HOvWrUtJaH4usHnzZvh8PmzYsCH5mfZNjpZFziLl7Rlj+/btJhAImH/91381b7/9tvne975nQqGQ6e3tzXXTzjirV682Tz31lDl48KA5cOCA+frXv24aGhrMwMBA8pg77rjDLFiwwLS1tZn9+/ebVatWmS996Us5bPWZZ9++fWbhwoVm2bJl5t57701+fq73zSeffGLOP/98c9ttt5m9e/eajz76yOzatct88MEHyWM2b95sqqqqzPPPP29+97vfmb/8y7/MKk/1eOSlYLnyyitNc3NzshyPx019fb1pbW3NYavyg2PHjhkAZvfu3caY00vYFhUVmR07diSPeffddw0A097enqtmnlH6+/vN4sWLzcsvv2yuueaapGDRvjkzyyKPR96pQrFYDB0dHdYyrX6/H01NTWmXaT2XiEQiAIDq6moAQEdHB0ZHR63+WrJkCRoaGs6Z/mpubsb1119v9QGgfQNMz7LImZB3guXEiROIx+NZLdN6rpBIJLBhwwZcddVVWLp0KYDTy9oGAgGEQiHr2HOlv7Zv344333wTra2tKXXnet8A07Mscibk3exmJT3Nzc04ePAgXn/99Vw3JS/o6urCvffei5dffhnFxcW5bk5eMh3LImdC3o1YZs+ejYKCgqyWaT0XuPvuu/Hiiy/iN7/5DebPn5/8vK6uDrFYDOFw2Dr+XOivjo4OHDt2DJdffjkKCwtRWFiI3bt349FHH0VhYSFqa2vP2b75jOlYFjkT8k6wBAIBLF++3FqmNZFIoK2t7ZxcptUYg7vvvhvPPfccXnnlFSxaZC8Qs3z5chQVFVn91dnZiSNHjpz1/XXttdfirbfewoEDB5LbihUr8O1vfzu5f672zWfkbFnkSZt9p5Ht27ebYDBonn76afPOO++Yv/7rvzahUMj09PTkumlnnDvvvNNUVVWZV1991Rw9ejS5DQ0NJY+54447TENDg3nllVfM/v37TWNjo2lsbMxhq3OH9AoZo31zJpZFHo+8FCzGGPPYY4+ZhoYGEwgEzJVXXmn27NmT6yblBKRZP/epp55KHjM8PGzuuusuM2vWLFNaWmpuvPFGc/To0dw1OoewYNG+MWbnzp1m6dKlJhgMmiVLlpgnnnjCqk8kEuaHP/yhqa2tNcFg0Fx77bWms7NzStfUtAmKonhO3tlYFEWZ+ahgURTFc1SwKIriOSpYFEXxHBUsiqJ4jgoWRVE8RwWLoiieo4JFURTPUcGiKIrnqGBRFMVzVLAoiuI5KlgURfGc/w+8+iSNC1KdHAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "imshow(state.detach().cpu()-out.detach().cpu())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06ZdYB-GTyIk",
        "outputId": "81b0fb4e-9cb4-4ca9-c95b-89d610b8a949"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[torch.Size([4, 64, 16, 16]), torch.Size([4, 512, 4, 4]), torch.Size([4, 4096])]\n",
            "[torch.Size([4, 3, 64, 64]), torch.Size([4, 3, 64, 64]), torch.Size([4, 3, 64, 64])]\n"
          ]
        }
      ],
      "source": [
        "# @title autoencoder split\n",
        "\n",
        "class autoencoder(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        d_list=[64, 512, 4096]\n",
        "        # r_list=[(360,640), (240,426), (144,256)] # https://en.wikipedia.org/wiki/Low-definition_television\n",
        "        self.enc1 = nn.Sequential(nn.Conv2d(3, d_list[0], 7, 2, 3), nn.BatchNorm2d(d_list[0]), nn.ReLU(), nn.MaxPool2d(2, 2),)\n",
        "        self.enc2 = nn.Sequential(nn.Conv2d(d_list[0], d_list[1], 5, 2, 2), nn.BatchNorm2d(d_list[1]), nn.ReLU(), nn.MaxPool2d(2, 2),)\n",
        "        self.enc3 = nn.Sequential(nn.Conv2d(d_list[1], d_list[2], 3, 2, 1), nn.ReLU(), nn.MaxPool2d(2, 2),\n",
        "            nn.AdaptiveMaxPool2d(1), # AdaptiveAvgPool2d AdaptiveMaxPool2d\n",
        "            nn.Flatten(start_dim=1),\n",
        "            # nn.Linear()\n",
        "        )\n",
        "\n",
        "        # self.deconv1 = nn.Sequential(nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),)\n",
        "        # self.deconv2 = nn.Sequential(nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),)\n",
        "        # self.deconv3 = nn.Sequential(nn.Upsample(scale_factor=2), nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1), nn.Sigmoid(),)\n",
        "        self.deconv1 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), nn.ConvTranspose2d(d_list[2], d_list[1], 3, 2, 1, output_padding=1), nn.BatchNorm2d(d_list[1]), nn.ReLU(),)\n",
        "        self.deconv2 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), nn.ConvTranspose2d(d_list[1], d_list[0], 5, 2, 2, output_padding=1), nn.BatchNorm2d(d_list[0]), nn.ReLU(),)\n",
        "        self.deconv3 = nn.Sequential(nn.Upsample(scale_factor=2, mode='bilinear'), nn.ConvTranspose2d(d_list[0], 3, 7, 2, 3, output_padding=1), nn.Sigmoid(),)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x)\n",
        "        return x[-1]\n",
        "\n",
        "    def encode(self, x):\n",
        "        x1=self.enc1(x)\n",
        "        x2=self.enc2(x1)\n",
        "        x3=self.enc3(x2)\n",
        "        # return self.enc(x).squeeze()\n",
        "        return x1,x2,x3\n",
        "    def decode(self, x123):\n",
        "        x1,x2,x3=x123\n",
        "        x3=x3.unsqueeze(-1).unsqueeze(-1)\n",
        "        o3=self.deconv3(self.deconv2(self.deconv1(x3)))\n",
        "        o2=self.deconv3(self.deconv2(x2))\n",
        "        o1=self.deconv3(x1)\n",
        "        return o1,o2,o3\n",
        "        # return self.deconv(x.unsqueeze(-1).unsqueeze(-1))\n",
        "    # def decode(self, x): return self.deconv(x)\n",
        "\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = autoencoder().to(device)\n",
        "# print(sum(p.numel() for p in model.enc.parameters() if p.requires_grad)) # res 2775104, convpool 2951424, stride 2957315\n",
        "# print(sum(p.numel() for p in model.deconv.parameters() if p.requires_grad)) # 2957315\n",
        "\n",
        "input = torch.rand((4,3,64,64), device=device)\n",
        "out = model.encode(input)\n",
        "# print(out.shape)\n",
        "print([o.shape for o in out])\n",
        "i2= model.decode(out)\n",
        "# print(i2.shape)\n",
        "print([i.shape for i in i2])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "Zf6gooDVfiIR",
        "outputId": "70736c04-d8e4-47f3-f58d-b7d1cf60cff5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([3, 16, 16])\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 300x300 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "epochs=30\n",
        "# num_batches=len(train_loader)\n",
        "# total_steps=int(num_batches*epochs)\n",
        "# max_lr=1e-4\n",
        "# min_lr=1e-7\n",
        "# # max_lr* gamma^total_steps = min_lr\n",
        "# gamma = np.exp(np.log(min_lr/max_lr)/total_steps)\n",
        "# print(gamma)\n",
        "# scheduler = torch.optim.lr_scheduler.ExponentialLR(optim, gamma=gamma) # 0.75(20)-0.9(100)\n",
        "# train(train_loader,model,optim,scheduler)\n",
        "\n",
        "state = buffer[7][80][0]\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "state = transform(state).unsqueeze(0).to(device)[0]\n",
        "# print(state.shape)\n",
        "pool = nn.AdaptiveMaxPool2d(16) # AdaptiveAvgPool2d AdaptiveMaxPool2d\n",
        "# sx_ = model.encode(state.unsqueeze(0))\n",
        "# # print(sx_.shape)\n",
        "# out= model.decode(sx_.unsqueeze(0)).squeeze(0)\n",
        "out = pool(state)\n",
        "\n",
        "print(out.shape)\n",
        "imshow(state.detach().cpu())\n",
        "imshow(out.detach().cpu())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import torcheval\n",
        "# from torcheval.metrics import StructuralSimilarity, FrechetInceptionDistance\n",
        "# # https://pytorch.org/torcheval/main/torcheval.metrics.html#image-metrics\n",
        "# loss_fn = torcheval.metrics.StructuralSimilarity()\n",
        "# loss_fn = torcheval.metrics.FrechetInceptionDistance()\n",
        "# from torchmetrics.image import StructuralSimilarityIndexMeasure # no backward\n",
        "# from ignite.metrics import SSIM\n",
        "# loss = SSIM(state_, state)\n",
        "# loss = FrechetInceptionDistance(state_, state)"
      ],
      "metadata": {
        "id": "qqkpV4uwV8Gp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "kRd8qZZ-GsvZ"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
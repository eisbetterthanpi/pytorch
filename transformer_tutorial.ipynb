{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/transformer_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### setup"
      ],
      "metadata": {
        "id": "VWwhEQ6bX_QF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcfvAGRbWJDy",
        "outputId": "4dfef9bd-bf98-45ae-f8da-d3ec67d62544",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.48M/4.48M [00:01<00:00, 3.09MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "# from torch.utils.data import dataset\n",
        "from torchtext.datasets import WikiText2\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "\n",
        "train_iter = WikiText2(split='train')\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "vocab = build_vocab_from_iterator(map(tokenizer, train_iter), specials=['<unk>'])\n",
        "vocab.set_default_index(vocab['<unk>']) \n",
        "\n",
        "def data_process(raw_text_iter: dataset.IterableDataset) -> Tensor:\n",
        "    \"\"\"Converts raw text into a flat Tensor.\"\"\"\n",
        "    data = [torch.tensor(vocab(tokenizer(item)), dtype=torch.long) for item in raw_text_iter]\n",
        "    return torch.cat(tuple(filter(lambda t: t.numel() > 0, data)))\n",
        "\n",
        "# train_iter was \"consumed\" by the process of building the vocab,\n",
        "# so we have to create it again\n",
        "train_iter, val_iter, test_iter = WikiText2()\n",
        "train_data = data_process(train_iter)\n",
        "val_data = data_process(val_iter)\n",
        "test_data = data_process(test_iter)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def batchify(data: Tensor, bsz: int) -> Tensor:\n",
        "    \"\"\"Divides the data into bsz separate sequences, removing extra elements that wouldn't cleanly fit.\n",
        "    Args:\n",
        "        data: Tensor, shape [N]\n",
        "        bsz: int, batch size\n",
        "    Returns: Tensor of shape [N // bsz, bsz]\n",
        "    \"\"\"\n",
        "    seq_len = data.size(0) // bsz\n",
        "    data = data[:seq_len * bsz]\n",
        "    data = data.view(bsz, seq_len).t().contiguous()\n",
        "    return data.to(device)\n",
        "\n",
        "batch_size = 20\n",
        "eval_batch_size = 10\n",
        "train_data = batchify(train_data, batch_size)  # shape [seq_len, batch_size]\n",
        "val_data = batchify(val_data, eval_batch_size)\n",
        "test_data = batchify(test_data, eval_batch_size)\n",
        "\n",
        "# get_batch() generates a pair of input-target sequences for the transformer model. It subdivides the source data into chunks of length bptt. For the language modeling task, the model needs the following words as Target. For example, with a bptt value of 2, we’d get the following two Variables for i = 0:\n",
        "# It should be noted that the chunks are along dimension 0, consistent with the S dimension in the Transformer model. The batch dimension N is along dimension 1.\n",
        "bptt = 35\n",
        "def get_batch(source, i):\n",
        "    \"\"\"source: Tensor, shape [full_seq_len, batch_size]   i: int\n",
        "    Returns: tuple (data, target), where data has shape [seq_len, batch_size] and target has shape [seq_len * batch_size]\"\"\"\n",
        "    seq_len = min(bptt, len(source) - 1 - i)\n",
        "    data = source[i:i+seq_len]\n",
        "    target = source[i+1:i+1+seq_len].reshape(-1)\n",
        "    return data, target\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### TransformerModel"
      ],
      "metadata": {
        "id": "iL7-v_rDYC1l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW4kEKZsWJDd"
      },
      "outputs": [],
      "source": [
        "# %matplotlib inline\n",
        "import math\n",
        "from typing import Tuple\n",
        "import torch\n",
        "from torch import nn, Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.nn import TransformerEncoder, TransformerEncoderLayer\n",
        "# https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, d_model, nhead, d_hid, nlayers, dropout = 0.5):\n",
        "        super().__init__()\n",
        "        # self.model_type = 'Transformer'\n",
        "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
        "        encoder_layers = TransformerEncoderLayer(d_model, nhead, d_hid, dropout)\n",
        "        self.transformer_encoder = TransformerEncoder(encoder_layers, nlayers)\n",
        "        self.encoder = nn.Embedding(ntoken, d_model)\n",
        "        self.d_model = d_model\n",
        "        self.decoder = nn.Linear(d_model, ntoken)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask): # src: [seq_len, batch_size], src_mask: [seq_len, seq_len], Returns: [seq_len, batch_size, ntoken]\n",
        "        src = self.encoder(src) * math.sqrt(self.d_model)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        output = self.decoder(output)\n",
        "        return output\n",
        "\n",
        "def generate_square_subsequent_mask(sz): # Generates an upper-triangular matrix of -inf, with zeros on diag.\n",
        "    return torch.triu(torch.ones(sz, sz) * float('-inf'), diagonal=1)\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, dropout = 0.1, max_len = 5000):\n",
        "        super().__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        position = torch.arange(max_len).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
        "        pe = torch.zeros(max_len, 1, d_model)\n",
        "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x): # x: [seq_len, batch_size, embedding_dim]\n",
        "        x = x + self.pe[:x.size(0)]\n",
        "        return self.dropout(x)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train/evaluate"
      ],
      "metadata": {
        "id": "lPEbRTbnYISU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fi3Qty_KWJEB"
      },
      "outputs": [],
      "source": [
        "\n",
        "ntokens = len(vocab)  # size of vocabulary\n",
        "emsize = 200  # embedding dimension\n",
        "d_hid = 200  # dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 2  # number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # number of heads in nn.MultiheadAttention\n",
        "dropout = 0.2  # dropout probability\n",
        "model = TransformerModel(ntokens, emsize, nhead, d_hid, nlayers, dropout).to(device)\n",
        "\n",
        "import copy\n",
        "import time\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "lr = 5.0\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.95)\n",
        "\n",
        "def train(model):\n",
        "    model.train()  # turn on train mode\n",
        "    total_loss = 0.\n",
        "    log_interval = 200\n",
        "    start_time = time.time()\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "\n",
        "    num_batches = len(train_data) // bptt\n",
        "    for batch, i in enumerate(range(0, train_data.size(0) - 1, bptt)):\n",
        "        data, targets = get_batch(train_data, i)\n",
        "        batch_size = data.size(0)\n",
        "        if batch_size != bptt:  # only on last batch\n",
        "            src_mask = src_mask[:batch_size, :batch_size]\n",
        "        output = model(data, src_mask)\n",
        "        loss = criterion(output.view(-1, ntokens), targets)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # to prevent gradients from exploding.\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if batch % log_interval == 0 and batch > 0:\n",
        "            lr = scheduler.get_last_lr()[0]\n",
        "            ms_per_batch = (time.time() - start_time) * 1000 / log_interval\n",
        "            cur_loss = total_loss / log_interval\n",
        "            ppl = math.exp(cur_loss)\n",
        "            print(f'| epoch {epoch:3d} | {batch:5d}/{num_batches:5d} batches | '\n",
        "                  f'lr {lr:02.2f} | ms/batch {ms_per_batch:5.2f} | '\n",
        "                  f'loss {cur_loss:5.2f} | ppl {ppl:8.2f}')\n",
        "            total_loss = 0\n",
        "            start_time = time.time()\n",
        "\n",
        "def evaluate(model: nn.Module, eval_data: Tensor) -> float:\n",
        "    model.eval()  # turn on evaluation mode\n",
        "    total_loss = 0.\n",
        "    src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "    with torch.no_grad():\n",
        "        for i in range(0, eval_data.size(0) - 1, bptt):\n",
        "            data, targets = get_batch(eval_data, i)\n",
        "            batch_size = data.size(0)\n",
        "            if batch_size != bptt:\n",
        "                src_mask = src_mask[:batch_size, :batch_size]\n",
        "            output = model(data, src_mask)\n",
        "            output_flat = output.view(-1, ntokens)\n",
        "            total_loss += batch_size * criterion(output_flat, targets).item()\n",
        "    return total_loss / (len(eval_data) - 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "swgoAJTCWJEF",
        "outputId": "6cf129b4-a458-47ea-9071-d856c3a9c8e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   200/ 2928 batches | lr 5.00 | ms/batch 38.19 | loss  8.22 | ppl  3713.80\n",
            "| epoch   1 |   400/ 2928 batches | lr 5.00 | ms/batch 36.97 | loss  6.93 | ppl  1025.85\n",
            "| epoch   1 |   600/ 2928 batches | lr 5.00 | ms/batch 36.98 | loss  6.48 | ppl   650.00\n",
            "| epoch   1 |   800/ 2928 batches | lr 5.00 | ms/batch 36.98 | loss  6.31 | ppl   550.74\n",
            "| epoch   1 |  1000/ 2928 batches | lr 5.00 | ms/batch 36.96 | loss  6.20 | ppl   494.51\n",
            "| epoch   1 |  1200/ 2928 batches | lr 5.00 | ms/batch 37.56 | loss  6.16 | ppl   474.45\n",
            "| epoch   1 |  1400/ 2928 batches | lr 5.00 | ms/batch 36.83 | loss  6.12 | ppl   454.24\n",
            "| epoch   1 |  1600/ 2928 batches | lr 5.00 | ms/batch 36.85 | loss  6.11 | ppl   449.99\n",
            "| epoch   1 |  1800/ 2928 batches | lr 5.00 | ms/batch 36.83 | loss  6.04 | ppl   418.03\n",
            "| epoch   1 |  2000/ 2928 batches | lr 5.00 | ms/batch 36.83 | loss  6.02 | ppl   412.01\n",
            "| epoch   1 |  2200/ 2928 batches | lr 5.00 | ms/batch 36.83 | loss  5.90 | ppl   365.73\n",
            "| epoch   1 |  2400/ 2928 batches | lr 5.00 | ms/batch 36.80 | loss  5.97 | ppl   393.22\n",
            "| epoch   1 |  2600/ 2928 batches | lr 5.00 | ms/batch 36.84 | loss  5.96 | ppl   386.03\n",
            "| epoch   1 |  2800/ 2928 batches | lr 5.00 | ms/batch 36.78 | loss  5.89 | ppl   360.00\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   1 | time: 112.03s | valid loss  5.81 | valid ppl   334.23\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   2 |   200/ 2928 batches | lr 4.75 | ms/batch 36.93 | loss  5.88 | ppl   357.17\n",
            "| epoch   2 |   400/ 2928 batches | lr 4.75 | ms/batch 36.78 | loss  5.86 | ppl   351.94\n",
            "| epoch   2 |   600/ 2928 batches | lr 4.75 | ms/batch 36.80 | loss  5.67 | ppl   290.94\n",
            "| epoch   2 |   800/ 2928 batches | lr 4.75 | ms/batch 36.83 | loss  5.71 | ppl   301.68\n",
            "| epoch   2 |  1000/ 2928 batches | lr 4.75 | ms/batch 36.79 | loss  5.66 | ppl   287.20\n",
            "| epoch   2 |  1200/ 2928 batches | lr 4.75 | ms/batch 36.86 | loss  5.68 | ppl   294.26\n",
            "| epoch   2 |  1400/ 2928 batches | lr 4.75 | ms/batch 37.03 | loss  5.69 | ppl   295.49\n",
            "| epoch   2 |  1600/ 2928 batches | lr 4.75 | ms/batch 36.95 | loss  5.71 | ppl   302.15\n",
            "| epoch   2 |  1800/ 2928 batches | lr 4.75 | ms/batch 38.71 | loss  5.65 | ppl   285.55\n",
            "| epoch   2 |  2000/ 2928 batches | lr 4.75 | ms/batch 37.73 | loss  5.67 | ppl   290.09\n",
            "| epoch   2 |  2200/ 2928 batches | lr 4.75 | ms/batch 36.83 | loss  5.54 | ppl   254.87\n",
            "| epoch   2 |  2400/ 2928 batches | lr 4.75 | ms/batch 36.86 | loss  5.64 | ppl   280.60\n",
            "| epoch   2 |  2600/ 2928 batches | lr 4.75 | ms/batch 38.71 | loss  5.64 | ppl   282.79\n",
            "| epoch   2 |  2800/ 2928 batches | lr 4.75 | ms/batch 36.80 | loss  5.58 | ppl   265.44\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   2 | time: 112.50s | valid loss  5.65 | valid ppl   285.04\n",
            "-----------------------------------------------------------------------------------------\n",
            "| epoch   3 |   200/ 2928 batches | lr 4.51 | ms/batch 36.98 | loss  5.61 | ppl   271.91\n",
            "| epoch   3 |   400/ 2928 batches | lr 4.51 | ms/batch 36.83 | loss  5.63 | ppl   277.50\n",
            "| epoch   3 |   600/ 2928 batches | lr 4.51 | ms/batch 36.84 | loss  5.43 | ppl   227.45\n",
            "| epoch   3 |   800/ 2928 batches | lr 4.51 | ms/batch 36.77 | loss  5.48 | ppl   239.22\n",
            "| epoch   3 |  1000/ 2928 batches | lr 4.51 | ms/batch 36.86 | loss  5.44 | ppl   230.80\n",
            "| epoch   3 |  1200/ 2928 batches | lr 4.51 | ms/batch 37.13 | loss  5.47 | ppl   238.53\n",
            "| epoch   3 |  1400/ 2928 batches | lr 4.51 | ms/batch 36.82 | loss  5.49 | ppl   241.50\n",
            "| epoch   3 |  1600/ 2928 batches | lr 4.51 | ms/batch 36.89 | loss  5.51 | ppl   248.04\n",
            "| epoch   3 |  1800/ 2928 batches | lr 4.51 | ms/batch 37.15 | loss  5.47 | ppl   237.61\n",
            "| epoch   3 |  2000/ 2928 batches | lr 4.51 | ms/batch 36.84 | loss  5.49 | ppl   241.25\n",
            "| epoch   3 |  2200/ 2928 batches | lr 4.51 | ms/batch 36.87 | loss  5.37 | ppl   214.42\n",
            "| epoch   3 |  2400/ 2928 batches | lr 4.51 | ms/batch 36.90 | loss  5.47 | ppl   237.65\n",
            "| epoch   3 |  2600/ 2928 batches | lr 4.51 | ms/batch 36.85 | loss  5.47 | ppl   237.61\n",
            "| epoch   3 |  2800/ 2928 batches | lr 4.51 | ms/batch 36.84 | loss  5.41 | ppl   223.28\n",
            "-----------------------------------------------------------------------------------------\n",
            "| end of epoch   3 | time: 111.70s | valid loss  5.56 | valid ppl   259.37\n",
            "-----------------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "best_val_loss = float('inf')\n",
        "epochs = 3\n",
        "best_model = None\n",
        "\n",
        "for epoch in range(1, epochs + 1):\n",
        "    epoch_start_time = time.time()\n",
        "    train(model)\n",
        "    val_loss = evaluate(model, val_data)\n",
        "    val_ppl = math.exp(val_loss)\n",
        "    elapsed = time.time() - epoch_start_time\n",
        "    print('-' * 89)\n",
        "    print(f'| end of epoch {epoch:3d} | time: {elapsed:5.2f}s | '\n",
        "          f'valid loss {val_loss:5.2f} | valid ppl {val_ppl:8.2f}')\n",
        "    print('-' * 89)\n",
        "\n",
        "    if val_loss < best_val_loss:\n",
        "        best_val_loss = val_loss\n",
        "        best_model = copy.deepcopy(model)\n",
        "\n",
        "    scheduler.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### wwwwwwwwwwwwwwwww"
      ],
      "metadata": {
        "id": "Nvm4wD1nYMHL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkyzC5B0WJEH",
        "outputId": "38aced83-cbc9-41cf-b39f-96b960c19e19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   9,  292,  591, 5361,    5,   46,    9,    3,   10, 5060],\n",
            "       device='cuda:0')\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-412cac4c3cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# print(lookup_tokens(evaldat))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# print(lookup_tokens(output))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaldat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVocab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookup_tokens\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: lookup_tokens() missing 1 required positional argument: 'indices'"
          ]
        }
      ],
      "source": [
        "# test_loss = evaluate(best_model, test_data)\n",
        "# test_ppl = math.exp(test_loss)\n",
        "# print('=' * 89)\n",
        "# print(f'| End of training | test loss {test_loss:5.2f} | '\n",
        "#       f'test ppl {test_ppl:8.2f}')\n",
        "# print('=' * 89)\n",
        "\n",
        "# from torchtext.vocab import lookup_tokens\n",
        "from torchtext.vocab import Vocab\n",
        "\n",
        "src_mask = generate_square_subsequent_mask(bptt).to(device)\n",
        "evaldat=test_data[0]\n",
        "data, targets = get_batch(evaldat, 0)\n",
        "batch_size = data.size(0)\n",
        "if batch_size != bptt:\n",
        "    src_mask = src_mask[:batch_size, :batch_size]\n",
        "output = model(data, src_mask)\n",
        "print(evaldat)\n",
        "# print(lookup_tokens(evaldat))\n",
        "# print(lookup_tokens(output))\n",
        "print(Vocab.lookup_tokens(list(evaldat)))\n",
        "print(Vocab.lookup_tokens(output))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "colab": {
      "name": "transformer_tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1hiTjYXYCX49h0HgNvYQ2_Y6IA7b5a641",
      "authorship_tag": "ABX9TyNZXaS1y3ksEOadpP/e/ePA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/tinyGPT_nextt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7ugFOONfWAmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4958ee55-fa79-4d71-8d11-7b9e37c6ada6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "# https://github.com/Sam-Armstrong/tinyGPT/blob/main/Training.py\n",
        "# !pip install torchdata\n",
        "# !pip install portalocker\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class WikiDataset(Dataset): # https://github.com/karpathy/minGPT\n",
        "    def __init__(self, data, block_size):\n",
        "        chars = sorted(list(set(data)))\n",
        "        vocab_size = len(chars)\n",
        "        self.stoi = {ch:i for i,ch in enumerate(chars)}\n",
        "        self.itos = {i:ch for i,ch in enumerate(chars)}\n",
        "        self.block_size = block_size\n",
        "        self.vocab_size = vocab_size\n",
        "        self.data = data\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data) - self.block_size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        chunk = self.data[idx:idx + self.block_size + 1]\n",
        "        dix = [self.stoi[s] for s in chunk]\n",
        "        x = torch.tensor(dix[:-1], dtype = torch.long)\n",
        "        y = torch.tensor(dix[1:], dtype = torch.long)\n",
        "        return x, y\n",
        "\n",
        "\n",
        "seq_len = 128\n",
        "# Code for using a text corpus contained within a .txt file\n",
        "# data = open('input.txt', 'r').read()\n",
        "# data = list(data)\n",
        "\n",
        "from torchtext.datasets import WikiText2\n",
        "text_iter = WikiText2(split = 'train')\n",
        "train_data = []\n",
        "for i, sequence in enumerate(text_iter):\n",
        "    train_data += list(sequence)\n",
        "# print(len(train_data)) # 10780437\n",
        "\n",
        "# train_dataset = WikiDataset(train_data[:10000], seq_len) # one line of poem is roughly 50 characters\n",
        "train_dataset = WikiDataset(train_data, seq_len) # one line of poem is roughly 50 characters\n",
        "text_iter = WikiText2(split = 'test')\n",
        "test_data = []\n",
        "for i, sequence in enumerate(text_iter):\n",
        "    test_data += list(sequence)\n",
        "# print(len(data)) # 10780437\n",
        "# test_dataset = WikiDataset(test_data[:1000], seq_len) # one line of poem is roughly 50 characters\n",
        "test_dataset = WikiDataset(test_data, seq_len) # one line of poem is roughly 50 characters\n",
        "\n",
        "vocab_size = train_dataset.vocab_size\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "batch_size = 512 #500\n",
        "train_loader = DataLoader(train_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 2) # num_workers = 4\n",
        "test_loader = DataLoader(test_dataset, shuffle = True, pin_memory = True, batch_size = batch_size, num_workers = 0)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title model\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class SelfAttention(nn.Module): # https://github.com/Sam-Armstrong/tinyGPT/blob/main/SelfAttention.py\n",
        "    \"\"\"Multi-Head Self Attention mechanism for use the the transformer model\"\"\"\n",
        "    def __init__(self, seq_len=seq_len, emb_dim = 512, n_heads = 4):\n",
        "        super().__init__()\n",
        "        self.emb_dim = emb_dim\n",
        "        self.n_heads = n_heads\n",
        "        self.head_dim = self.emb_dim // self.n_heads\n",
        "        self.values = nn.Linear(self.emb_dim, self.emb_dim, bias = False)\n",
        "        self.keys = nn.Linear(self.emb_dim, self.emb_dim, bias = False)\n",
        "        self.queries = nn.Linear(self.emb_dim, self.emb_dim, bias = False)\n",
        "        self.projection = nn.Linear(self.emb_dim, self.emb_dim, bias = False)\n",
        "        self.softmax = nn.Softmax(dim = -1)\n",
        "        self.register_buffer(\"mask\", torch.tril(torch.ones(seq_len, seq_len)).view(1, 1, seq_len, seq_len))\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.shape[0]\n",
        "        seq_len = x.shape[1]\n",
        "        values = self.values(x)\n",
        "        keys = self.keys(x)\n",
        "        queries = self.queries(x)\n",
        "        values = values.reshape(batch_size, seq_len, self.n_heads, self.head_dim)\n",
        "        keys = keys.reshape(batch_size, seq_len, self.n_heads, self.head_dim)\n",
        "        queries = queries.reshape(batch_size, seq_len, self.n_heads, self.head_dim)\n",
        "        similarities = torch.einsum('nqhd,nkhd->nhqk', [queries, keys])\n",
        "        similarities = similarities.masked_fill(self.mask[:,:,:seq_len,:seq_len] == 0, float('-inf'))\n",
        "        attention_weights = self.softmax(similarities / math.sqrt(self.emb_dim))\n",
        "        output = torch.einsum('nhql,nlhd->nqhd', [attention_weights, values]).reshape(batch_size, seq_len, self.emb_dim)\n",
        "        return self.projection(output)\n",
        "\n",
        "class Block(nn.Module): # https://github.com/Sam-Armstrong/tinyGPT/blob/main/TransformerBlock.py\n",
        "    \"\"\"A single transformer decoder block\"\"\"\n",
        "    def __init__(self, emb_dim=embed_dim):\n",
        "        super().__init__()\n",
        "        self.ln1 = nn.LayerNorm(emb_dim)\n",
        "        self.ln2 = nn.LayerNorm(emb_dim)\n",
        "        self.attention = SelfAttention(seq_len=seq_len, emb_dim=emb_dim, n_heads=n_heads)\n",
        "        self.fc1 = nn.Linear(emb_dim, 4 * emb_dim, bias = False)\n",
        "        self.fc2 = nn.Linear(4 * emb_dim, emb_dim, bias = False)\n",
        "        self.silu = nn.SiLU()\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Attention Block\n",
        "        res = x.clone()\n",
        "        x = self.ln1(x)\n",
        "        x = self.attention(x)\n",
        "        x += res\n",
        "        # MLP Block\n",
        "        res = x.clone()\n",
        "        x = self.ln2(x)\n",
        "        x = self.fc1(x)\n",
        "        x = self.silu(x)\n",
        "        x = self.fc2(x)\n",
        "        return self.dropout(x)\n",
        "\n",
        "class tinyGPT(nn.Module): # https://github.com/Sam-Armstrong/tinyGPT/blob/main/Model.py\n",
        "    def __init__(self, vocab_size, embed_dim, seq_len):\n",
        "        super().__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.position_embedding = nn.Parameter(torch.zeros(1, seq_len, embed_dim))\n",
        "        self.projection = nn.Linear(embed_dim * 2, embed_dim, bias = False)\n",
        "        nn.init.normal_(self.projection.weight, mean = 0.0, std = 0.02)\n",
        "        self.dropout = nn.Dropout(0.1)\n",
        "        self.blocks = nn.Sequential(*[Block(embed_dim) for _ in range(2)]) # n_layers = 2\n",
        "        self.ln_out = nn.LayerNorm(embed_dim)\n",
        "        self.fc_out = nn.Linear(embed_dim, vocab_size, bias = False)\n",
        "        self.seq_len = seq_len\n",
        "        # print(\"number of parameters: \" sum(p.numel() for p in self.parameters()))\n",
        "\n",
        "    def forward(self, idx):\n",
        "        batch_size = idx.shape[0]\n",
        "        seq_len = idx.shape[1]\n",
        "        embedding = self.embedding(idx)\n",
        "        position_embedding = self.position_embedding[:, :seq_len, :].repeat(batch_size, 1, 1)\n",
        "        # Concats token and position and embeddings then projects them onto the embedding dimension\n",
        "        x = torch.concat((embedding, position_embedding), dim = -1)\n",
        "        x = self.projection(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.blocks(x)\n",
        "        x = self.ln_out(x)\n",
        "        return self.fc_out(x)\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = tinyGPT(vocab_size, embed_dim, seq_len).to(device)\n"
      ],
      "metadata": {
        "id": "Gn-NORe9WoLu"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train test\n",
        "from torch.nn import functional as F\n",
        "\n",
        "def test(model, x, max_steps = 512):\n",
        "    seq_len = model.seq_len\n",
        "    model.eval()\n",
        "    print(\"test\",x)\n",
        "    for n in range(max_steps):\n",
        "        if x.shape[1] <= seq_len:\n",
        "            x_bar = x\n",
        "        else:\n",
        "            x_bar = x[:, -seq_len:]\n",
        "        # print(\"test\",x_bar)\n",
        "        output = model(x_bar)\n",
        "        # print(\"output\",output)\n",
        "        output = output[:, -1, :]\n",
        "        output = F.softmax(output, dim = -1)\n",
        "        ix = torch.multinomial(output, num_samples = 1)\n",
        "        x = torch.cat((x, ix), dim = 1)\n",
        "    return x\n",
        "\n",
        "from tqdm import tqdm\n",
        "def train(loader, model, loss_fn, optimizer):\n",
        "    model.train()\n",
        "    losses = []\n",
        "    pbar = tqdm(enumerate(loader), total = len(loader))\n",
        "    for it, (x, y) in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        with torch.set_grad_enabled(True):\n",
        "            logits = model(x)\n",
        "            # loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "            loss = loss_fn(logits, y)\n",
        "            losses.append(loss.item())\n",
        "        model.zero_grad()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1)\n",
        "        optimizer.step()\n",
        "        # pbar.set_description(f\"epoch {epoch + 1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\n",
        "        pbar.set_description(f\"epoch {epoch + 1} iter {it}: train loss {loss.item():.5f}.\")\n",
        "\n",
        "import numpy as np\n",
        "def eval(loader, model, loss_fn):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    pbar = enumerate(loader)\n",
        "    for it, (x, y) in pbar:\n",
        "        x = x.to(device)\n",
        "        y = y.to(device)\n",
        "        with torch.set_grad_enabled(False):\n",
        "            logits = model(x)\n",
        "            # loss = criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "            loss = loss_fn(logits, y)\n",
        "            losses.append(loss.item())\n",
        "    test_loss = float(np.mean(losses))\n",
        "    # print(\"test loss: %f\", test_loss)\n",
        "    return test_loss\n"
      ],
      "metadata": {
        "id": "QCN055Zr7Dq4",
        "cellView": "form"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title wwwwwwwwwwww\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), 1e-4, (0.9, 0.95)) # lr = 1e-4 #3e-4\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "def loss_fn(logits, y):\n",
        "    # print(logits.shape, y.shape) # [500, 128, 283], [500, 128]\n",
        "    return criterion(logits.view(-1, logits.size(-1)), y.view(-1))\n",
        "\n",
        "for epoch in range(1):\n",
        "    train(train_loader, model, loss_fn, optimizer)\n",
        "    test_loss = eval(test_loader, model, loss_fn)\n",
        "    print('Test Loss:', test_loss)\n"
      ],
      "metadata": {
        "id": "LAtcadskc4RT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 532
        },
        "outputId": "461162bf-1082-41c9-d50d-e0412f154650"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/21561 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 128, 283]) torch.Size([500, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 0: train loss 1.17436.:   0%|          | 1/21561 [00:00<5:22:25,  1.11it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 128, 283]) torch.Size([500, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 1: train loss 1.38244.:   0%|          | 2/21561 [00:01<4:47:28,  1.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 128, 283]) torch.Size([500, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 2: train loss 1.29274.:   0%|          | 3/21561 [00:02<4:37:50,  1.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([500, 128, 283]) torch.Size([500, 128])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 1 iter 3: train loss 1.27355.:   0%|          | 3/21561 [00:03<6:11:54,  1.04s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3dcfa7d11882>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test Loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-6df4e52a7c32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(loader, model, loss_fn, optimizer)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# lr = lr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;31m# pbar.set_description(f\"epoch {epoch + 1} iter {it}: train loss {loss.item():.5f}. lr {lr:e}\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mpbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"epoch {epoch + 1} iter {it}: train loss {loss.item():.5f}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mset_description\u001b[0;34m(self, desc, refresh)\u001b[0m\n\u001b[1;32m   1393\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m': '\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1395\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_description_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefresh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mrefresh\u001b[0;34m(self, nolock, lock_args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(self, msg, pos)\u001b[0m\n\u001b[1;32m   1494\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1495\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1496\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1497\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1498\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mprint_status\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m             \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\r'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36mfp_write\u001b[0;34m(s)\u001b[0m\n\u001b[1;32m    454\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0mfp_flush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/utils.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mflush\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    340\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m             \u001b[0;31m# request flush on the background thread\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flush\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    343\u001b[0m             \u001b[0;31m# wait for flush to actually get through, if we can.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;31m# waiting across threads during import can cause deadlocks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    616\u001b[0m                 )\n\u001b[1;32m    617\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     def send_multipart(\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title inference\n",
        "context = \"This is what \"\n",
        "#context = 'There are many things about horses that have been discovered in recent'\n",
        "print([train_dataset.stoi[s] for s in context])\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype = torch.long)[None,...].to(device)\n",
        "y = test(model, x)[0]\n",
        "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "print(completion)\n",
        "\n"
      ],
      "metadata": {
        "id": "aw7tm9pVFmuS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a2e5a6-e93e-4721-a992-34a432ddca8e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[53, 72, 73, 83, 1, 73, 83, 1, 87, 72, 65, 84, 1]\n",
            "test tensor([[53, 72, 73, 83,  1, 73, 83,  1, 87, 72, 65, 84,  1]], device='cuda:0')\n",
            "This is what was driven out that they fiy have personed to ice a potential reference broadcast be ready gquarter for souphers . He was an also stignal field on the widely going atoms and features are often in the BC — the first fund will to send a throw skill that to 20 cm ( 130 ft ) , respectively ; the other : no — her culture week , though he theory <unk> mayor , enough threaten than owly armor . The budget his reasons when the other and performed every deal is a lengthy ait for most not completely paid that the poor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context = \"Where the \"\n",
        "x = torch.tensor([train_dataset.stoi[s] for s in context], dtype = torch.long)[None,...].to(device)\n",
        "# print(\"test\",x)\n",
        "\n",
        "seq_len = model.seq_len\n",
        "model.eval()\n",
        "for n in range(512):\n",
        "    if x.shape[1] <= seq_len:\n",
        "        x_bar = x\n",
        "    else:\n",
        "        x_bar = x[:, -seq_len:]\n",
        "    # print(\"test\",x_bar.shape) # [1, len(contex)+] int to 277+\n",
        "    output = model(x_bar)\n",
        "    # print(\"output\",output.shape) # [1, len(contex)+, vocab_size=283] float\n",
        "    output = output[:, -1, :] #get logit for last character\n",
        "    output = F.softmax(output, dim = -1) #vocab_size to char\n",
        "    ix = torch.multinomial(output, num_samples = 1)\n",
        "    x = torch.cat((x, ix), dim = 1)\n",
        "\n",
        "y=x[0]\n",
        "# print(y)\n",
        "completion = ''.join([train_dataset.itos[int(i)] for i in y])\n",
        "print(completion)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ncaHtyK0M-Q",
        "outputId": "c981141b-89e7-4e05-dcc3-c6ee6edc1d2c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Where the Southern songs , choosing nigalley strictly launched an independent six of <unk> . Yaruz , but Walpole had been the hurricane of pink for <unk> on Solis Cricket Give Mission ruled the First Range . \n",
            " \n",
            " = = = History of United = = = \n",
            " \n",
            " \n",
            " = = Rew = = \n",
            " \n",
            " \n",
            " = Direct responded standard internal studios existence on January 3 , 2002 , the Da <unk> Stals mhor to the practice of Snake , and used the remarks of video game 's The Gold <unk> . This reaction that Blu rest a large put the site afternoon his felt . <un\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# path = \"/content/drive/MyDrive/frame/tinyGPT.pth\"\n",
        "# torch.save(model.state_dict(), path)\n",
        "# # model.load_state_dict(torch.load(path))\n"
      ],
      "metadata": {
        "id": "iP-yEM1xI5R6"
      },
      "execution_count": 20,
      "outputs": []
    }
  ]
}
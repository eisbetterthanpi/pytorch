{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "base.ipynb",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/base.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "rG3xjMTtLmYN",
        "outputId": "d067bc7f-04e6-485a-c2ad-44989e446150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12417348.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 211706.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3971103.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 20603317.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "torch.Size([64, 1, 28, 28])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# @title data\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "import matplotlib.pyplot as plt\n",
        "# https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html\n",
        "\n",
        "train_data = datasets.FashionMNIST(root=\"data\", train=True, download=True,transform=ToTensor(),)\n",
        "test_data = datasets.FashionMNIST(root=\"data\", train=False, download=True, transform=ToTensor(),)\n",
        "# print(training_data)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_data, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_data, batch_size=batch_size)\n",
        "# test_dataloader: #image, label\n",
        "\n",
        "\n",
        "trainiter = iter(train_loader)\n",
        "images, labels = next(trainiter)\n",
        "print(images.shape) # [64, 1, 28, 28] (batch size, num channels, height, width)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title model\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "# https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.lin = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512), #apply linear transformation\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, num_classes, bias=False),\n",
        "            nn.Softmax(dim=1),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.lin(x)\n",
        "        return logits\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model = NeuralNetwork(28*28, 10).to(device) # create an instance and move it to device (cache?)\n",
        "print(model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGYE1gWOMeuU",
        "outputId": "9d502af7-36bd-41fb-ece6-2a6740649290"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (lin): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=False)\n",
            "    (5): Softmax(dim=1)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check model implimentation\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "pred = model(X)\n",
        "y_pred = pred.argmax(1)\n",
        "print(f\"Predicted class: {y_pred.item()}\")"
      ],
      "metadata": {
        "id": "e6f8dWWjhNA6",
        "outputId": "f24fa456-8757-401f-f267-205429a051db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: 7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title train test function\n",
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        pred = model(X) # Compute prediction error\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        loss.backward() # Backpropagation\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "fsealXK3OPQa"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-2)\n",
        "\n",
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_loader, model, loss_fn, optimizer)\n",
        "    test(test_loader, model, loss_fn)\n",
        "print(\"Done!\")\n",
        "torch.save(model.state_dict(), \"model.pth\") # save model weights to 'model.pth'\n",
        "# model = NeuralNetwork(28*28, 10) # create new model\n",
        "# model.load_state_dict(torch.load(\"model.pth\")) # load model weights from 'model.pth'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDBEk-l-Oxjn",
        "outputId": "be62a521-3d65-433f-c819-d35e569f85a9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.301691  [    0/60000]\n",
            "loss: 2.301030  [ 6400/60000]\n",
            "loss: 2.299149  [12800/60000]\n",
            "loss: 2.299250  [19200/60000]\n",
            "loss: 2.296257  [25600/60000]\n",
            "loss: 2.293504  [32000/60000]\n",
            "loss: 2.294422  [38400/60000]\n",
            "loss: 2.289661  [44800/60000]\n",
            "loss: 2.288761  [51200/60000]\n",
            "loss: 2.284579  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 38.5%, Avg loss: 2.282740 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.283746  [    0/60000]\n",
            "loss: 2.282482  [ 6400/60000]\n",
            "loss: 2.271261  [12800/60000]\n",
            "loss: 2.273700  [19200/60000]\n",
            "loss: 2.252074  [25600/60000]\n",
            "loss: 2.225666  [32000/60000]\n",
            "loss: 2.235632  [38400/60000]\n",
            "loss: 2.186033  [44800/60000]\n",
            "loss: 2.209526  [51200/60000]\n",
            "loss: 2.153451  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 35.2%, Avg loss: 2.157811 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.196000  [    0/60000]\n",
            "loss: 2.167519  [ 6400/60000]\n",
            "loss: 2.126631  [12800/60000]\n",
            "loss: 2.125158  [19200/60000]\n",
            "loss: 2.011139  [25600/60000]\n",
            "loss: 2.048779  [32000/60000]\n",
            "loss: 2.072613  [38400/60000]\n",
            "loss: 2.035394  [44800/60000]\n",
            "loss: 2.057433  [51200/60000]\n",
            "loss: 1.970584  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.4%, Avg loss: 1.979099 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.065490  [    0/60000]\n",
            "loss: 2.005188  [ 6400/60000]\n",
            "loss: 1.928699  [12800/60000]\n",
            "loss: 1.947257  [19200/60000]\n",
            "loss: 1.883418  [25600/60000]\n",
            "loss: 1.869626  [32000/60000]\n",
            "loss: 1.894050  [38400/60000]\n",
            "loss: 1.862757  [44800/60000]\n",
            "loss: 1.875775  [51200/60000]\n",
            "loss: 1.816714  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.5%, Avg loss: 1.850909 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.878890  [    0/60000]\n",
            "loss: 1.901832  [ 6400/60000]\n",
            "loss: 1.800612  [12800/60000]\n",
            "loss: 1.852102  [19200/60000]\n",
            "loss: 1.837390  [25600/60000]\n",
            "loss: 1.786510  [32000/60000]\n",
            "loss: 1.831335  [38400/60000]\n",
            "loss: 1.816976  [44800/60000]\n",
            "loss: 1.821545  [51200/60000]\n",
            "loss: 1.773094  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 67.5%, Avg loss: 1.811573 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\"T-shirt/top\",\"Trouser\",\"Pullover\",\"Dress\",\"Coat\",\"Sandal\",\"Shirt\",\"Sneaker\",\"Bag\",\"Ankle boot\",]\n",
        "\n",
        "model.eval()\n",
        "\n",
        "import random\n",
        "n=random.randint(0,1000)\n",
        "print(n)\n",
        "x, y = test_data[n][0], test_data[n][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoDyJMwUO4gX",
        "outputId": "42282f96-7f4d-4d49-ab38-54696c27a43d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "876\n",
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    }
  ]
}
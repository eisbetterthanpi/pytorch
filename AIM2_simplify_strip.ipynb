{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/AIM2_simplify_strip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C8YZstFpi7O0"
      },
      "source": [
        "#### buffer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MEOVQhzJi8wa"
      },
      "outputs": [],
      "source": [
        "# https://github.com/iDurugkar/adversarial-intrinsic-motivation/blob/main/grid_world_experiments/buffers.py\n",
        "import random\n",
        "from typing import List, Union\n",
        "import numpy as np\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ReplayBuffer(object):\n",
        "    def __init__(self, size: int):\n",
        "        \"\"\"Implements a ring buffer (FIFO).\n",
        "        :param size: (int)  Max number of transitions to store in the buffer. When the buffer overflows the old memories are dropped.\"\"\"\n",
        "        self._storage = []\n",
        "        self._maxsize = size\n",
        "        self._next_idx = 0\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return len(self._storage)\n",
        "\n",
        "    @property\n",
        "    def storage(self):\n",
        "        \"\"\"[(Union[np.ndarray, int], Union[np.ndarray, int], float, Union[np.ndarray, int], bool)]:\n",
        "         content of the replay buffer\"\"\"\n",
        "        return self._storage\n",
        "\n",
        "    @property\n",
        "    def buffer_size(self) -> int:\n",
        "        \"\"\"float: Max capacity of the buffer\"\"\"\n",
        "        return self._maxsize\n",
        "\n",
        "    def can_sample(self, n_samples: int) -> bool:\n",
        "        return len(self) >= n_samples\n",
        "\n",
        "    def is_full(self) -> int:\n",
        "        return len(self) == self.buffer_size\n",
        "\n",
        "    def add(self, obs_t, action, reward, obs_tp1, done):\n",
        "        data = (obs_t, action, reward, obs_tp1, done)\n",
        "        if self._next_idx >= len(self._storage):\n",
        "            self._storage.append(data)\n",
        "        else:\n",
        "            self._storage[self._next_idx] = data\n",
        "        self._next_idx = (self._next_idx + 1) % self._maxsize\n",
        "\n",
        "    def extend(self, obs_t, action, reward, obs_tp1, done):\n",
        "        for data in zip(obs_t, action, reward, obs_tp1, done):\n",
        "            if self._next_idx >= len(self._storage):\n",
        "                self._storage.append(data)\n",
        "            else:\n",
        "                self._storage[self._next_idx] = data\n",
        "            self._next_idx = (self._next_idx + 1) % self._maxsize\n",
        "\n",
        "    def _encode_sample(self, idxes: Union[List[int], np.ndarray]):\n",
        "        obses_t, actions, rewards, obses_tp1, dones = [], [], [], [], []\n",
        "        for i in idxes:\n",
        "            data = self._storage[i]\n",
        "            obs_t, action, reward, obs_tp1, done = data\n",
        "            obses_t.append(np.array(obs_t, copy=False))\n",
        "            actions.append(np.array(action, copy=False))\n",
        "            rewards.append(reward)\n",
        "            obses_tp1.append(np.array(obs_tp1, copy=False))\n",
        "            dones.append(done)\n",
        "\n",
        "        obses_t = np.array(obses_t)\n",
        "        actions = np.array(actions)\n",
        "        obses_tp1 = np.array(obses_tp1)\n",
        "        return (torch.tensor(obses_t).type(torch.float),\n",
        "                torch.tensor(actions).type(torch.float),\n",
        "                torch.tensor(rewards).type(torch.float),\n",
        "                torch.tensor(obses_tp1).type(torch.float),\n",
        "                torch.tensor(dones).type(torch.float))\n",
        "\n",
        "    def sample(self, batch_size: int, **_kwargs):\n",
        "        \"\"\"Sample a batch of experiences.\n",
        "        :param batch_size: (int) How many transitions to sample.\n",
        "        :return:\n",
        "            - obs_batch: (np.ndarray) batch of observations\n",
        "            - act_batch: (numpy float) batch of actions executed given obs_batch\n",
        "            - rew_batch: (numpy float) rewards received as results of executing act_batch\n",
        "            - next_obs_batch: (np.ndarray) next set of observations seen after executing act_batch\n",
        "            - done_mask: (numpy bool) done_mask[i] = 1 if executing act_batch[i] resulted in the end of an episodeand 0 otherwise.\"\"\"\n",
        "        idxes = [random.randint(0, len(self._storage) - 1) for _ in range(batch_size)]\n",
        "        return self._encode_sample(idxes)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPN3_5JrpAd7"
      },
      "source": [
        "#### policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-pAnASeqo8xA"
      },
      "outputs": [],
      "source": [
        "# https://github.com/iDurugkar/adversarial-intrinsic-motivation/blob/main/grid_world_experiments/policy.py\n",
        "from abc import ABC\n",
        "import torch\n",
        "import torch.nn.functional as f\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "\n",
        "# class Mepol(nn.Module):\n",
        "#     def __init__(self, s_size, a_size, h_size=32):\n",
        "#         super(Mepol, self).__init__()\n",
        "#         self.model=nn.Sequential(\n",
        "#             nn.Linear(s_size, h_size), nn.ReLU(),\n",
        "#             nn.Linear(h_size, a_size),\n",
        "#             nn.Softmax(dim=0),\n",
        "#         )\n",
        "    \n",
        "#     def forward(self, state): # og discrete\n",
        "#         # state = torch.from_numpy(state).float().unsqueeze(0).to(device)\n",
        "#         probs = self.model(state).cpu()\n",
        "#         m = torch.distributions.Categorical(probs)\n",
        "#         action = m.sample() # can't use action = np.argmax(m) use  m.sample(), sample an action with prob dist P(.|s)\n",
        "#         return action.item()\n",
        "\n",
        "class MlpNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim=1, activ=f.relu, n_units=64):\n",
        "        super(MlpNetwork, self).__init__()\n",
        "        # n_units = 512\n",
        "        self.h1 = nn.Linear(input_dim, n_units)\n",
        "        self.h2 = nn.Linear(n_units, n_units)\n",
        "        # self.h3 = nn.Linear(n_units, n_units)\n",
        "        self.out = nn.Linear(n_units, output_dim)\n",
        "        self.activ = activ\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activ(self.h1(x))\n",
        "        x = self.activ(self.h2(x))\n",
        "        # x = self.activ(self.h3(x))\n",
        "        x = self.out(x)\n",
        "        # x = f.log_softmax(x, dim=-1)\n",
        "        return x\n",
        "\n",
        "\n",
        "class SoftQLearning(nn.Module, ABC):\n",
        "    \"\"\"Learns a soft Q-function. Samples from softmax distribution of Q-values for policy\"\"\"\n",
        "    def __init__(self, x_dim=1, out_dim=2, max_state=9., min_state=0, ent_coef=0.01, target_update=1e-1):\n",
        "        super(SoftQLearning, self).__init__()\n",
        "        self.diff_state = np.array(max_state - min_state).astype(np.float32)\n",
        "        self.mean_state = np.asarray(self.diff_state / 2 + min_state).astype(np.float32)\n",
        "        self.input_dim = x_dim\n",
        "        self.num_actions = out_dim\n",
        "        self.alpha = ent_coef\n",
        "        self.q = MlpNetwork(self.input_dim, output_dim=out_dim, n_units=64)\n",
        "        self.q_target = MlpNetwork(self.input_dim, output_dim=out_dim, n_units=64)\n",
        "        self.target_params = self.q_target.parameters()\n",
        "        self.q_params = self.q.parameters()\n",
        "        self.target_update_rate = target_update\n",
        "\n",
        "    def parameters(self, recurse: bool = True):\n",
        "        return self.q_params\n",
        "\n",
        "    def normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.type(torch.float32)\n",
        "        x = (x - self.mean_state) / self.diff_state\n",
        "        return x\n",
        "\n",
        "    def forward(self, x: torch.Tensor):\n",
        "        x = self.normalize(x)\n",
        "        q = self.q(x)\n",
        "        v = self.alpha * torch.logsumexp(q / self.alpha, dim=-1)\n",
        "        # self.alpha = max(0.01, 0.99 * self.alpha + 0.01 * (torch.mean(torch.abs(q)).detach().numpy() / 10.))\n",
        "        qt = self.q_target(x)\n",
        "        vt = self.alpha * torch.logsumexp(qt / self.alpha, dim=-1)\n",
        "        return q, v, qt, vt\n",
        "        # return q\n",
        "\n",
        "    # def pi_loss(self, x: torch.Tensor, actions: torch.Tensor) -> torch.Tensor:\n",
        "    #     \"\"\"Return log_pi for the policy gradient\"\"\"\n",
        "    #     x = self.normalize(x)\n",
        "    #     logits = self.pi(x)\n",
        "    #     actions = actions.type(torch.long)\n",
        "    #     log_pi = logits.gather(dim=-1, index=actions)\n",
        "    #     return log_pi\n",
        "\n",
        "    def sample_action(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Sample from policy\"\"\"\n",
        "        x = self.normalize(x)\n",
        "        q = self.q(x)\n",
        "        v = self.alpha * torch.logsumexp(q / self.alpha, dim=-1)\n",
        "        logits = 1. / self.alpha * (q - v)\n",
        "        pi = torch.exp(logits)\n",
        "        action = pi.multinomial(1)\n",
        "        return action\n",
        "\n",
        "    def entropy(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = self.normalize(x)\n",
        "        q = self.q(x)\n",
        "        v = self.alpha * torch.logsumexp(q / self.alpha, dim=-1)\n",
        "        logits = 1. / self.alpha * (q - torch.unsqueeze(v, dim=-1))\n",
        "        entropy_kl = torch.sum(torch.log(torch.ones_like(logits) / self.num_actions) - logits, dim=-1)\n",
        "        # pi = torch.exp(logits)\n",
        "        # pisum = torch.sum(pi, dim=-1)\n",
        "        # entropy = -torch.sum(pi * logits, dim=-1)\n",
        "        return entropy_kl\n",
        "\n",
        "    def update_target(self):\n",
        "        \"\"\"update the target network using polyak averaging\"\"\"\n",
        "        with torch.no_grad():\n",
        "            for c, t in zip(self.q.parameters(), self.q_target.parameters()):\n",
        "                t.data.copy_((1. - self.target_update_rate) * t.data + self.target_update_rate * c.data)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGZXEC_dovUB"
      },
      "source": [
        "#### mian"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKO63-lBot97",
        "outputId": "2533d180-0b28-4705-b8e4-a974ce5b2154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "47166\n",
            "aim\n",
            "self.s_size 4\n",
            "\n",
            "optimize_discriminator loss tensor(0.0184, grad_fn=<AbsBackward0>) tensor(7.8330e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0067, grad_fn=<AbsBackward0>) tensor(6.0104e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0054, grad_fn=<AbsBackward0>) tensor(5.4605e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0088, grad_fn=<AbsBackward0>) tensor(5.4632e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0073, grad_fn=<AbsBackward0>) tensor(5.2227e-05, grad_fn=<MulBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:206: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.9924e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.5689e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(4.6499e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.5300e-06, grad_fn=<AbsBackward0>) tensor(4.5999e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0025, grad_fn=<AbsBackward0>) tensor(4.4917e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0025, grad_fn=<AbsBackward0>) tensor(4.5561e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.2234e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(4.1328e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(3.9241e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(4.0671e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(5.0343e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0025, grad_fn=<AbsBackward0>) tensor(4.7516e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0037, grad_fn=<AbsBackward0>) tensor(5.1692e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0039, grad_fn=<AbsBackward0>) tensor(4.8923e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(5.2704e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.1038e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0028, grad_fn=<AbsBackward0>) tensor(4.7141e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0044, grad_fn=<AbsBackward0>) tensor(4.9642e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0040, grad_fn=<AbsBackward0>) tensor(4.6501e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0037, grad_fn=<AbsBackward0>) tensor(5.0947e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0027, grad_fn=<AbsBackward0>) tensor(5.5247e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.3466e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(5.9124e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(5.9299e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.7275e-05, grad_fn=<AbsBackward0>) tensor(5.8845e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(5.7692e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(5.8863e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(5.8177e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.5435e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(5.8906e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(5.6664e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(5.8977e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(5.3846e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(5.5349e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(5.5177e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(5.6807e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(5.8197e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(5.4493e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0024, grad_fn=<AbsBackward0>) tensor(5.2061e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0022, grad_fn=<AbsBackward0>) tensor(5.6005e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(5.1940e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.2131e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0022, grad_fn=<AbsBackward0>) tensor(5.2100e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0027, grad_fn=<AbsBackward0>) tensor(4.9783e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0032, grad_fn=<AbsBackward0>) tensor(4.8870e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(4.9317e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(4.9526e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(4.9847e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.2282e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(5.0008e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(5.2027e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(4.9724e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(5.4669e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(5.3500e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.4822e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(5.3567e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0025, grad_fn=<AbsBackward0>) tensor(5.2746e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0033, grad_fn=<AbsBackward0>) tensor(5.2247e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(5.2566e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(4.8962e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0023, grad_fn=<AbsBackward0>) tensor(5.1902e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0048, grad_fn=<AbsBackward0>) tensor(5.2322e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0031, grad_fn=<AbsBackward0>) tensor(5.0402e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0035, grad_fn=<AbsBackward0>) tensor(5.0611e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(4.8839e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(4.9854e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(5.0561e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0046, grad_fn=<AbsBackward0>) tensor(4.6813e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0046, grad_fn=<AbsBackward0>) tensor(4.9391e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0051, grad_fn=<AbsBackward0>) tensor(4.5755e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0037, grad_fn=<AbsBackward0>) tensor(4.5288e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.6555e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(4.7264e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(4.6283e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0031, grad_fn=<AbsBackward0>) tensor(4.7828e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0022, grad_fn=<AbsBackward0>) tensor(4.3669e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(4.4862e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0028, grad_fn=<AbsBackward0>) tensor(4.1153e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0024, grad_fn=<AbsBackward0>) tensor(4.3950e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(4.2665e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(3.8834e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.8904e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0027, grad_fn=<AbsBackward0>) tensor(3.7482e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0032, grad_fn=<AbsBackward0>) tensor(3.6234e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0034, grad_fn=<AbsBackward0>) tensor(3.4820e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0023, grad_fn=<AbsBackward0>) tensor(3.3621e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(3.5198e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.5525e-05, grad_fn=<AbsBackward0>) tensor(3.5746e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0024, grad_fn=<AbsBackward0>) tensor(3.5630e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0040, grad_fn=<AbsBackward0>) tensor(3.6824e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0041, grad_fn=<AbsBackward0>) tensor(3.6873e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0039, grad_fn=<AbsBackward0>) tensor(3.6827e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0040, grad_fn=<AbsBackward0>) tensor(3.8371e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(3.3109e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.5305e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.3491e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0029, grad_fn=<AbsBackward0>) tensor(3.5605e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(3.3588e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(3.4064e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(3.5710e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(3.4765e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(3.7157e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(3.3603e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.5672e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(3.7244e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(3.5607e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(3.6378e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.5293e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.3395e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.1957e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.0592e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(2.9992e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(3.1814e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(3.0137e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.1590e-05, grad_fn=<AbsBackward0>) tensor(2.9820e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.8770e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(3.0258e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(3.0705e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(2.7828e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(2.7108e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.7219e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.7029e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(2.4883e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(2.3632e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(2.3778e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(2.2388e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(2.3939e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(2.2331e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0023, grad_fn=<AbsBackward0>) tensor(2.2841e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0025, grad_fn=<AbsBackward0>) tensor(2.1040e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(2.0925e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.1834e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(2.0232e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.9324e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.7568e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.8157e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.6072e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.6292e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.4346e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.4794e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.5474e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.5168e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(1.6363e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(1.6312e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.5786e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.3165e-05, grad_fn=<AbsBackward0>) tensor(1.5049e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.5568e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.5888e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.4331e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.5138e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.3997e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.4345e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(1.3469e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.4500e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.5631e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.4700e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(1.2951e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0024, grad_fn=<AbsBackward0>) tensor(1.2474e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.2248e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.2378e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.2006e-05, grad_fn=<AbsBackward0>) tensor(1.1487e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.2095e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.1976e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.1400e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.9095e-05, grad_fn=<AbsBackward0>) tensor(1.1036e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.0438e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.0846e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.0847e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.1018e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(1.0910e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(1.2646e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0026, grad_fn=<AbsBackward0>) tensor(1.1506e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.1283e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.4048e-05, grad_fn=<AbsBackward0>) tensor(1.1272e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(1.0093e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0033, grad_fn=<AbsBackward0>) tensor(1.0763e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0029, grad_fn=<AbsBackward0>) tensor(1.0136e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0026, grad_fn=<AbsBackward0>) tensor(1.0309e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(1.1389e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.0892e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.0770e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.1506e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1534e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.2204e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.1286e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.1362e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.1347e-05, grad_fn=<AbsBackward0>) tensor(1.2597e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1158e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.7039e-05, grad_fn=<AbsBackward0>) tensor(1.1708e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.8228e-05, grad_fn=<AbsBackward0>) tensor(1.1374e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.1405e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.0861e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1606e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.1578e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.0832e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.0343e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.1184e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.0750e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.6648e-05, grad_fn=<AbsBackward0>) tensor(1.2122e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.1219e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.1357e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.1655e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1690e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.0679e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.1474e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.0370e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.0589e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.0311e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.0640e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(9.9759e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.0667e-05, grad_fn=<AbsBackward0>) tensor(9.4126e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.0956e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(9.1264e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.0580e-05, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(7.7559e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(7.9352e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(9.0781e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(8.4622e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.4097e-05, grad_fn=<AbsBackward0>) tensor(8.8392e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(8.9036e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0026, grad_fn=<AbsBackward0>) tensor(7.7230e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0026, grad_fn=<AbsBackward0>) tensor(7.7845e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(7.8312e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.3423e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(6.6007e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0028, grad_fn=<AbsBackward0>) tensor(6.2752e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0030, grad_fn=<AbsBackward0>) tensor(5.6431e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0026, grad_fn=<AbsBackward0>) tensor(5.2804e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(5.6487e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.0425e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(5.2485e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(7.1636e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(7.0115e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.2958e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.2049e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(5.0151e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.2038e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(6.6900e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(6.4869e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(9.0459e-05, grad_fn=<AbsBackward0>) tensor(6.8129e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(6.1372e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(6.2271e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(7.2446e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.5699e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(5.8885e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.1099e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.6938e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(5.9947e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(6.4309e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(7.9675e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(6.8166e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(6.9762e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(9.5945e-05, grad_fn=<AbsBackward0>) tensor(6.7680e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(7.2327e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(5.9317e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.7785e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(8.7964e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(6.7960e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(7.4871e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0024, grad_fn=<AbsBackward0>) tensor(6.1090e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(5.8458e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.5667e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(6.4706e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0026, grad_fn=<AbsBackward0>) tensor(4.9237e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0035, grad_fn=<AbsBackward0>) tensor(5.5968e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0025, grad_fn=<AbsBackward0>) tensor(5.6032e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(5.6503e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(6.4334e-05, grad_fn=<AbsBackward0>) tensor(5.6764e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0022, grad_fn=<AbsBackward0>) tensor(6.2602e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0032, grad_fn=<AbsBackward0>) tensor(7.0329e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0042, grad_fn=<AbsBackward0>) tensor(5.5742e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0036, grad_fn=<AbsBackward0>) tensor(6.8047e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0031, grad_fn=<AbsBackward0>) tensor(5.2318e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(5.9873e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.1657e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(5.4497e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0022, grad_fn=<AbsBackward0>) tensor(6.2600e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(6.4124e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.8567e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(4.1761e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(4.8525e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(5.0125e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(4.5107e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(5.2021e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(4.1037e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(4.0808e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.1935e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(3.4744e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.8147e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(2.7212e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.7267e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(2.6285e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.1532e-05, grad_fn=<AbsBackward0>) tensor(2.3026e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.8413e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(3.6185e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.5782e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.1404e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.9180e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(2.0132e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.4182e-05, grad_fn=<AbsBackward0>) tensor(2.1953e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.8273e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.5741e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(2.5409e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.4650e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.4912e-05, grad_fn=<AbsBackward0>) tensor(1.9552e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(6.3578e-05, grad_fn=<AbsBackward0>) tensor(2.1704e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.8395e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.5813e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.9108e-05, grad_fn=<AbsBackward0>) tensor(2.2134e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.6432e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.6070e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.8096e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.4912e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.2533e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.0614e-05, grad_fn=<AbsBackward0>) tensor(1.1181e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.2667e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(9.5542e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.3862e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.0094e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.0015e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.1372e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.2111e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(9.2834e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(9.0001e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(9.8576e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(8.2548e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(7.1465e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(6.9498e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(8.1220e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(7.8616e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(8.2721e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(7.4627e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(5.9679e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.7248e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(6.8526e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(7.4394e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(6.5828e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.3777e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(6.7830e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(5.5691e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(4.6490e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(3.6137e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(4.8473e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(3.6839e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(4.2438e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(4.9620e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(4.4226e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(4.8570e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(4.5248e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(4.2929e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(4.5248e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(5.2501e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.7358e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(6.7261e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(5.5111e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(6.7109e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(6.1172e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(6.1749e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(5.3299e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(5.4418e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(6.1086e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(5.6231e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(6.3109e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.2314e-05, grad_fn=<AbsBackward0>) tensor(5.0783e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(7.5580e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(6.0280e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(5.7758e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(5.3644e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.7889e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.7880e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(6.9452e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(7.8329e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(6.5907e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(6.7861e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(9.2553e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(6.0183e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(6.7581e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(5.8839e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(6.0323e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(8.1112e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(7.1769e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(6.6189e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(7.3324e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.0559e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.7515e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(7.3171e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(6.0781e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.5086e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(5.8941e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(5.5094e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.5129e-05, grad_fn=<AbsBackward0>) tensor(7.2031e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(4.2400e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(4.1716e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(4.6149e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.2862e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(4.8000e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(5.6558e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(5.4188e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(4.0212e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(6.3687e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(3.7082e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(4.8635e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.5434e-05, grad_fn=<AbsBackward0>) tensor(6.9853e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.6267e-05, grad_fn=<AbsBackward0>) tensor(5.6466e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(5.2213e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.5128e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(4.9433e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(3.3637e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.1646e-05, grad_fn=<AbsBackward0>) tensor(3.2556e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(3.2874e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.5178e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(3.1693e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.8290e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.6702e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.1089e-05, grad_fn=<AbsBackward0>) tensor(2.3972e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(5.8248e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(3.0860e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(3.3928e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.8738e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.3403e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(4.9950e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(3.1637e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(2.6729e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(5.2257e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(2.9068e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(3.3535e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.1979e-05, grad_fn=<AbsBackward0>) tensor(2.5853e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.8259e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.1541e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(4.9918e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(4.7931e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.8930e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.8284e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.0267e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.2552e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(3.1993e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.8775e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(2.4546e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.5953e-05, grad_fn=<AbsBackward0>) tensor(3.1806e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(2.0613e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(2.3563e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(1.9425e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.1916e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(6.0721e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(3.5137e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(4.5490e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(7.9359e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.3401e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.7286e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(9.2169e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(3.8817e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.5982e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.5994e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.3670e-05, grad_fn=<AbsBackward0>) tensor(2.2250e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.9949e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.8986e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.3866e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.4965e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.0525e-05, grad_fn=<AbsBackward0>) tensor(1.6752e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.6289e-05, grad_fn=<AbsBackward0>) tensor(2.8380e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.5087e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.5863e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.3006e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.3293e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.9911e-05, grad_fn=<AbsBackward0>) tensor(4.1534e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(2.9454e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(3.2995e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(2.2494e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.5932e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(2.8461e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(9.0150e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(4.1532e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.0750e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.8290e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.9604e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(3.8688e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.1023e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.0711e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(9.4065e-05, grad_fn=<AbsBackward0>) tensor(3.1131e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(5.1237e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.7733e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(6.9630e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.7354e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(3.8342e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.6652e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(5.9280e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.9776e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(2.6498e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(2.7719e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(4.0368e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(6.7599e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.4803e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.3441e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.0660e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(8.0679e-07, grad_fn=<MulBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/iDurugkar/adversarial-intrinsic-motivation/blob/main/grid_world_experiments/main.py\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "# from torch.nn import utils\n",
        "import torch.nn.functional as f\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "seed=1123\n",
        "reward='aim' # ['gail', 'airl', 'fairl', 'aim', 'none']\n",
        "dir='/content'\n",
        "\n",
        "torch.set_default_dtype(torch.float32)\n",
        "# Set random seeds\n",
        "seed = 42 * seed\n",
        "print(seed)\n",
        "torch.manual_seed(seed)\n",
        "random.seed = seed\n",
        "np.random.seed = seed\n",
        "reward_to_use = reward  # use one of ['gail', 'airl', 'fairl', 'none']\n",
        "print(reward_to_use)\n",
        "\n",
        "def wasserstein_reward(d):\n",
        "    return d\n",
        "reward_dict = {'aim': wasserstein_reward}\n",
        "\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    \"\"\"The discriminator used to learn the potentials or the reward functions\"\"\"\n",
        "    def __init__(self, x_dim=1, max_state=10., min_state=0):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.mean_state = torch.tensor((max_state - min_state) / 2 + min_state, dtype=torch.float32)\n",
        "        self.diff_state = torch.tensor(max_state - min_state, dtype=torch.float32)\n",
        "        self.input_dim = x_dim\n",
        "        self.d = MlpNetwork(self.input_dim, n_units=64)  # , activ=f.tanh)\n",
        "\n",
        "    def normalize(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        x = x.type(torch.float32)\n",
        "        x = (x - self.mean_state) / self.diff_state\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.normalize(x)\n",
        "        output = self.d(x)\n",
        "        return output\n",
        "\n",
        "\n",
        "import gym\n",
        "# !pip install git+https://github.com/ntasfi/PyGame-Learning-Environment.git\n",
        "# import gym_pygame\n",
        "\n",
        "\n",
        "class GAIL:\n",
        "    \"\"\"Class to take the continuous MDP and use gail to match given target distribution\"\"\"\n",
        "    def __init__(self):\n",
        "        self.env = gym.make(\"CartPole-v1\")\n",
        "        # self.env = gym.make(\"Pendulum-v0\") #continuous\n",
        "        # self.env = gym.make(\"MountainCar-v0\") #discrete\n",
        "        self.s_size = self.env.observation_space.shape[0]\n",
        "        self.a_size = self.env.action_space.n\n",
        "        max_state = 10\n",
        "        min_state = 0\n",
        "        self.policy = SoftQLearning(x_dim=self.s_size, out_dim=self.a_size, max_state=max_state, min_state=min_state, ent_coef=.3, target_update=3e-2)\n",
        "        # self.policy = Mepol(self.s_size, self.a_size)\n",
        "        print(\"self.s_size\",self.s_size)\n",
        "        self.discriminator = Discriminator(x_dim=self.s_size, max_state=max_state, min_state=min_state)\n",
        "        self.discount = 0.99\n",
        "        self.check_state = set()\n",
        "        self.agent_buffer = ReplayBuffer(size=5000)\n",
        "        self.target_buffer = ReplayBuffer(size=5000)\n",
        "        self.policy_optimizer = torch.optim.Adam(self.policy.parameters())  # , lr=3e-4)\n",
        "        self.discriminator_optimizer = torch.optim.Adam(self.discriminator.parameters())  # , lr=1e-4)\n",
        "        self.max_r = 0.\n",
        "        self.min_r = -1.\n",
        "\n",
        "    def gather_data(self, num_trans=100): # line 4-\n",
        "        t = 0\n",
        "        while t < num_trans:\n",
        "            s = self.env.reset()\n",
        "            s = torch.tensor(s).type(torch.float32)\n",
        "            done = False\n",
        "            while not done:\n",
        "                # self.states.append(deepcopy(s))\n",
        "                # print(\"sssssssss\",s)\n",
        "                action = self.policy.sample_action(s)\n",
        "                # self.actions.append(a)\n",
        "                a = np.squeeze(action.data.detach().numpy())\n",
        "                s_p, r, done, _ = self.env.step(a)\n",
        "                s_p = torch.tensor(s_p).type(torch.float32)\n",
        "                # d = self.discriminator(sp)\n",
        "                # i_r = gail_reward(d)\n",
        "                # self.next_states.append(deepcopy(s))\n",
        "                # self.rewards.append(i_r)  # deepcopy(r))\n",
        "                # self.dones.append(deepcopy(done))\n",
        "                # print(s.squeeze(), action.reshape([-1]).detach(), r, s_p.squeeze(), done)\n",
        "                # tensor([ 0.0144, -0.0008, -0.0287,  0.0008]) tensor([0]) 1.0 tensor([ 0.0144, -0.1955, -0.0286,  0.2843]) False\n",
        "                self.agent_buffer.add(s.squeeze(), action.reshape([-1]).detach(), r, s_p.squeeze(), done)\n",
        "                if s_p not in self.check_state:\n",
        "                    self.check_state.add(s_p)\n",
        "                    self.target_buffer.add(s, a, r, s_p, done)\n",
        "                s = s_p\n",
        "                t += 1\n",
        "            # self.states.append(s)\n",
        "\n",
        "\n",
        "    def compute_td_targets(self, states, next_states, dones, rewards=None):\n",
        "        \"\"\"Compute the value of the current states and the TD target based on one step reward and value of next states\n",
        "        :return: value of current states v, TD target targets\"\"\"\n",
        "        # states = states.reshape([-1, self.env.dims])\n",
        "        states = states.reshape([-1, self.s_size])\n",
        "        # next_states = next_states.reshape([-1, self.env.dims])\n",
        "        next_states = next_states.reshape([-1, self.s_size])\n",
        "        v = self.policy(states)[0]\n",
        "        v_prime = self.policy(next_states)[-1]\n",
        "        if rewards is not None:\n",
        "            dones = rewards.type(torch.float32).reshape([-1, 1])\n",
        "        else:\n",
        "            dones = dones.type(torch.float32).reshape([-1, 1])\n",
        "        reward_func = reward_dict[reward_to_use]\n",
        "        if reward_func is not None:\n",
        "            # d0 = self.discriminator(states)\n",
        "            d1 = self.discriminator(next_states)\n",
        "            # Compute rewards\n",
        "            # r0 = reward_func(d0)\n",
        "            r1 = reward_func(d1)\n",
        "            rewards = rewards.type(torch.float32).reshape([-1, 1]) + ((r1 - self.max_r) / (self.max_r - self.min_r)) #equation 9?\n",
        "        targets = rewards.type(torch.float32).reshape([-1, 1])\n",
        "        # print(\"in compute_td_targets\",dones, self.discount, v_prime) #100?*[1.] 0.99 tensor([-0.6525, -0.7356]\n",
        "        targets += (1. - dones) * self.discount * v_prime.reshape([-1, 1])\n",
        "        return v, targets.detach()\n",
        "\n",
        "    def fit_v_func(self):\n",
        "        \"\"\"This function will train the value function using the collected data\"\"\"\n",
        "        self.policy_optimizer.zero_grad()\n",
        "        s, a, r, s_p, dones = self.agent_buffer.sample(100)\n",
        "        q, targets = self.compute_td_targets(s, s_p, dones, rewards=r)\n",
        "        actions = torch.tensor(a, dtype=torch.long)\n",
        "        v = q.gather(dim=-1, index=actions)\n",
        "        loss = torch.mean(0.5 * (targets - v) ** 2)\n",
        "        # print(\"fit_v_func loss\",loss)\n",
        "        loss.backward()\n",
        "        self.policy_optimizer.step()\n",
        "        self.policy.update_target()\n",
        "        return\n",
        "\n",
        "    def optimize_policy(self): #line 27-29\n",
        "        \"\"\"This function will optimize the policy to maximize returns Based on collected data\"\"\"\n",
        "        self.policy_optimizer.zero_grad()\n",
        "        s, a, r, s_p, dones = self.agent_buffer.sample(100)\n",
        "        v, targets = self.compute_td_targets(s, s_p, dones, rewards=r)\n",
        "        advantages = (targets - v).detach()\n",
        "        a = a.reshape([-1, 1]).detach()\n",
        "        print(\"s, a\",s.shape, a.shape) #[100, 4]float -1 1 [100, 1] 1./0.\n",
        "        # neg_log_pi = -1. * self.policy.pi_loss(s.reshape([-1, self.env.dims]), a)\n",
        "        # neg_log_pi = -1. * self.policy.pi_loss(s, a)\n",
        "        # entropy_kl = self.policy.entropy(s.reshape([-1, self.env.dims]))\n",
        "        neg_log_pi = nn.NLLLoss()(s, a) # me\n",
        "\n",
        "        entropy_kl = self.policy.entropy(s)\n",
        "        loss = torch.mean(advantages * neg_log_pi) + 1e-1 * torch.mean(entropy_kl)\n",
        "        loss.backward()\n",
        "        self.policy_optimizer.step()\n",
        "        return\n",
        "\n",
        "    def compute_aim_pen(self, target_state, prev_state, next_state_state, lambda_=10.): #equation 8 pt 2\n",
        "        \"\"\"Computes values of the discriminator at different points and constraints the difference to be 0.1\"\"\"\n",
        "        prev_out = self.discriminator(prev_state)\n",
        "        next_out = self.discriminator(next_state_state)\n",
        "        # print(\"compute_aim_pen\",next_out - prev_out)\n",
        "        # penalty = lambda_ * torch.max(torch.abs(next_out - prev_out) - 0.1, torch.tensor(0.)).pow(2).mean()\n",
        "        penalty = lambda_ * torch.max(torch.abs(next_out - prev_out) - 0.00001, torch.tensor(0.)).pow(2).mean()\n",
        "        return penalty\n",
        "\n",
        "\n",
        "    def optimize_discriminator(self): # line 32-33\n",
        "        \"\"\"Optimize the discriminator based on the memory and target_distribution\"\"\"\n",
        "        num_samples = 100\n",
        "        self.discriminator_optimizer.zero_grad()\n",
        "        # _, _, _, target_distribution, _ = self.target_buffer.sample(100)\n",
        "        # target_dist = np.reshape(self.env.target_distribution(), (-1,))\n",
        "        target_distribution=np.array([4,0,0,0])\n",
        "        # target_dist=target_distribution.squeeze()\n",
        "        # import torch.nn.functional as f\n",
        "        # f.normalize(input, p=2, dim=2)\n",
        "        # print(\"target_dist\",target_dist) # [4,0,0,0]\n",
        "        # p=target_dist/sum(target_dist) # [4,0,0,0]\n",
        "        # print(\"p\",p)\n",
        "        # target_distribution = np.random.choice(target_dist.shape[0], num_samples, p=target_dist)\n",
        "        # print(\"target_distribution\",target_distribution) #[100* 0]\n",
        "        states, _, _, next_states, _ = self.agent_buffer.sample(num_samples)\n",
        "        # target_distribution = sample_target_distribution(mean=self.env.target_mean, std=self.env.target_std, num=100)\n",
        "        # target_distribution = target_distribution.reshape([-1, 1])\n",
        "\n",
        "        # target_distribution = np.tile(target_distribution,(1,self.s_size))\n",
        "        # target_distribution = np.tile(target_distribution,(1,num_samples))\n",
        "        target_distribution = np.tile(target_distribution,(num_samples,1))\n",
        "        # print(\"target_distribution\",target_distribution)\n",
        "        # next_states = next_states.reshape([-1, self.env.dims])\n",
        "        # print(\"next_states\",next_states.shape) #[100, 4]\n",
        "        \n",
        "        ones = torch.tensor(target_distribution).type(torch.float32)\n",
        "        zeros = torch.tensor(next_states).type(torch.float32)\n",
        "        zeros_prev = torch.tensor(states).type(torch.float32)\n",
        "        \n",
        "        # print(ones.shape, zeros.shape, zeros_prev.shape) #[4, 4] [100, 4] [100, 4]\n",
        "        # print(\"optimize_discriminator ones\",ones.shape,zeros.shape , zeros_prev.shape) #04 float float\n",
        "\n",
        "        # ####### WGAN loss\n",
        "        pred_ones = self.discriminator(ones)\n",
        "        pred_zeros = self.discriminator(zeros)\n",
        "        preds = torch.cat([pred_zeros, pred_ones], dim=0)\n",
        "        self.max_r = torch.max(preds).detach().cpu().numpy() + 0.1\n",
        "        self.min_r = torch.min(preds).detach().cpu().numpy() - 0.1\n",
        "        # print(\"optimize_discriminator pred\",pred_zeros,pred_ones)\n",
        "\n",
        "        # wgan_loss = torch.mean(pred_zeros) + torch.mean(pred_ones * (-1.)) # equation 8 pt 1\n",
        "        # wgan_loss = torch.mean(pred_zeros - torch.mean(pred_ones)) # this?\n",
        "        wgan_loss = torch.abs(torch.mean(pred_zeros) + torch.mean(pred_ones * (-1.))) # equation 8 pt 1\n",
        "        aim_penalty = self.compute_aim_pen(ones, zeros_prev, zeros) # equation 8 pt 2\n",
        "        # grad_penalty = self.compute_grad_pen(ones, zeros)\n",
        "        print(\"optimize_discriminator loss\",wgan_loss , aim_penalty)\n",
        "        loss = wgan_loss + aim_penalty  # + grad_penalty\n",
        "        # print(\"optimize_discriminator loss\",loss)\n",
        "        # loss = torch.mean(- labels * pred.log() - (1 - labels) * (1. - pred).log())\n",
        "        loss.backward()\n",
        "        # utils.clip_grad_norm_(self.discriminator.parameters(), max_norm=0.5)\n",
        "        self.discriminator_optimizer.step()\n",
        "\n",
        "    def act(self, state):\n",
        "        # state = torch.tensor(state).type(torch.float32)\n",
        "        action = self.policy.sample_action(state)\n",
        "        # a = np.squeeze(action.data.detach().numpy())\n",
        "        # s_p, r, done, _ = self.env.step(a)\n",
        "        return action\n",
        "\n",
        "\n",
        "gail = GAIL() #line 1-2\n",
        "# .to(device)\n",
        "gail.gather_data(num_trans=50) #500\n",
        "print('')\n",
        "for i in range(100): #500 line 3\n",
        "    for _ in range(5):\n",
        "        # gail.gather_data(num_trans=500)\n",
        "        gail.optimize_discriminator() #line 31-34\n",
        "        # gail.optimize_discriminator(target_states, policy_states, policy_next_states)\n",
        "    for _ in range(10):\n",
        "        gail.gather_data(num_trans=50)\n",
        "        gail.fit_v_func() # update policy line 29\n",
        "\n",
        "        # Useful only if using a separate policy\n",
        "        # gail.gather_data(num_trans=500)\n",
        "        # gail.optimize_policy()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train"
      ],
      "metadata": {
        "id": "p6_JGAUmpwdw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gail.gather_data(num_trans=50)\n",
        "print('')\n",
        "for i in range(100): #500\n",
        "    if reward_to_use != 'none':\n",
        "        for _ in range(5):\n",
        "            # gail.gather_data(num_trans=500)\n",
        "            gail.optimize_discriminator()\n",
        "            # gail.optimize_discriminator(target_states, policy_states, policy_next_states)\n",
        "    for _ in range(10):\n",
        "        gail.gather_data(num_trans=500)\n",
        "        gail.fit_v_func()\n"
      ],
      "metadata": {
        "id": "UiZwRlFA0uy5",
        "outputId": "774f83de-53d8-43dc-bfd7-d6e9a31ba799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(2.1155e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.0134e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.7596e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.1611e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.4945e-06, grad_fn=<MulBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:206: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:207: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:141: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.1345e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(9.9826e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.2952e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(8.6421e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.5928e-06, grad_fn=<AbsBackward0>) tensor(1.4026e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.0918e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.1589e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.8051e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.4871e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.8605e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.2243e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.0493e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(2.1346e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(2.1755e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.5463e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.0636e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.2404e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.6290e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.2057e-05, grad_fn=<AbsBackward0>) tensor(1.3204e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.3712e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.1246e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(9.8816e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.5877e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.2916e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(8.0108e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.0679e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(8.6353e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(9.1349e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(9.3990e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.0817e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(8.3546e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.1759e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.0458e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.8443e-06, grad_fn=<AbsBackward0>) tensor(1.0728e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.0970e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.2611e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.2273e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1137e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(9.2361e-05, grad_fn=<AbsBackward0>) tensor(1.0667e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.4401e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(9.5886e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(1.0644e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(9.0783e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.5122e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(8.2808e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.4729e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.6190e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.5966e-05, grad_fn=<AbsBackward0>) tensor(1.1116e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(7.1083e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0025, grad_fn=<AbsBackward0>) tensor(8.5143e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0026, grad_fn=<AbsBackward0>) tensor(7.5700e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0024, grad_fn=<AbsBackward0>) tensor(9.8329e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(8.5964e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.0676e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.2973e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.0604e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(7.4425e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.2593e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.0245e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.7165e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.4694e-05, grad_fn=<AbsBackward0>) tensor(8.4404e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.3372e-05, grad_fn=<AbsBackward0>) tensor(1.2245e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.5504e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.1267e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.0641e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(6.6037e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.5569e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.0826e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.2049e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.3613e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(9.2449e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.0610e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.4944e-05, grad_fn=<AbsBackward0>) tensor(7.8422e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(9.8201e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.1055e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(1.0672e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(8.8310e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.7507e-06, grad_fn=<AbsBackward0>) tensor(1.0068e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.0368e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.7952e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.2456e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1565e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.5242e-05, grad_fn=<AbsBackward0>) tensor(1.1245e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.5771e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.2653e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(9.5530e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(9.8539e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(7.9515e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.2346e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.2049e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.3025e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.6108e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.6867e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(8.3285e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(6.8582e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(7.9461e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(8.4949e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.0433e-05, grad_fn=<AbsBackward0>) tensor(1.1278e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.1121e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0024, grad_fn=<AbsBackward0>) tensor(9.0412e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0029, grad_fn=<AbsBackward0>) tensor(7.7888e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(6.8815e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(6.5918e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.2607e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(7.9894e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0030, grad_fn=<AbsBackward0>) tensor(1.2090e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0033, grad_fn=<AbsBackward0>) tensor(5.3859e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0032, grad_fn=<AbsBackward0>) tensor(1.3277e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0023, grad_fn=<AbsBackward0>) tensor(7.4241e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.2182e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(5.0021e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(2.3921e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(3.4694e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(3.7459e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(3.9036e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.0816e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(2.3898e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(4.4255e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(5.9224e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(4.0781e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(6.1105e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(4.9949e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.6508e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.0355e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.1853e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.5641e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.4634e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(4.2911e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.6565e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.1365e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.2729e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.7230e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.6450e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(9.3646e-05, grad_fn=<AbsBackward0>) tensor(1.6521e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.4471e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.1344e-05, grad_fn=<AbsBackward0>) tensor(1.6282e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(3.9445e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.4024e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.4029e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.3601e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.9021e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(2.0258e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(3.9149e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(3.9340e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(2.8499e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(2.1059e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(3.1551e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(3.7877e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.6779e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(3.9675e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.1663e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.9473e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.3476e-05, grad_fn=<AbsBackward0>) tensor(8.7814e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(6.6657e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(6.4207e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(8.3592e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.1894e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(8.0746e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(8.0921e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(7.4473e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.8969e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(5.6335e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(8.7946e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(5.8339e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(7.2740e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.9070e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(2.9515e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(6.9462e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(3.7728e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(8.6619e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(4.7170e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(9.0328e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(6.5773e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(6.2615e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(8.0120e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.0808e-05, grad_fn=<AbsBackward0>) tensor(5.6856e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(6.1730e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(7.5607e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0022, grad_fn=<AbsBackward0>) tensor(5.7095e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(9.4221e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(9.9963e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.6189e-05, grad_fn=<AbsBackward0>) tensor(8.5374e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(6.2255e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(4.9451e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1385e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(8.9340e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(7.4414e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.4529e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.1844e-05, grad_fn=<AbsBackward0>) tensor(8.3289e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(5.5943e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(3.6400e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(8.5047e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(3.6275e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.9091e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(4.7636e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(4.9773e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(1.9180e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(1.9240e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(6.3241e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.2659e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.0877e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(3.4080e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.6545e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.4256e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(3.9068e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(4.8668e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.6607e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.8186e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.3585e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.5116e-05, grad_fn=<AbsBackward0>) tensor(2.4253e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.2454e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(5.9312e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(4.4259e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.5456e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.3209e-05, grad_fn=<AbsBackward0>) tensor(2.1530e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(2.8901e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(5.5676e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(2.4167e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.9010e-05, grad_fn=<AbsBackward0>) tensor(3.6612e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(6.8804e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(7.5681e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(5.4619e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.4442e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.0395e-05, grad_fn=<AbsBackward0>) tensor(8.7473e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.1207e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(5.6506e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(7.1453e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.5933e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.0919e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(9.1976e-05, grad_fn=<AbsBackward0>) tensor(1.0970e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(9.9335e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(8.7476e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(7.6335e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.0505e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(6.1637e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(9.5283e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.9017e-05, grad_fn=<AbsBackward0>) tensor(6.7825e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(7.5132e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(8.2713e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.1039e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(9.1954e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(7.7320e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(8.3315e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.9252e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.0832e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(8.5142e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.2918e-05, grad_fn=<AbsBackward0>) tensor(7.0369e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(7.2365e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(9.2378e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.0118e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.8363e-05, grad_fn=<AbsBackward0>) tensor(6.9684e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.8218e-05, grad_fn=<AbsBackward0>) tensor(8.3407e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(8.4613e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(9.1069e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(8.6319e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(6.5376e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(7.3218e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(7.7675e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.7199e-05, grad_fn=<AbsBackward0>) tensor(9.0491e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.7967e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.1540e-05, grad_fn=<AbsBackward0>) tensor(9.8171e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(9.0512e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(8.5580e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(9.0084e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(8.9468e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(7.1615e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(7.3272e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(8.4682e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(9.4237e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(8.9305e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(9.1952e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(1.2762e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.2000e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.8943e-05, grad_fn=<AbsBackward0>) tensor(1.5163e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.1248e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.8396e-05, grad_fn=<AbsBackward0>) tensor(1.1631e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.3243e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.6391e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.9525e-05, grad_fn=<AbsBackward0>) tensor(1.4852e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.8168e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(1.5304e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.7261e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.8355e-05, grad_fn=<AbsBackward0>) tensor(2.2327e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.7636e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(1.7519e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(1.4485e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(2.2818e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(2.1101e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(1.7803e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(1.5915e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0021, grad_fn=<AbsBackward0>) tensor(1.5097e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(1.6104e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.5829e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.7399e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.3980e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.5692e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.4118e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.1714e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.4202e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.1781e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.3253e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.1165e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.3513e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(9.8641e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.4130e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.1802e-05, grad_fn=<AbsBackward0>) tensor(9.1941e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(7.8135e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.0222e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(8.4700e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(6.7356e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.7448e-05, grad_fn=<AbsBackward0>) tensor(4.9419e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.7840e-05, grad_fn=<AbsBackward0>) tensor(4.6795e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.7100e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.3447e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.7452e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.0260e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(2.8679e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(8.6539e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(2.1714e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.8410e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.5125e-05, grad_fn=<AbsBackward0>) tensor(3.4761e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(8.5987e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(6.5007e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.2157e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(5.5502e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(9.3848e-05, grad_fn=<AbsBackward0>) tensor(2.2366e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(7.2386e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(4.4080e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0022, grad_fn=<AbsBackward0>) tensor(5.4370e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(4.4099e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.5384e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.9641e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.4813e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.8567e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(3.5633e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.6517e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(4.4705e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.0299e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.2291e-05, grad_fn=<AbsBackward0>) tensor(2.0953e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.8302e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(2.2541e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.3629e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.4945e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.8550e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.0957e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(2.5762e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(8.2423e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(4.1601e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.6260e-05, grad_fn=<AbsBackward0>) tensor(3.4236e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.1953e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(4.0561e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0016, grad_fn=<AbsBackward0>) tensor(1.1281e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(3.4111e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(3.4239e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.4119e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(1.9942e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(1.4824e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(8.2249e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(3.1122e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.7936e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(4.3178e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(4.5545e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.3421e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.4235e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(3.5962e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(3.8044e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.5127e-05, grad_fn=<AbsBackward0>) tensor(2.8992e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(2.3464e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.0264e-05, grad_fn=<AbsBackward0>) tensor(4.4665e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.7984e-05, grad_fn=<AbsBackward0>) tensor(3.6877e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(3.8192e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(4.0497e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.9959e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.5263e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(3.0801e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.7011e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.7386e-05, grad_fn=<AbsBackward0>) tensor(3.5123e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.9493e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.5743e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(3.1751e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.1809e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.6880e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(5.6522e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(1.5237e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0020, grad_fn=<AbsBackward0>) tensor(1.0851e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(6.4894e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(6.0772e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.6906e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(2.6927e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(2.1739e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(2.1403e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.3413e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(1.3217e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(9.8353e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.0879e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(3.7401e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.0831e-05, grad_fn=<AbsBackward0>) tensor(5.7427e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.9404e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(2.5493e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(3.5052e-05, grad_fn=<AbsBackward0>) tensor(6.6894e-08, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.4061e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.8186e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(1.2595e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(3.4036e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(2.0466e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.3072e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(2.6344e-05, grad_fn=<AbsBackward0>) tensor(4.1190e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(3.2550e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(2.8214e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(2.7143e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(3.4044e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.9215e-05, grad_fn=<AbsBackward0>) tensor(6.0956e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0012, grad_fn=<AbsBackward0>) tensor(3.5182e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(4.2222e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(5.6342e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(2.1267e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(6.2145e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(6.7724e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(4.7417e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(5.8035e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.2137e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(7.1824e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.3951e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(4.4813e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(5.6265e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.3688e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(3.7643e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(5.5855e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(5.0309e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(4.5517e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.3092e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(5.0222e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(5.1534e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(4.4296e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0010, grad_fn=<AbsBackward0>) tensor(1.5727e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.8413e-05, grad_fn=<AbsBackward0>) tensor(4.8691e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0013, grad_fn=<AbsBackward0>) tensor(1.0104e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(5.5477e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0019, grad_fn=<AbsBackward0>) tensor(1.1823e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0017, grad_fn=<AbsBackward0>) tensor(2.8984e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(4.2338e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(8.5830e-05, grad_fn=<AbsBackward0>) tensor(6.1288e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(5.0429e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(7.0103e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(4.0579e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.8456e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(1.3126e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(4.1546e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(4.0686e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.5020e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(6.9268e-05, grad_fn=<AbsBackward0>) tensor(2.7243e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(3.3552e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(5.1909e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0006, grad_fn=<AbsBackward0>) tensor(3.8037e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.0371e-05, grad_fn=<AbsBackward0>) tensor(3.5969e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(9.4181e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(7.2072e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0014, grad_fn=<AbsBackward0>) tensor(1.1305e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(9.5892e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(1.1218e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(1.2332e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(1.2273e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0018, grad_fn=<AbsBackward0>) tensor(9.2626e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0015, grad_fn=<AbsBackward0>) tensor(1.0415e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.3937e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(1.2298e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.1910e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0011, grad_fn=<AbsBackward0>) tensor(9.7970e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(1.3318e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(8.3233e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(6.4902e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(4.0238e-05, grad_fn=<AbsBackward0>) tensor(3.6527e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(7.9018e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0004, grad_fn=<AbsBackward0>) tensor(2.8990e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(1.0683e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(7.9811e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.1555e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(1.2387e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.1629e-05, grad_fn=<AbsBackward0>) tensor(6.5998e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(7.2181e-05, grad_fn=<AbsBackward0>) tensor(5.9050e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0002, grad_fn=<AbsBackward0>) tensor(6.8403e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(6.6677e-05, grad_fn=<AbsBackward0>) tensor(9.2575e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(8.5589e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(7.3546e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(3.7641e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(6.9123e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(1.2457e-06, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0005, grad_fn=<AbsBackward0>) tensor(5.5301e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(1.9047e-05, grad_fn=<AbsBackward0>) tensor(7.9193e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0003, grad_fn=<AbsBackward0>) tensor(6.1371e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(5.6495e-05, grad_fn=<AbsBackward0>) tensor(2.6760e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0008, grad_fn=<AbsBackward0>) tensor(3.5357e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0009, grad_fn=<AbsBackward0>) tensor(3.2660e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0007, grad_fn=<AbsBackward0>) tensor(8.2539e-07, grad_fn=<MulBackward0>)\n",
            "optimize_discriminator loss tensor(0.0001, grad_fn=<AbsBackward0>) tensor(4.9910e-07, grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### eval"
      ],
      "metadata": {
        "id": "eXoSwJuZEQI3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "p4cPQiuoiwAH",
        "outputId": "dbf16cbc-981a-4960-c5a2-dd2c54b6c53d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "76.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "model=gail\n",
        "rewards=0\n",
        "s = env.reset()\n",
        "s = torch.tensor(s.copy()).type(torch.float32)\n",
        "done = False\n",
        "while not done:\n",
        "    # print(\"sssssssss\",s)\n",
        "    action = model.act(s)\n",
        "    a = np.squeeze(action.data.detach().numpy())\n",
        "    s_p, r, done, _ = env.step(a)\n",
        "    s_p = torch.tensor(s_p).type(torch.float32)\n",
        "    s = s_p\n",
        "    rewards+=r\n",
        "print(rewards)\n",
        "# Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### video"
      ],
      "metadata": {
        "id": "7vmEJYJSEDZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imageio-ffmpeg\n",
        "!apt install python-opengl ffmpeg xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(500, 500))\n",
        "virtual_display.start()\n",
        "import imageio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rtd7Oaq-EAMv",
        "outputId": "bc16ec42-d886-458d-e920-1b9e5faade19"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: imageio-ffmpeg in /usr/local/lib/python3.7/dist-packages (0.4.7)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "ffmpeg is already the newest version (7:3.4.11-0ubuntu0.1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.11).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 19 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# make mp4\n",
        "\n",
        "env = gym.make(\"CartPole-v1\")\n",
        "model=gail\n",
        "rewards=0\n",
        "images = []  \n",
        "done = False\n",
        "s = env.reset()\n",
        "img = env.render(mode='rgb_array')\n",
        "images.append(img)\n",
        "s = torch.tensor(s.copy()).type(torch.float32)\n",
        "done = False\n",
        "while not done:\n",
        "    # print(\"sssssssss\",s)\n",
        "    action = model.act(s)\n",
        "    a = np.squeeze(action.data.detach().numpy())\n",
        "    s_p, r, done, _ = env.step(a)\n",
        "    s_p = torch.tensor(s_p).type(torch.float32)\n",
        "    s = s_p\n",
        "    rewards+=r\n",
        "\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "# print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
        "imageio.mimsave(\"video.mp4\", [np.array(img) for i, img in enumerate(images)], fps=30)\n",
        "\n",
        "print(rewards)\n",
        "# Cart Position, Cart Velocity, Pole Angle, Pole Angular Velocity\n",
        "\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "mp4 = open('video.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)\n"
      ],
      "metadata": {
        "id": "Lo4JH45if81z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "outputId": "aa4fa244-a533-4f7f-dcf7-99ee04373f40"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:imageio_ffmpeg:IMAGEIO FFMPEG_WRITER WARNING: input image is not divisible by macro_block_size=16, resizing from (600, 400) to (608, 400) to ensure video compatibility with most codecs and players. To prevent resizing, make your input image divisible by the macro_block_size or set the macro_block_size to 1 (risking incompatibility).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<video width=400 controls>\n",
              "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              "</video>\n"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### mario"
      ],
      "metadata": {
        "id": "L6YGV3WH4VnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### wrappers"
      ],
      "metadata": {
        "id": "MX3GDMwUsZiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class MarioSparse(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        # super().__init__(env)\n",
        "        super(MarioSparse, self).__init__(env)\n",
        "        self.env = env\n",
        "        self.total_score = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        life = info['life']\n",
        "        score = info['score']\n",
        "        self.total_score += score\n",
        "        if life<2:\n",
        "            print(\"MarioSparse: died\")\n",
        "            # return observation, score, True, info # lost one life, end env\n",
        "            done = True\n",
        "        # else:\n",
        "            # self.total_score = 0\n",
        "        return observation, score, done, info\n",
        "    def reset(self):\n",
        "        self.total_score = 0\n",
        "        return self.env.reset()\n",
        "# env = MarioSparse(env)\n",
        "\n",
        "class MarioEarlyStop(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        # super().__init__(env)\n",
        "        super(MarioEarlyStop, self).__init__(env)\n",
        "        self.env = env\n",
        "        self.max_pos = 0\n",
        "        self.count_step = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        x_pos = info['x_pos']\n",
        "        if x_pos <= self.max_pos: self.count_step += 1\n",
        "        else:\n",
        "            self.max_pos = x_pos\n",
        "            self.count_step = 0\n",
        "        if self.count_step > 500:\n",
        "            print(\"MarioEarlyStop: early stop \", self.max_pos)\n",
        "            # return observation, reward, True, info # early stop\n",
        "            done = True\n",
        "        # else:\n",
        "        return observation, reward, done, info\n",
        "    def reset(self):\n",
        "        self.max_pos = 0\n",
        "        self.count_step = 0\n",
        "        return self.env.reset()\n",
        "# env = MarioEarlyStop(env)\n",
        "\n",
        "\n",
        "\n",
        "class PosState(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super(PosState, self).__init__(env)\n",
        "        self.env = env\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        x_pos = info['x_pos']\n",
        "        y_pos = info['y_pos']\n",
        "        return [x_pos,y_pos], score, done, info\n",
        "    def reset(self):\n",
        "        return self.env.reset()\n",
        "# env = PosState(env)\n"
      ],
      "metadata": {
        "id": "JT169qWBrhif"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### setup"
      ],
      "metadata": {
        "id": "WgZHYIvjscjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gym-super-mario-bros nes-py\n",
        "# https://github.com/Kautenja/gym-super-mario-bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
        "\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v3') #og v0 pixel v3\n",
        "env = JoypadSpace(env, COMPLEX_MOVEMENT) # SIMPLE_MOVEMENT COMPLEX_MOVEMENT\n",
        "env = MarioSparse(env)\n",
        "env = MarioEarlyStop(env)\n",
        "env = PosState(env)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZwMMlbO14VJc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "AIM2_simplify_strip.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
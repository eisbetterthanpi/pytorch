{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "JEPA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPOSD9LY/sL0YWODRO7CWto",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/JEPA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install optuna\n"
      ],
      "metadata": {
        "id": "btQjTpnUd95O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6_Xjga__gdeY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fc51d0b-5e9b-40a6-c965-595aeff385d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x.dim() 1\n",
            "x torch.Size([1, 40])\n",
            "cov_x torch.Size([40, 40])\n",
            "off_diagonal torch.Size([40, 40])\n",
            "off_diagonal torch.Size([40, 40])\n",
            "tensor(0.9638, grad_fn=<AddBackward0>)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# https://openreview.net/pdf?id=BZ5a1r-kVsf\n",
        "# import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim\n",
        "import collections\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "import optuna\n",
        "\n",
        "def off_diagonal(x):\n",
        "    print(\"off_diagonal\",x.shape)\n",
        "    n, m = x.shape\n",
        "    assert n == m\n",
        "    return x.flatten()[:-1].view(n - 1, n + 1)[:, 1:].flatten()\n",
        "\n",
        "\n",
        "class JEPA(nn.Module):\n",
        "    # def __init__(self, xin_channels, dim_sx, dim_sy, dim_z, dim_v, n_actions, space_dims, hidden_dims):\n",
        "    def __init__(self, xin_channels, dim_sx, dim_sy, dim_z, dim_v):\n",
        "        super(JEPA, self).__init__()\n",
        "        self.enc_x = nn.Sequential( # embed pi (240, 256, 3) -> 256 when flattened\n",
        "            nn.Conv2d(xin_channels, 8, 3, stride=2, padding=1), nn.ELU(),\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(8, 16, 5, stride=2, padding=2), nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 8, 7, stride=2, padding=3), nn.ELU(),\n",
        "            nn.Conv2d(8, 1, 5, stride=2, padding=2), nn.ELU(),\n",
        "            nn.AdaptiveAvgPool2d((5,4)),\n",
        "            # # nn.Conv2d(in_channels, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "            # nn.ReLU(),\n",
        "            )\n",
        "        self.enc_y = nn.Sequential( # embed pi (240, 256, 3) -> 256 when flattened\n",
        "            nn.Conv2d(xin_channels, 8, 3, stride=2, padding=1), nn.ELU(),\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(8, 16, 5, stride=2, padding=2), nn.ELU(),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 8, 7, stride=2, padding=3), nn.ELU(),\n",
        "            nn.Conv2d(8, 1, 5, stride=2, padding=2), nn.ELU(),\n",
        "            nn.AdaptiveAvgPool2d((5,4)),\n",
        "            # # nn.Conv2d(in_channels, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "            # nn.ReLU(),\n",
        "            )\n",
        "        self.pred = nn.Sequential(\n",
        "            nn.Linear(dim_sx + dim_z, dim_sy),\n",
        "            nn.ReLU(True),\n",
        "            )\n",
        "        self.exp_x = nn.Sequential(\n",
        "            nn.Linear(dim_sx, dim_v),\n",
        "            nn.ReLU(True),\n",
        "            )\n",
        "        self.exp_y = nn.Sequential(\n",
        "            nn.Linear(dim_sy, dim_v),\n",
        "            nn.ReLU(True),\n",
        "            )    \n",
        "\n",
        "    # def zreg(self, z):\n",
        "    #     loss=0\n",
        "    #     dim_z=len(z)\n",
        "    #     # dim_z=self.dim_z\n",
        "    #     for i in range(dim_z):\n",
        "    #         z_=z.copy()\n",
        "    #         z_[i:]=0\n",
        "    #         sx = self.enc_x(x)\n",
        "    #         sy_ = self.pred(sx, z_)\n",
        "    #         sy = self.enc_y(y)\n",
        "    #         # loss(sy, sy_)\n",
        "    #         mseloss = nn.MSELoss()(sy, sy_)\n",
        "    #         loss+=mseloss\n",
        "    #     return loss\n",
        "\n",
        "    def vicreg(self, x, y): # https://github.com/facebookresearch/vicreg/blob/main/main_vicreg.py\n",
        "        # x = self.projector(self.backbone(x))\n",
        "        # y = self.projector(self.backbone(y))\n",
        "\n",
        "        # invariance loss\n",
        "        repr_loss = F.mse_loss(x, y)\n",
        "\n",
        "        # x = torch.cat(FullGatherLayer.apply(x), dim=0)\n",
        "        # y = torch.cat(FullGatherLayer.apply(y), dim=0)\n",
        "        x = x - x.mean(dim=0)\n",
        "        y = y - y.mean(dim=0)\n",
        "\n",
        "        # variance loss\n",
        "        std_x = torch.sqrt(x.var(dim=0) + 0.0001)\n",
        "        std_y = torch.sqrt(y.var(dim=0) + 0.0001)\n",
        "        std_loss = torch.mean(F.relu(1 - std_x)) / 2 + torch.mean(F.relu(1 - std_y)) / 2\n",
        "\n",
        "        # # covariance loss\n",
        "        # cov_x = (x.T @ x) / (self.args.batch_size - 1)\n",
        "        # cov_y = (y.T @ y) / (self.args.batch_size - 1)\n",
        "        # cov_loss = off_diagonal(cov_x).pow_(2).sum().div(self.num_features)\\\n",
        "        #  + off_diagonal(cov_y).pow_(2).sum().div(self.num_features)\n",
        "\n",
        "        # loss = (self.args.sim_coeff * repr_loss + self.args.std_coeff * std_loss + self.args.cov_coeff * cov_loss)\n",
        "\n",
        "        batch_size=3\n",
        "        num_features=3\n",
        "        sim_coeff=1\n",
        "        std_coeff=1\n",
        "        cov_coeff=1\n",
        "\n",
        "        print(\"x.dim()\",x.dim())\n",
        "        if x.dim() == 1:\n",
        "            x = x.view(-1, 1)\n",
        "        \n",
        "        if y.dim() == 1:\n",
        "            y = y.view(-1, 1)\n",
        "        x=x.T\n",
        "        y=y.T\n",
        "        print(\"x\",x.shape)\n",
        "        cov_x = (x.T @ x) / (batch_size - 1)\n",
        "        cov_y = (y.T @ y) / (batch_size - 1)\n",
        "        print(\"cov_x\",cov_x.shape)\n",
        "        cov_loss = off_diagonal(cov_x).pow_(2).sum().div(num_features)\\\n",
        "         + off_diagonal(cov_y).pow_(2).sum().div(num_features)\n",
        "\n",
        "        loss = (sim_coeff * repr_loss + std_coeff * std_loss + cov_coeff * cov_loss)\n",
        "        return loss\n",
        "\n",
        "    def argm(self, sx, sy):\n",
        "        optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "        sampler = optuna.samplers.NSGAIISampler()\n",
        "        # sampler = optuna.samplers.MOTPESampler()\n",
        "        study = optuna.create_study(direction=\"maximize\", sampler=sampler, pruner=optuna.pruners.MedianPruner())\n",
        "        # study = optuna.create_study()\n",
        "        # print(\"sx\",sx.shape)\n",
        "        # sx=sx.flatten()\n",
        "        def objective(trial):\n",
        "            z = trial.suggest_uniform('z', -1, 1)\n",
        "            # print(\"z trail\",sx,z)\n",
        "            z=torch.tensor([z])\n",
        "            sxz = torch.cat([sx, z], dim=-1)\n",
        "            sy_ = self.pred(sxz)\n",
        "            mseloss = nn.MSELoss()(sy, sy_)\n",
        "            return mseloss\n",
        "        study.optimize(objective, n_trials=100)\n",
        "        st=study.best_params\n",
        "        # print(\"st\",st['z'])\n",
        "        st=torch.tensor([st['z']])\n",
        "        return st\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        sx = self.enc_x(x)\n",
        "        sy = self.enc_y(y)\n",
        "        sx=sx.flatten()\n",
        "        sy=sy.flatten()\n",
        "        z = self.argm(sx, sy)\n",
        "        sxz = torch.cat([sx, z], dim=-1)\n",
        "        sy_ = self.pred(sxz)\n",
        "        # loss(sy, sy_)\n",
        "        mseloss = nn.MSELoss()(sy, sy_)\n",
        "\n",
        "        # zloss = zreg(z)\n",
        "\n",
        "        vx = self.exp_x(sx)\n",
        "        vy = self.exp_y(sy)\n",
        "        # print(\"vx\",vx.shape) #[40]\n",
        "        vicloss = self.vicreg(vx, vy)\n",
        "        return mseloss + vicloss\n",
        "\n",
        "\n",
        "xin_channels=3\n",
        "dim_sx=20\n",
        "dim_sy=20\n",
        "dim_z=1\n",
        "dim_v=40\n",
        "model = JEPA(xin_channels, dim_sx, dim_sy, dim_z, dim_v)\n",
        "\n",
        "\n",
        "# x=torch.rand(210, 160, 3)\n",
        "# y=torch.rand(210, 160, 3)\n",
        "x=torch.rand(3, 210, 160)\n",
        "y=torch.rand(3, 210, 160)\n",
        "inv_loss = model(x,y)\n",
        "print(inv_loss)\n",
        "\n",
        "\n",
        "# enc_x = nn.Sequential( # embed pi (240, 256, 3) -> 256 when flattened\n",
        "#             nn.Conv2d(xin_channels, 8, 3, stride=2, padding=1), nn.ELU(),\n",
        "#             # nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "#             nn.Conv2d(8, 16, 5, stride=2, padding=2), nn.ELU(),\n",
        "#             nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "#             nn.Conv2d(16, 8, 7, stride=2, padding=3), nn.ELU(),\n",
        "#             nn.Conv2d(8, 1, 5, stride=2, padding=2), nn.ELU(),\n",
        "#             nn.AdaptiveAvgPool2d((5,4)),\n",
        "#             # # nn.Conv2d(in_channels, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "#             # nn.ReLU(),\n",
        "#             )\n",
        "# x=torch.rand(3, 210, 160)\n",
        "# sx=enc_x(x)\n",
        "# print(\"sx.shape\",sx.shape) # [1, 256] [1, 5, 4]\n",
        "# sx=sx.flatten()\n",
        "# print(\"sx.shape\",sx.shape) # [20]\n",
        "\n",
        "\n",
        "# pred = nn.Sequential(\n",
        "#             nn.Linear(dim_sx + dim_z, dim_sy),\n",
        "#             nn.ReLU(True),\n",
        "#             )\n",
        "\n",
        "# # sx =torch.rand(1, 16, 16)\n",
        "# z =torch.rand(1)\n",
        "# z=torch.tensor(z)\n",
        "# sxz = torch.cat([sx, z], dim=-1)\n",
        "# print(sxz.shape) #257\n",
        "# sy_ = pred(sxz)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "V_EUHNNBgxuw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
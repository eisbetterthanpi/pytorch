{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "kimhc6028_curiousity_next.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "-qQjuJIepAvA",
        "SPCCve3p2bL-",
        "EfnomeCYZPIu",
        "GCHpcDteZdLS",
        "_R9i720bZg8Q"
      ],
      "authorship_tag": "ABX9TyPZ9CSVJsO8ObhcTAfmha2y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/kimhc6028_curiousity_next.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### setup"
      ],
      "metadata": {
        "id": "-qQjuJIepAvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # https://github.com/kimhc6028/pytorch-noreward-rl\n",
        "# https://stackoverflow.com/questions/67808779/running-gym-atari-in-google-colab\n",
        "%pip install -U gym\n",
        "%pip install -U gym[atari,accept-rom-license]\n",
        "\n",
        "# !pip install gym[box2d]\n",
        "# import gym\n",
        "\n",
        "\n",
        "# # https://colab.research.google.com/github/pytorch/tutorials/blob/gh-pages/_downloads/54f5097c720c6f2656219ab14a4e7431/mario_rl_tutorial.ipynb\n",
        "# import gym\n",
        "# from gym.spaces import Box\n",
        "# from gym.wrappers import FrameStack\n",
        "# from nes_py.wrappers import JoypadSpace\n",
        "# import gym_super_mario_bros\n",
        "\n",
        "# env = gym_super_mario_bros.make(\"SuperMarioBros-1-1-v0\")\n",
        "# env = JoypadSpace(env, [[\"right\"], [\"right\", \"A\"]])\n",
        "\n",
        "!pip install gym-super-mario-bros nes-py\n",
        "# https://github.com/Kautenja/gym-super-mario-bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
        "# env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "# env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "\n"
      ],
      "metadata": {
        "id": "C1GD7lk8H13h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69796fed-44d0-4834-dbf1-6f77bc7d419e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.24.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym) (0.0.7)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym) (3.8.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.24.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.7)\n",
            "Requirement already satisfied: ale-py~=0.7.5 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.7.5)\n",
            "Requirement already satisfied: autorom[accept-rom-license]~=0.4.2 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.4.2)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Requirement already satisfied: AutoROM.accept-rom-license in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (0.4.2)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym-super-mario-bros in /usr/local/lib/python3.7/dist-packages (7.4.0)\n",
            "Requirement already satisfied: nes-py in /usr/local/lib/python3.7/dist-packages (8.2.1)\n",
            "Requirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from nes-py) (0.24.1)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from nes-py) (4.64.0)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nes-py) (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from nes-py) (1.21.6)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py) (0.0.7)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py) (4.11.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py) (3.8.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.21,>=1.4.0->nes-py) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model"
      ],
      "metadata": {
        "id": "2shhIBykZLyf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/model.py\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def normalized_columns_initializer(weights, std=1.0):\n",
        "    out = torch.randn(weights.size())\n",
        "    # out *= std / torch.sqrt(out.pow(2).sum(1).expand_as(out))\n",
        "    out *= std / torch.sqrt(out.pow(2).sum(1).unsqueeze(dim=1).expand_as(out))\n",
        "    return out\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        weight_shape = list(m.weight.data.size())\n",
        "        fan_in = np.prod(weight_shape[1:4])\n",
        "        fan_out = np.prod(weight_shape[2:4]) * weight_shape[0]\n",
        "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
        "        m.weight.data.uniform_(-w_bound, w_bound)\n",
        "        m.bias.data.fill_(0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        weight_shape = list(m.weight.data.size())\n",
        "        fan_in = weight_shape[1]\n",
        "        fan_out = weight_shape[0]\n",
        "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
        "        m.weight.data.uniform_(-w_bound, w_bound)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "class ActorCritic(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, action_space):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.in_dim = num_inputs # mario (240, 256)\n",
        "        self.conv1 = nn.Conv2d(num_inputs[0], 32, 3, stride=2, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
        "        self.conv4 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
        "        self.lstm = nn.LSTMCell(num_inputs[1], 256)\n",
        "        # self.lstm = nn.LSTMCell(32 * 10, 256)\n",
        "        num_outputs = action_space.n\n",
        "        self.critic_linear = nn.Linear(256, 1)\n",
        "        self.actor_linear = nn.Linear(256, num_outputs)\n",
        "        ################################################################\n",
        "        self.icm_conv1 = nn.Conv2d(num_inputs[0], 32, 3, stride=2, padding=1)\n",
        "        self.icm_conv2 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
        "        self.icm_conv3 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
        "        self.icm_conv4 = nn.Conv2d(32, 32, 3, stride=2, padding=1)\n",
        "        #self.icm_lstm = nn.LSTMCell(32 * 3 * 3, 256)\n",
        "        self.inverse_linear1 = nn.Linear(num_inputs[1] + num_inputs[1], 256)\n",
        "        # self.inverse_linear1 = nn.Linear(320 + 320, 256)\n",
        "        self.inverse_linear2 = nn.Linear(256, num_outputs)\n",
        "        self.forward_linear1 = nn.Linear(num_inputs[1] + num_outputs, 256)\n",
        "        # self.forward_linear1 = nn.Linear(320 + num_outputs, 256)\n",
        "        self.forward_linear2 = nn.Linear(256, num_inputs[1])\n",
        "        # self.forward_linear2 = nn.Linear(256, 320)\n",
        "        #self.inverse_linear1 = nn.Linear(256 + 256, 256)\n",
        "        #self.inverse_linear2 = nn.Linear(256, num_outputs)\n",
        "\n",
        "        #self.forward_linear1 = nn.Linear(256 + num_outputs, 256)\n",
        "        #self.forward_linear2 = nn.Linear(256, 256)\n",
        "        ################################################################\n",
        "        self.apply(weights_init)\n",
        "        self.inverse_linear1.weight.data = normalized_columns_initializer(self.inverse_linear1.weight.data, 0.01)\n",
        "        self.inverse_linear1.bias.data.fill_(0)\n",
        "        self.inverse_linear2.weight.data = normalized_columns_initializer(self.inverse_linear2.weight.data, 1.0)\n",
        "        self.inverse_linear2.bias.data.fill_(0)\n",
        "        \n",
        "        self.forward_linear1.weight.data = normalized_columns_initializer(self.forward_linear1.weight.data, 0.01)\n",
        "        self.forward_linear1.bias.data.fill_(0)\n",
        "        self.forward_linear2.weight.data = normalized_columns_initializer(self.forward_linear2.weight.data, 1.0)\n",
        "        self.forward_linear2.bias.data.fill_(0)\n",
        "        '''\n",
        "        self.icm_lstm.bias_ih.data.fill_(0)\n",
        "        self.icm_lstm.bias_hh.data.fill_(0)\n",
        "        '''\n",
        "        ################################################################\n",
        "        self.actor_linear.weight.data = normalized_columns_initializer(self.actor_linear.weight.data, 0.01)\n",
        "        self.actor_linear.bias.data.fill_(0)\n",
        "        self.critic_linear.weight.data = normalized_columns_initializer(self.critic_linear.weight.data, 1.0)\n",
        "        self.critic_linear.bias.data.fill_(0)\n",
        "        self.lstm.bias_ih.data.fill_(0)\n",
        "        self.lstm.bias_hh.data.fill_(0)\n",
        "        self.train()\n",
        "\n",
        "\n",
        "    def forward(self, inputs, icm):\n",
        "        if icm == False: #A3C\n",
        "            inputs, (a3c_hx, a3c_cx) = inputs # [1, 210, 160, 3], ([1, 256], [1, 256])\n",
        "            x = F.elu(self.conv1(inputs)) # [1, 32, 80, 2]\n",
        "            x = F.elu(self.conv2(x)) # [1, 32, 40, 1]\n",
        "            x = F.elu(self.conv3(x)) # [1, 32, 20, 1]\n",
        "            x = F.elu(self.conv4(x)) # [1, 32, 10, 1] mario[1, 32, 16, 1]\n",
        "            print(\"x4\",x.shape) # mario[2, 256]\n",
        "            x = x.view(-1, self.in_dim[1])\n",
        "            \n",
        "            print(\"xv\",x.shape)\n",
        "            # x = x.view(-1, 32 * 10)\n",
        "            print(\"wrthf\",x.shape, a3c_hx.shape, a3c_cx.shape) # [2, 256], [1, 256], [1, 256]\n",
        "\n",
        "            a3c_hx, a3c_cx = self.lstm(x, (a3c_hx, a3c_cx))\n",
        "            x = a3c_hx\n",
        "            critic = self.critic_linear(x)\n",
        "            actor = self.actor_linear(x)\n",
        "            # print(\"forward A3C \",critic.shape, actor.shape, a3c_hx.shape, a3c_cx.shape)\n",
        "            return critic, actor, (a3c_hx, a3c_cx) # [1, 1], [1, 18], ([1, 256], [1, 256])\n",
        "\n",
        "        else: #icm\n",
        "            s_t, s_t1, a_t = inputs\n",
        "            # s_t1=s_t1.float()\n",
        "            # print(\"###s t###\",s_t.dtype) # [1, 210, 160, 3] torch.float32\n",
        "\n",
        "            '''\n",
        "            s_t, (icm_hx, icm_cx) = s_t\n",
        "            s_t1, (icm_hx1, icm_cx1) = s_t1\n",
        "            '''\n",
        "            vec_st = F.elu(self.icm_conv1(s_t))\n",
        "            vec_st = F.elu(self.icm_conv2(vec_st))\n",
        "            vec_st = F.elu(self.icm_conv3(vec_st))\n",
        "            vec_st = F.elu(self.icm_conv4(vec_st))\n",
        "            \n",
        "            vec_st1 = F.elu(self.icm_conv1(s_t1))\n",
        "            vec_st1 = F.elu(self.icm_conv2(vec_st1))\n",
        "            vec_st1 = F.elu(self.icm_conv3(vec_st1))\n",
        "            vec_st1 = F.elu(self.icm_conv4(vec_st1))\n",
        "            vec_st = vec_st.view(-1, self.in_dim[1])\n",
        "            vec_st1 = vec_st1.view(-1, self.in_dim[1])\n",
        "            # vec_st = vec_st.view(-1, 32 * 10) # [1, 320] torch.float32\n",
        "            # vec_st1 = vec_st1.view(-1, 32 * 10) # [1, 320] torch.float32\n",
        "\n",
        "            #icm_hx, icm_cx = self.icm_lstm(vec_st, (icm_hx, icm_cx))\n",
        "            #icm_hx1, icm_cx1 = self.icm_lstm(vec_st1, (icm_hx1, icm_cx1))\n",
        "            #vec_st = icm_hx\n",
        "            #vec_st1 = icm_hx1\n",
        "            inverse_vec = torch.cat((vec_st, vec_st1), 1)\n",
        "            forward_vec = torch.cat((vec_st, a_t), 1)\n",
        "            inverse = self.inverse_linear1(inverse_vec)\n",
        "            inverse = F.relu(inverse)\n",
        "            inverse = self.inverse_linear2(inverse)\n",
        "            inverse = F.softmax(inverse)\n",
        "            forward = self.forward_linear1(forward_vec)\n",
        "            forward = F.relu(forward)\n",
        "            forward = self.forward_linear2(forward)\n",
        "            # print(\"forward icm \",vec_st1.shape, inverse.shape, forward.shape)\n",
        "            return vec_st1, inverse, forward # [1, 320], [1, 18], [1, 320]\n",
        "            #return vec_st1, inverse, forward, (icm_hx, icm_cx), (icm_hx1, icm_cx1)\n"
      ],
      "metadata": {
        "id": "xFFfM5gmpm5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model simple"
      ],
      "metadata": {
        "id": "VCeOD767-chJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/model.py\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "\n",
        "def normalized_columns_initializer(weights, std=1.0):\n",
        "    out = torch.randn(weights.size())\n",
        "    out *= std / torch.sqrt(out.pow(2).sum(1).unsqueeze(dim=1).expand_as(out))\n",
        "    return out\n",
        "\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        weight_shape = list(m.weight.data.size())\n",
        "        fan_in = np.prod(weight_shape[1:4])\n",
        "        fan_out = np.prod(weight_shape[2:4]) * weight_shape[0]\n",
        "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
        "        m.weight.data.uniform_(-w_bound, w_bound)\n",
        "        m.bias.data.fill_(0)\n",
        "    elif classname.find('Linear') != -1:\n",
        "        weight_shape = list(m.weight.data.size())\n",
        "        fan_in = weight_shape[1]\n",
        "        fan_out = weight_shape[0]\n",
        "        w_bound = np.sqrt(6. / (fan_in + fan_out))\n",
        "        m.weight.data.uniform_(-w_bound, w_bound)\n",
        "        m.bias.data.fill_(0)\n",
        "\n",
        "\n",
        "class ActorCritic(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, action_space):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        # self.lstm = nn.LSTMCell(32 * 3 * 3, 256)\n",
        "        ################################################################\n",
        "        #self.icm_lstm = nn.LSTMCell(32 * 3 * 3, 256)\n",
        "        #self.inverse_linear1 = nn.Linear(256 + 256, 256)\n",
        "        #self.inverse_linear2 = nn.Linear(256, num_outputs)\n",
        "\n",
        "        #self.forward_linear1 = nn.Linear(256 + num_outputs, 256)\n",
        "        #self.forward_linear2 = nn.Linear(256, 256)\n",
        "        ################################################################\n",
        "        self.apply(weights_init)\n",
        "        self.inverse_linear1.weight.data = normalized_columns_initializer(self.inverse_linear1.weight.data, 0.01)\n",
        "        self.inverse_linear1.bias.data.fill_(0)\n",
        "        self.inverse_linear2.weight.data = normalized_columns_initializer(self.inverse_linear2.weight.data, 1.0)\n",
        "        self.inverse_linear2.bias.data.fill_(0)\n",
        "        \n",
        "        self.forward_linear1.weight.data = normalized_columns_initializer(self.forward_linear1.weight.data, 0.01)\n",
        "        self.forward_linear1.bias.data.fill_(0)\n",
        "        self.forward_linear2.weight.data = normalized_columns_initializer(self.forward_linear2.weight.data, 1.0)\n",
        "        self.forward_linear2.bias.data.fill_(0)\n",
        "        '''\n",
        "        self.icm_lstm.bias_ih.data.fill_(0)\n",
        "        self.icm_lstm.bias_hh.data.fill_(0)\n",
        "        '''\n",
        "        ################################################################\n",
        "        self.actor_linear.weight.data = normalized_columns_initializer(self.actor_linear.weight.data, 0.01)\n",
        "        self.actor_linear.bias.data.fill_(0)\n",
        "        self.critic_linear.weight.data = normalized_columns_initializer(self.critic_linear.weight.data, 1.0)\n",
        "        self.critic_linear.bias.data.fill_(0)\n",
        "        self.lstm.bias_ih.data.fill_(0)\n",
        "        self.lstm.bias_hh.data.fill_(0)\n",
        "        self.train()\n",
        "\n",
        "\n",
        "class ActorCritic(torch.nn.Module):\n",
        "    def __init__(self, num_inputs, action_space):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.in_dim = num_inputs # mario (240, 256)\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(num_inputs[0], 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(), # added for RuntimeError: Input batch size 2 doesn't match hidden0 batch size 1\n",
        "            )\n",
        "        self.icm_conv = nn.Sequential(\n",
        "            nn.Conv2d(num_inputs[0], 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(), # added for cat\n",
        "            )\n",
        "        self.lstm = nn.LSTMCell(num_inputs[1], 256)\n",
        "        num_outputs = action_space.n\n",
        "        self.critic_linear = nn.Linear(256, 1)\n",
        "        self.actor_linear = nn.Linear(256, num_outputs)\n",
        "\n",
        "        self.inverse_linear1 = nn.Linear(num_inputs[1] + num_inputs[1], 256)\n",
        "        self.inverse_linear2 = nn.Linear(256, num_outputs)\n",
        "\n",
        "        self.forward_linear1 = nn.Linear(num_inputs[1] + num_outputs, 256)\n",
        "        self.forward_linear2 = nn.Linear(256, num_inputs[1])\n",
        "\n",
        "    def forward(self, inputs, icm):\n",
        "        if icm == False: #A3C\n",
        "            inputs, (a3c_hx, a3c_cx) = inputs # [1, 210, 160, 3], ([1, 256], [1, 256])\n",
        "            x = self.conv(inputs).view(-1, self.in_dim[1])\n",
        "            a3c_hx, a3c_cx = self.lstm(x, (a3c_hx, a3c_cx))\n",
        "            x = a3c_hx\n",
        "            critic = self.critic_linear(x)\n",
        "            actor = self.actor_linear(x)\n",
        "            # print(\"forward A3C \",critic.shape, actor.shape, a3c_hx.shape, a3c_cx.shape)\n",
        "            return critic, actor, (a3c_hx, a3c_cx) # [1, 1], [1, 18], ([1, 256], [1, 256])\n",
        "\n",
        "        else: #icm\n",
        "            s_t, s_t1, a_t = inputs\n",
        "            '''\n",
        "            s_t, (icm_hx, icm_cx) = s_t\n",
        "            s_t1, (icm_hx1, icm_cx1) = s_t1\n",
        "            '''\n",
        "            vec_st = self.icm_conv(s_t).view(-1, self.in_dim[1])\n",
        "            vec_st1 = self.icm_conv(s_t1).view(-1, self.in_dim[1])\n",
        "            #icm_hx, icm_cx = self.icm_lstm(vec_st, (icm_hx, icm_cx))\n",
        "            #icm_hx1, icm_cx1 = self.icm_lstm(vec_st1, (icm_hx1, icm_cx1))\n",
        "            #vec_st = icm_hx\n",
        "            #vec_st1 = icm_hx1\n",
        "            inverse_vec = torch.cat((vec_st, vec_st1), 1)\n",
        "            forward_vec = torch.cat((vec_st, a_t), 1)\n",
        "\n",
        "            inverse = self.inverse_linear1(inverse_vec)\n",
        "            inverse = F.relu(inverse)\n",
        "            inverse = self.inverse_linear2(inverse)\n",
        "            inverse = F.softmax(inverse)\n",
        "\n",
        "            forward = self.forward_linear1(forward_vec)\n",
        "            forward = F.relu(forward)\n",
        "            forward = self.forward_linear2(forward)\n",
        "            # print(\"forward icm \",vec_st1.shape, inverse.shape, forward.shape)\n",
        "            return vec_st1, inverse, forward # [1, 320], [1, 18], [1, 320]\n",
        "            #return vec_st1, inverse, forward, (icm_hx, icm_cx), (icm_hx1, icm_cx1)\n"
      ],
      "metadata": {
        "id": "GyGo-Pl8-chS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model simplier"
      ],
      "metadata": {
        "id": "FidkEuaA8HvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/model.py\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "class ActorCritic(torch.nn.Module):\n",
        "    def __init__(self, in_shape, action_space):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.in_dim = in_shape # mario (240, 256)\n",
        "        self.conv = nn.Sequential( # A3C pi\n",
        "            nn.Conv2d(in_shape[0], 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(), # added for RuntimeError: Input batch size 2 doesn't match hidden0 batch size 1\n",
        "            )\n",
        "        self.icm_conv = nn.Sequential( # ICM embed phi\n",
        "            nn.Conv2d(in_shape[0], 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(), # added for cat\n",
        "            )\n",
        "        self.lstm = nn.LSTMCell(in_shape[1], 256)\n",
        "        num_outputs = action_space.n\n",
        "        self.critic_linear = nn.Linear(256, 1) # -> value\n",
        "        self.actor_linear = nn.Linear(256, num_outputs) # -> action\n",
        "\n",
        "        self.inv_linear = nn.Sequential( # inv learning, predict at\n",
        "            nn.Linear(in_shape[1] + in_shape[1], 256), nn.ReLU(),\n",
        "            nn.Linear(256, num_outputs), nn.Softmax()\n",
        "            ) # cat(phi(st), phi(st+1)) -> athat\n",
        "        self.fwd_linear = nn.Sequential( # predict phi st+1\n",
        "            nn.Linear(in_shape[1] + num_outputs, 256), nn.ReLU(),\n",
        "            nn.Linear(256, in_shape[1])\n",
        "            ) # cat(phi(st), at) -> phihat(st+1)\n",
        "\n",
        "    def forward(self, inputs, icm):\n",
        "        if icm == False: #A3C\n",
        "            inputs, (a3c_hx, a3c_cx) = inputs # [1, 210, 160, 3], ([1, 256], [1, 256])\n",
        "            x = self.conv(inputs).view(-1, self.in_dim[1])\n",
        "            a3c_hx, a3c_cx = self.lstm(x, (a3c_hx, a3c_cx))\n",
        "            x = a3c_hx\n",
        "            critic = self.critic_linear(x)\n",
        "            actor = self.actor_linear(x)\n",
        "            # print(\"forward A3C \",critic.shape, actor.shape, a3c_hx.shape, a3c_cx.shape)\n",
        "            return critic, actor, (a3c_hx, a3c_cx) # [1, 1], [1, 18], ([1, 256], [1, 256])\n",
        "\n",
        "        else: #icm\n",
        "            s_t, s_t1, a_t = inputs\n",
        "            '''\n",
        "            s_t, (icm_hx, icm_cx) = s_t\n",
        "            s_t1, (icm_hx1, icm_cx1) = s_t1\n",
        "            '''\n",
        "            vec_st = self.icm_conv(s_t).view(-1, self.in_dim[1])\n",
        "            vec_st1 = self.icm_conv(s_t1).view(-1, self.in_dim[1])\n",
        "            #icm_hx, icm_cx = self.icm_lstm(vec_st, (icm_hx, icm_cx))\n",
        "            #icm_hx1, icm_cx1 = self.icm_lstm(vec_st1, (icm_hx1, icm_cx1))\n",
        "            #vec_st = icm_hx\n",
        "            #vec_st1 = icm_hx1\n",
        "            inverse_vec = torch.cat((vec_st, vec_st1), 1)\n",
        "            forward_vec = torch.cat((vec_st, a_t), 1)\n",
        "            inverse = self.inv_linear(inverse_vec)\n",
        "            forward = self.fwd_linear(forward_vec)\n",
        "            # print(\"forward icm \",vec_st1.shape, inverse.shape, forward.shape)\n",
        "            return vec_st1, inverse, forward # [1, 320], [1, 18], [1, 320]\n",
        "            #return vec_st1, inverse, forward, (icm_hx, icm_cx), (icm_hx1, icm_cx1)\n"
      ],
      "metadata": {
        "id": "jGpJGeDM8HvU"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### perceiverio"
      ],
      "metadata": {
        "id": "SPCCve3p2bL-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "!pip install perceiver-pytorch"
      ],
      "metadata": {
        "id": "1Crz85Xzz7ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from perceiver_pytorch import PerceiverIO\n",
        "# https://github.com/lucidrains/perceiver-pytorch\n",
        "actor = PerceiverIO(\n",
        "    dim = env.observation_space.shape[0]*env.observation_space.shape[1],                    # dimension of sequence to be encoded\n",
        "    queries_dim = env.action_space,            # dimension of decoder queries\n",
        "    logits_dim = None,            # dimension of final logits\n",
        "    depth = 6,                   # depth of net\n",
        "    num_latents = 64,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "    latent_dim = 64,            # latent dimension\n",
        "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "    latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "    cross_dim_head = 16,         # number of dimensions per cross attention head\n",
        "    latent_dim_head = 16,        # number of dimensions per latent self attention head\n",
        "    weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        ").to(device)\n",
        "\n",
        "critic = PerceiverIO(\n",
        "    dim = env.observation_space.shape[0]*env.observation_space.shape[1],                    # dimension of sequence to be encoded\n",
        "    queries_dim = env.action_space,            # dimension of decoder queries\n",
        "    logits_dim = None,            # dimension of final logits\n",
        "    depth = 6,                   # depth of net\n",
        "    num_latents = 64,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "    latent_dim = 64,            # latent dimension\n",
        "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "    latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "    cross_dim_head = 16,         # number of dimensions per cross attention head\n",
        "    latent_dim_head = 16,        # number of dimensions per latent self attention head\n",
        "    weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        ").to(device)\n",
        "\n",
        "lstm = PerceiverIO(\n",
        "    dim = 256,                    # dimension of sequence to be encoded\n",
        "    queries_dim = 256,            # dimension of decoder queries\n",
        "    logits_dim = None,            # dimension of final logits\n",
        "    depth = 6,                   # depth of net\n",
        "    num_latents = 64,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "    latent_dim = 64,            # latent dimension\n",
        "    cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "    latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "    cross_dim_head = 16,         # number of dimensions per cross attention head\n",
        "    latent_dim_head = 16,        # number of dimensions per latent self attention head\n",
        "    weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        ").to(device)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, inputs, icm):\n",
        "        if icm == False: #A3C\n",
        "            inputs, (a3c_hx, a3c_cx) = inputs # [1, 210, 160, 3], ([1, 256], [1, 256])\n",
        "\n",
        "\n",
        "            x = F.elu(self.conv4(x)) # [1, 32, 10, 1]\n",
        "            # x = x.view(-1, 32 * 3 * 3)\n",
        "            x = x.view(-1, 32 * 10)\n",
        "\n",
        "            a3c_hx, a3c_cx = self.lstm(x, (a3c_hx, a3c_cx))\n",
        "\n",
        "            return critic, actor, (a3c_hx, a3c_cx) # [1, 1], [1, 18], ([1, 256], [1, 256])\n",
        "\n",
        "        else: #icm\n",
        "            s_t, s_t1, a_t = inputs\n",
        "            # s_t1=s_t1.float()\n",
        "            # print(\"###s t###\",s_t.dtype) # [1, 210, 160, 3] torch.float32\n",
        "\n",
        "\n",
        "            return vec_st1, inverse, forward # [1, 320], [1, 18], [1, 320]\n",
        "\n"
      ],
      "metadata": {
        "id": "MSP6ruBz0gcs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "outputId": "13789f4a-b3b3-4beb-fee9-547e7f3399f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e8fbbb5902f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://github.com/lucidrains/perceiver-pytorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m actor = PerceiverIO(\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m                    \u001b[0;31m# dimension of sequence to be encoded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mqueries_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0;31m# dimension of decoder queries\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mlogits_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0;31m# dimension of final logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'env' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train"
      ],
      "metadata": {
        "id": "EfnomeCYZPIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/train.py\n",
        "import math, os, sys, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "\n",
        "def ensure_shared_grads(model, shared_model):\n",
        "    for param, shared_param in zip(model.parameters(), shared_model.parameters()):\n",
        "        if shared_param.grad is not None:\n",
        "            return\n",
        "        shared_param._grad = param.grad\n",
        "\n",
        "def train(rank, args, shared_model, optimizer=None):\n",
        "    torch.manual_seed(seed + rank)\n",
        "    # env = gym.make(env_name)\n",
        "    env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "    \n",
        "    # num_outputs = env.action_space.n\n",
        "    model = ActorCritic(env.observation_space.shape, env.action_space)\n",
        "    if optimizer is None:\n",
        "        optimizer = optim.Adam(shared_model.parameters(), lr)\n",
        "    model.train()\n",
        "    state = env.reset()\n",
        "    # state=state[:,:,0]\n",
        "    state = torch.from_numpy(state.copy()).type(torch.float) # i added, change from int to float\n",
        "\n",
        "    done = True\n",
        "    episode_length = 0\n",
        "    while True:\n",
        "    # for x in range(num_episodes):\n",
        "        episode_length += 1\n",
        "        # Sync with the shared model\n",
        "        # model.load_state_dict(shared_model.state_dict())\n",
        "        if done:\n",
        "            cx = torch.zeros(1, 256)\n",
        "            hx = torch.zeros(1, 256)\n",
        "        else:\n",
        "            cx = cx.data\n",
        "            hx = hx.data\n",
        "        values = []\n",
        "        log_probs = []\n",
        "        rewards = []\n",
        "        entropies = []\n",
        "        inverses = []\n",
        "        forwards = []\n",
        "        actions = []\n",
        "        vec_st1s = []\n",
        "\n",
        "        # print(\"#####www####\",state.dtype,hx.dtype)\n",
        "        for step in range(num_steps):\n",
        "            # print(\"#####www####\",Variable(state.unsqueeze(0)).dtype,(state.unsqueeze(0).dtype))\n",
        "            value, logit, (hx, cx) = model((state.unsqueeze(0), (hx, cx)), icm = False)\n",
        "            s_t = state\n",
        "            # print(\"logit.size\",logit.shape) # [1, 6]\n",
        "            prob = F.softmax(logit, dim=1)\n",
        "            log_prob = F.log_softmax(logit, dim=1)\n",
        "            entropy = -(log_prob * prob).sum(1)\n",
        "            entropies.append(entropy)\n",
        "            # action = prob.multinomial().data\n",
        "            action = prob.multinomial(1).data\n",
        "            log_prob = log_prob.gather(1, action)\n",
        "            oh_action = torch.Tensor(1, env.action_space.n)\n",
        "            oh_action.zero_()\n",
        "            oh_action.scatter_(1,action,1)\n",
        "            a_t = oh_action\n",
        "            actions.append(oh_action)\n",
        "            # print(\"oh_action.numpy()\",oh_action.numpy())\n",
        "            state, reward, done, _ = env.step(action.numpy()[0][0])\n",
        "            state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "            # print(\"###o###\",state.dtype)\n",
        "            # state=state[:,:,0]\n",
        "\n",
        "            done = done or episode_length >= max_episode_length\n",
        "            reward = max(min(reward, 1), -1)\n",
        "            s_t1 = state.float()\n",
        "            # print(\"###st###\",s_t.unsqueeze(0).dtype)\n",
        "            # print(\"###vst###\",Variable(s_t.unsqueeze(0)).dtype)\n",
        "            vec_st1, inverse, forward = model((s_t.unsqueeze(0), s_t1.unsqueeze(0), a_t), icm = True)            \n",
        "\n",
        "            reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1) / 2.\n",
        "            #reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1).sqrt() / 2.\n",
        "            # print(\"reward_intrinsic\", reward_intrinsic.data.numpy())\n",
        "            # reward_intrinsic = reward_intrinsic.data.numpy()[0][0]\n",
        "            reward_intrinsic = reward_intrinsic.data.numpy()\n",
        "            # print(\"ep \",x,\", rwd ext: \", reward.item(), \" ,rwd int: \", reward_intrinsic.item())\n",
        "            # print(\"ep \",x,\", rwd ext: \", reward, \" ,rwd int: \", reward_intrinsic.item())\n",
        "            reward += reward_intrinsic\n",
        "\n",
        "            if done:\n",
        "                episode_length = 0\n",
        "                state = env.reset()\n",
        "                state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "\n",
        "            values.append(value)\n",
        "            log_probs.append(log_prob)\n",
        "            rewards.append(reward)\n",
        "            vec_st1s.append(vec_st1)\n",
        "            inverses.append(inverse)\n",
        "            forwards.append(forward)\n",
        "            if done:\n",
        "                break\n",
        "        R = torch.zeros(1, 1)\n",
        "        if not done:\n",
        "            value, _, _ = model((state.unsqueeze(0), (hx, cx)), icm = False)\n",
        "            R = value.data\n",
        "        values.append(R)\n",
        "        policy_loss = 0\n",
        "        value_loss = 0\n",
        "        inverse_loss = 0\n",
        "        forward_loss = 0\n",
        "        gae = torch.zeros(1, 1)\n",
        "        for i in reversed(range(len(rewards))):\n",
        "            R = gamma * R + rewards[i]\n",
        "            advantage = R - values[i]\n",
        "            value_loss = value_loss + 0.5 * advantage.pow(2)\n",
        "            # Generalized Advantage Estimataion\n",
        "            # print(torch.tensor(rewards[i]) , gamma * values[i + 1].data , values[i].data)\n",
        "            # delta_t = rewards[i] + gamma * values[i + 1].data - values[i].data\n",
        "            delta_t = torch.tensor(rewards[i]) + gamma * values[i + 1].data - values[i].data\n",
        "            gae = gae * gamma * tau + delta_t\n",
        "            policy_loss = policy_loss - log_probs[i] * gae - 0.01 * entropies[i]\n",
        "            cross_entropy = - (actions[i] * torch.log(inverses[i] + 1e-15)).sum(1)\n",
        "            inverse_loss = inverse_loss + cross_entropy\n",
        "            forward_err = forwards[i] - vec_st1s[i]\n",
        "            forward_loss = forward_loss + 0.5 * (forward_err.pow(2)).sum(1)\n",
        "        optimizer.zero_grad()\n",
        "        # ((1-beta) * inverse_loss + beta * forward_loss).backward(retain_variables=True)\n",
        "        inv_loss = (1-beta) * inverse_loss + beta * forward_loss\n",
        "        pol_loss = lmbda * (policy_loss + 0.5 * value_loss)\n",
        "        (inv_loss + pol_loss).backward()\n",
        "        # (inv_loss + 0*pol_loss).backward()\n",
        "        # (((1-beta) * inverse_loss + beta * forward_loss) + lmbda * (policy_loss + 0.5 * value_loss)).backward()\n",
        "        print(''.join([str(a) for a in actions]))\n",
        "        print(\"inv_loss: \", inv_loss.item(), \" ,pol_loss: \", pol_loss.item())\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 40)\n",
        "        # ensure_shared_grads(model, shared_model)\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "NmIs3Qk6p8zR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train simple"
      ],
      "metadata": {
        "id": "sbpPda4YEv13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# train.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/train.py\n",
        "import math, os, sys, random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "\n",
        "# def train(rank, args, shared_model, optimizer=None):\n",
        "def train(rank, args, model, optimizer=None):\n",
        "    torch.manual_seed(seed)\n",
        "    # env = gym.make(env_name)\n",
        "    env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "    \n",
        "    # model = ActorCritic(env.observation_space.shape, env.action_space)\n",
        "    if optimizer is None:\n",
        "        optimizer = optim.Adam(shared_model.parameters(), lr)\n",
        "    # model.load_state_dict(shared_model.state_dict()) # Sync with the shared model\n",
        "    model.train()\n",
        "\n",
        "    for x in range(num_episodes):\n",
        "        cx = torch.zeros(1, 256).to(device)\n",
        "        hx = torch.zeros(1, 256).to(device)\n",
        "        values = []\n",
        "        log_probs = []\n",
        "        rewards = []\n",
        "        entropies = []\n",
        "        inverses = []\n",
        "        forwards = []\n",
        "        actions = []\n",
        "        vec_st1s = []\n",
        "        episode_length = 0\n",
        "\n",
        "        state = env.reset()\n",
        "        # state=state[:,:,0]\n",
        "        state = torch.from_numpy(state.copy()).type(torch.float).to(device) # i added, change from int to float\n",
        "        s_t1 = state.float()\n",
        "        # print(\"#####www####\",state.dtype,hx.dtype)\n",
        "        while True:\n",
        "            episode_length += 1\n",
        "        # for step in range(num_steps):\n",
        "            value, logit, (hx, cx) = model((state.unsqueeze(0), (hx, cx)), icm = False)\n",
        "            s_t = state\n",
        "            # print(\"logit.size\",logit.shape) # [1, 6]\n",
        "            prob = F.softmax(logit, dim=1)\n",
        "            log_prob = F.log_softmax(logit, dim=1)\n",
        "            entropy = -(log_prob * prob).sum(1)\n",
        "            entropies.append(entropy)\n",
        "            # action = prob.multinomial().data\n",
        "            action = prob.multinomial(1).data\n",
        "            log_prob = log_prob.gather(1, action)\n",
        "            print(\"action\",action.item())\n",
        "            # print(\"action.device\",action.device)\n",
        "            # oh_action = torch.zeros(1, env.action_space.n).scatter_(1,action,1).to(device)\n",
        "            oh_action = torch.zeros(1, env.action_space.n)\n",
        "            oh_action[action]=1\n",
        "            # one=torch.tensor(1).to(device)\n",
        "            # print(\"action.device\",action.device)\n",
        "            # print(\"one.device\",one.device)\n",
        "            # oh_action.scatter_(one,action,one)\n",
        "            print(\"oh_action\",oh_action)\n",
        "            oh_action.to(device)\n",
        "            a_t = oh_action\n",
        "            actions.append(oh_action)\n",
        "            # print(\"oh_action.numpy()\",oh_action.numpy())\n",
        "            state, reward, done, _ = env.step(action.numpy()[0][0])\n",
        "            state = torch.from_numpy(state.copy()).type(torch.float).to(device)\n",
        "            # state=state[:,:,0]\n",
        "\n",
        "            done = done or episode_length >= max_episode_length\n",
        "            reward = max(min(reward, 1), -1)\n",
        "            s_t = s_t1\n",
        "            s_t1 = state.float()\n",
        "            # print(\"###st###\",s_t.unsqueeze(0).dtype)\n",
        "            vec_st1, inverse, forward = model((s_t.unsqueeze(0), s_t1.unsqueeze(0), a_t), icm = True)            \n",
        "\n",
        "            reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1) / 2.\n",
        "            #reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1).sqrt() / 2.\n",
        "            # print(\"reward_intrinsic\", reward_intrinsic.data.numpy())\n",
        "            # reward_intrinsic = reward_intrinsic.data.numpy()[0][0]\n",
        "            reward_intrinsic = reward_intrinsic.data.numpy()\n",
        "            # print(\"ep \",x,\", rwd ext: \", reward, \" ,rwd int: \", reward_intrinsic.item())\n",
        "            reward += reward_intrinsic\n",
        "\n",
        "            values.append(value)\n",
        "            log_probs.append(log_prob)\n",
        "            rewards.append(reward)\n",
        "            vec_st1s.append(vec_st1)\n",
        "            inverses.append(inverse)\n",
        "            forwards.append(forward)\n",
        "\n",
        "            if done:\n",
        "                print(episode_length)\n",
        "                episode_length = 0\n",
        "                # state = env.reset()\n",
        "                # state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "                # s_t1 = state.float()\n",
        "                # s_t1 = state.float()\n",
        "                break\n",
        "\n",
        "        R = torch.zeros(1, 1)\n",
        "        if not done:\n",
        "            value, _, _ = model((state.unsqueeze(0), (hx, cx)), icm = False)\n",
        "            R = value.data\n",
        "        values.append(R)\n",
        "        policy_loss = 0\n",
        "        value_loss = 0\n",
        "        inverse_loss = 0\n",
        "        forward_loss = 0\n",
        "        gae = torch.zeros(1, 1)\n",
        "        for i in reversed(range(len(rewards))):\n",
        "            R = gamma * R + rewards[i]\n",
        "            advantage = R - values[i]\n",
        "            value_loss = value_loss + 0.5 * advantage.pow(2)\n",
        "            # Generalized Advantage Estimataion\n",
        "            # delta_t = rewards[i] + gamma * values[i + 1].data - values[i].data\n",
        "            delta_t = torch.tensor(rewards[i]) + gamma * values[i + 1].data - values[i].data\n",
        "            gae = gae * gamma * tau + delta_t\n",
        "            policy_loss = policy_loss - log_probs[i] * gae - 0.01 * entropies[i]\n",
        "            cross_entropy = - (actions[i] * torch.log(inverses[i] + 1e-15)).sum(1)\n",
        "            inverse_loss = inverse_loss + cross_entropy\n",
        "            forward_err = forwards[i] - vec_st1s[i]\n",
        "            forward_loss = forward_loss + 0.5 * (forward_err.pow(2)).sum(1)\n",
        "        optimizer.zero_grad()\n",
        "        # ((1-beta) * inverse_loss + beta * forward_loss).backward(retain_variables=True)\n",
        "        inv_loss = (1-beta) * inverse_loss + beta * forward_loss\n",
        "        pol_loss = lmbda * (policy_loss + 0.5 * value_loss)\n",
        "        (inv_loss + pol_loss).backward()\n",
        "        # (inv_loss + 0*pol_loss).backward()\n",
        "        # (((1-beta) * inverse_loss + beta * forward_loss) + lmbda * (policy_loss + 0.5 * value_loss)).backward()\n",
        "        print(''.join([str(torch.argmax(a).item()) for a in actions]))\n",
        "        print(\"inv_loss: \", inv_loss.item(), \" ,pol_loss: \", pol_loss.item())\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 40)\n",
        "        optimizer.step()\n"
      ],
      "metadata": {
        "id": "Erf14x8KEv2A"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test"
      ],
      "metadata": {
        "id": "GCHpcDteZdLS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# test.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/test.py\n",
        "import math, os, sys, random, pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import time\n",
        "from collections import deque\n",
        "\n",
        "# def test(rank, args, shared_model):\n",
        "def test(rank, args, model):\n",
        "    torch.manual_seed(seed + rank)\n",
        "    # env = gym.make(env_name)\n",
        "    env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "    env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "    # model = ActorCritic(env.observation_space.shape, env.action_space)\n",
        "    model.eval()\n",
        "    state = env.reset()\n",
        "    state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "    reward_sum = 0\n",
        "    # done = True\n",
        "    start_time = time.time()\n",
        "    # a quick hack to prevent the agent from stucking\n",
        "    actions = deque(maxlen=2100)\n",
        "    episode_length = 0\n",
        "    result = []\n",
        "\n",
        "    # model.load_state_dict(shared_model.state_dict())\n",
        "    cx = torch.zeros(1, 256)\n",
        "    hx = torch.zeros(1, 256)\n",
        "    state = env.reset()\n",
        "    state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "    while True:\n",
        "    # for x in range(1):\n",
        "        episode_length += 1\n",
        "        value, logit, (hx, cx) = model((state.unsqueeze(0), (hx, cx)), icm = False)\n",
        "        # print(\"logit \",logit)\n",
        "        prob = F.softmax(logit)\n",
        "        action = prob.max(1)[1].data.numpy()\n",
        "        # print(\"action\",action)\n",
        "        # state, reward, done, _ = env.step(action[0, 0])\n",
        "        state, reward, done, _ = env.step(action[0])\n",
        "        state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "        done = done or episode_length >= max_episode_length\n",
        "        # print(\"rwd ext: \", reward)\n",
        "\n",
        "        reward_sum += reward\n",
        "        # a quick hack to prevent the agent from stucking\n",
        "        # actions.append(action[0, 0])\n",
        "        actions.append(action[0])\n",
        "        # if actions.count(actions[0]) == actions.maxlen:\n",
        "        #     done = True\n",
        "        if done:\n",
        "            end_time = time.time()\n",
        "            print(\"Time {}, episode reward {}, episode length {}\".format(\n",
        "                time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)), reward_sum, episode_length))\n",
        "            result.append((reward_sum, end_time - start_time))\n",
        "            # f = open('output/result.pickle','w')\n",
        "            # pickle.dump(result, f)\n",
        "            # f.close()\n",
        "            # torch.save(model.state_dict(), 'output/{}.pth'.format((end_time - start_time)))\n",
        "            torch.save(model.state_dict(), 'model.pth')\n",
        "            reward_sum = 0\n",
        "            episode_length = 0\n",
        "            print(''.join([str(a) for a in actions]))\n",
        "            actions.clear()\n",
        "            # state = env.reset()\n",
        "            # state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "            # time.sleep(60)\n",
        "            break\n"
      ],
      "metadata": {
        "id": "ja6KZf13p--B"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### my_optim"
      ],
      "metadata": {
        "id": "_R9i720bZg8Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# my_optim.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/my_optim.py\n",
        "import math\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "class SharedAdam(optim.Adam):\n",
        "    \"\"\"Implements Adam algorithm with shared states.\"\"\"\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n",
        "        super(SharedAdam, self).__init__(params, lr, betas, eps, weight_decay)\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                state['step'] = torch.zeros(1)\n",
        "                state['exp_avg'] = p.data.new().resize_as_(p.data).zero_()\n",
        "                state['exp_avg_sq'] = p.data.new().resize_as_(p.data).zero_()\n",
        "\n",
        "    def share_memory(self):\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                state = self.state[p]\n",
        "                state['step'].share_memory_()\n",
        "                state['exp_avg'].share_memory_()\n",
        "                state['exp_avg_sq'].share_memory_()\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "        closure (callable, optional): A closure that reevaluates the model and returns the loss.\"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "        for group in self.param_groups:\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = p.grad.data\n",
        "                state = self.state[p]\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "                state['step'] += 1\n",
        "                if group['weight_decay'] != 0:\n",
        "                    grad = grad.add(group['weight_decay'], p.data)\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                denom = exp_avg_sq.sqrt().add_(group['eps'])\n",
        "                bias_correction1 = 1 - beta1 ** state['step'][0]\n",
        "                bias_correction2 = 1 - beta2 ** state['step'][0]\n",
        "                step_size = group['lr'] * math.sqrt(bias_correction2) / bias_correction1\n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "        return loss\n"
      ],
      "metadata": {
        "id": "_iYAN2OepyJo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### main"
      ],
      "metadata": {
        "id": "fj3tv7XHZmD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# main.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/main.py\n",
        "import os, sys, cv2\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import gym\n",
        "\n",
        "lr=0.001\n",
        "gamma=0.99\n",
        "tau=1.00\n",
        "seed=1\n",
        "num_processes=4\n",
        "num_steps=20\n",
        "max_episode_length=500 # 10000\n",
        "# env_name='PongDeterministic-v4'\n",
        "# env_name='LunarLander-v2'\n",
        "# env_name='MontezumaRevengeDeterministic-v4'\n",
        "# env_name='MontezumaRevengeDeterministic-ram-v4'\n",
        "\n",
        "no_shared=False\n",
        "eta=0.01\n",
        "beta=0.2\n",
        "lmbda=0.1\n",
        "outdir=\"output\"\n",
        "record='store_true'\n",
        "num_episodes=10#100\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "# env = gym.make(env_name)\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "# query_environment(\"MountainCar-v0\")\n",
        "\n",
        "# print(env.observation_space.shape, env.action_space) # (210, 160, 3) Discrete(18)\n",
        "\n",
        "shared_model = ActorCritic(env.observation_space.shape, env.action_space).to(device)\n",
        "# shared_model.share_memory()\n",
        "if no_shared:\n",
        "    optimizer = None\n",
        "else:\n",
        "    # optimizer = SharedAdam(shared_model.parameters(), lr=lr)\n",
        "    optimizer = torch.optim.Adam(shared_model.parameters(), lr=lr)\n",
        "\n",
        "    # optimizer.share_memory()\n",
        "args=None\n",
        "# train(0, args, shared_model, optimizer)\n",
        "\n",
        "# processes = []\n",
        "# import torch.multiprocessing as mp\n",
        "# p = mp.Process(target=test, args=(num_processes, args, shared_model))\n",
        "# p.start()\n",
        "# processes.append(p)\n",
        "# for rank in range(0, num_processes):\n",
        "#     p = mp.Process(target=train, args=(rank, args, shared_model, optimizer))\n",
        "#     p.start()\n",
        "#     processes.append(p)\n",
        "# for p in processes:\n",
        "#     p.join()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjPLqIBgH9xJ",
        "outputId": "4001d4e8-5faa-4923-915e-9b77871fc38b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:565: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:98: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### wwwwwwwww"
      ],
      "metadata": {
        "id": "wFrRKvOwhYM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train(0, args, shared_model, optimizer)\n",
        "# test(0, args, shared_model)\n",
        "\n",
        "# for x in range(20):\n",
        "#     train(x, args, shared_model, optimizer)\n",
        "#     test(x, args, shared_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHLw7ewldCLm",
        "outputId": "a779b512-b08b-4739-bc35-4004982b3d38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:565: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:98: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # # (optional:) mount to google drive to save the model\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "PATH=\"/content/gdrive/MyDrive/curious/\" # for saving to google drive\n",
        "# PATH=\"/content\" # for saving on colab only\n",
        "name='model_mario_train.pth'\n",
        "model=shared_model\n",
        "torch.save(model.state_dict(), PATH+name)\n",
        "# model.load_state_dict(torch.load(PATH+name))\n",
        "\n"
      ],
      "metadata": {
        "id": "TN-XW-LvZ8Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f9527f-502c-4c40-ae67-b6c69a7c6dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import gym\n",
        "from colabgymrender.recorder import Recorder\n",
        "\n",
        "# env gym.make(\"Obert-v0\")\n",
        "env = Recorder (env, './video')\n",
        "observation = env.reset()\n",
        "terminal= False\n",
        "while not terminal:\n",
        "    action env.action_space.sample()\n",
        "    observation, reward, terminal, info = env.step(action)\n",
        "env.play()\n",
        "\n"
      ],
      "metadata": {
        "id": "7eiY5i13mrmb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### video"
      ],
      "metadata": {
        "id": "lFZ99OzuAurr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !apt install python-opengl ffmpeg xvfb\n",
        "# https://github.com/openai/gym/issues/1898#issuecomment-860034155\n",
        "!apt-get install python-opengl -y xvfb\n",
        "!pip install pyvirtualdisplay \n",
        "from pyvirtualdisplay import Display\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()\n"
      ],
      "metadata": {
        "id": "J94LIJiKTE2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94485680-de05-4048-c989-31cde715af4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python-opengl is already the newest version (3.1.0+dfsg-1).\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.10).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (3.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyvirtualdisplay.display.Display at 0x7f4f8e5d5c90>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# env = gym.make(env_name)\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "\n",
        "action_space = env.action_space.n\n",
        "state_space = env.observation_space.shape[0]\n",
        "state = env.reset()\n",
        "state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "# print(\"state\",state,state.shape)\n",
        "action = env.action_space.sample() # Take a random action\n",
        "observation, reward, done, info = env.step(action)\n",
        "# print(observation)\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "screen = env.render(mode='rgb_array')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.imshow(screen)\n",
        "# plt.imshow(screen[:,:,0])\n",
        "plt.grid(False)\n",
        "print(screen.shape) #(400, 600, 3)\n"
      ],
      "metadata": {
        "id": "fLHOCMWBMCxL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "outputId": "ae84b065-e0b3-40f3-fd47-0b5057545ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:565: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:98: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:298: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`\u001b[0m\n",
            "  \"No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:306: UserWarning: \u001b[33mWARN: No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), rendering may occur at inconsistent fps\u001b[0m\n",
            "  \"No render fps was declared in the environment (env.metadata['render_fps'] is None or not defined), \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 256, 3)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAARQAAAD8CAYAAAC2EFsiAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de3wU1dnA8d/ZzZUEEgIhYAABQe4KGhUVFUEUqApeitJ6rS3VipaqfUVtX7W23upb76KoKFgFvACiIooUkUu53ySBkHAnQEIghARy253z/nE2yYbcNsksu0me7+ezn+ycmdnnzOzk2TMzZ2aU1hohhLCDI9AVEEI0HZJQhBC2kYQihLCNJBQhhG0koQghbCMJRQhhG78lFKXUCKVUqlIqXSk1yV9xhBDBQ/mjH4pSyglsB4YD+4E1wDitdYrtwYQQQcNfLZQLgXSt9U6tdTEwExjtp1hCiCAR4qfPTQT2eQ3vBy6qbuLIqLa6ZesufqqKEKIhDmesy9Zax/syrb8SSq2UUuOB8QDRsZ256YFVgaqKEKIGb08K2ePrtP7a5ckAOnkNd/SUldFaT9FaJ2mtkyKjfEp+Qogg56+EsgbooZTqqpQKA24F5vkplhAiSPhll0dr7VJKTQC+A5zAVK11sj9iCSGCh9+OoWit5wPz/fX5QojgIz1lhRC2kYQihLCNJBQhhG0koQghbCMJRQhhG0koQgjbSEIRQthGEooQwjYBuzjQ36JbwKC+sC8TUveasgv6QEwU/GcdWBZEhMHgc8243Qchfb95f1FfaNmi4ucdPQ7rU837Pl3hjLYVxxeVwNKN0DYWBvSoOG7pJigqtnf5mqJuidDtDFi7DY7lmbJhSVDsqn3dDrsA1Cmft3U3ZBw27y8fAKEhsGht1TG9/bDGnuW5fACEhVYsO5ANKbuq34Y2bK9+u128DoacX3k5wcx3JNeeejdEk22hxETBmCvgxivh7M5wSX+48QpTFuI0r18OMwmlXRzcdCWclWjmHZpkpnO5zZccHgo3DIELepvxbk/5sAtg9OVmgy8ugdhouHko9O1mxheVwGUDYOxQcDbZNW2f3l3Mem8bU142+nIYMajmdRvihDGXw/ALy8d1SzTTt29jPmfkJXD95dXHjIk28426xMxnh2IXlLjMMgxNMp/vcptx1W1DtW23py5n6cuy7KlzQzXZFkqpxHj45VBoEQEto0yZAn43GjonwLtfmsx+3WUw9ir494LyeZduMl98u9Zmgzz7TFiz1fxypO6FK8+H6Ejz66m1idWvG/y43pSB+bW5qB/MWgTuIPnSG4Nbh8PsH8uHoyKrX7efLjLDhcXl4yLCzD9qXEs4dKT2eJvSTAs1+xjcewNEhsNH3zZsGVZuAYcyCaqgqLxuUPM2BFVvt6W8lzPYNPmEAtChbeWyPl3NbszOA2Y48ygM6gctIytOFxEG48f4v46i3K+vgdiW0PUMUFW172vR60wYcl79Ym/dbWL2OrN+89upqu0WTGtq0h3lw9+tNLs8waDJJ5QVP5vm4J6DcPl50Kld+bjWLeEf95r34WGV531mvPlbVAyPTzZNUuF/8a3N38Q63ian9PsMDYE1KfDdKjhZaH/9Toeattu8k/DWF+XDBUWnv37VafJ79sUlpkm8Mhksd8Vxx/LhyXfNa+HqyvP+/QPTHG0ba341C70OrHr/cjpU+YEyrc240heApQF5Jr3PLA3/+BBOFJr1WaradetxLB8+/MbsrgweAP3PKj9mUerU+U8tf/Y+M8+T7/pjySrHLOW9DUHN261lmaRS+jp1GQOpybZQtDaZ2+UqP2BVVGLKNCY5FBaVfxnFnnFubVokBUXm76S34OnfmYN8Y4eZL/nWq+B8zwHawmJ4/n44fgKemQqTZ8Pd18KFfcrr8td3zEE3UTOXy6z3ybPhYDY8+ga8MMGs44zD1a/bopLy7zNtH7w3D24bYQ5kZudC6h4zPsQJL04on3dNCuTmm5jeu7UPv1YxkTVUYXHls3zVbUPvz6t9u20RUXE5wCxzqs83avQfvzxGo67adUzS/rqnbESYOaAHZuPxzuYOBa1bmfcFRZWbx3GtzK+I221+/by1ijJNa6h8uq4hMesrQp0gynGcrNxiiGiPMyTc53nru5yB0iLCtEJOXbe+aBNT9XIGSmw0OJ0mgR09Xl4eiG2oOm9PClmntU7yZdom20IBs+Fd0h/6d4eEOJj3E6xKMRuUUubA7PCLzG7NnkMwd4n5lQA4s735hQt1QqtomPwFHPScLYhvDSMHmY2zyxnw6izYmdHwmPVeTpXHiOhPGBo1h78uSWdzq79wRp9xPiWV+i5noLSKMqf4z+8FL/4b9h7yfd6zEmHirZCVY1qTgdahLfzhRpMcSlzwp1dMeSC2Ibs02WMokeFw9UXmbMHLM8yR8NGXmy/KoUyz+ZfDzLiPvjWdjK4dbDbY3l1gwi/hjc/h9c9MZ6S7rzX/fGe0hV9fbQ6avTwTVifDg2PhnO4Ni9kQ3cKSGRo1B4Bnbu5O5n8foiA/CwCHA/qdVT5tQpw5JgT1X85ASoyHju1qn64qpZ0Yg0GXDnDPdWZXzrv1EahtyC5NNqHEtYKrLigfXrzO9DG45SrThL9tRPm43Qdh3TbzpXWMN7/YkZ4f96ISmL0Yzog3B/oG9oTuXvfz//g780XfclXDYvqLUtC1g+ltmRAH5/U0v2xQ/+UMpK27YcvOyuVOh+nwdeqrjVcnuYb2K7HLWYlmPe7LNHXyPnsYjNtQXTTpXR5hmsnfr4JLzzGXFGxKM83kpibEaX7JT5WRFTzHfkr16gKdEszlBdddZrrnO5Sp/9qtga5dwzTZFkp2LsxfAeecBed6Xf8xfb7ZX31vnrle54Yh5eOWbIA9mTDrB3Oga7zXw1P3Z8Hitabpv21PeXdtAJcF075pWEx/Cgs1++u5+RU7S9V3OYNRicv0zTj15e91Wx+rk03dlm6Czekm6Vsatu4K3m3IV036LE9EmNkfvagv5BfAN8tNc9myyntD/na0aVJu2WEuHCs9Yt6+jemNmHnU/CPO+qH8ly62pfknDA8z+7/T55dfhNaQmPV1dNe3nHtkIo9e25VHZmynf/FRtgxJpiA8kbAQ+P0NMGOhqc/lA+DwMdiQ2rDlDITuHc3xg5goc/FnVo75J3vpY/O3Jn+8xRzsTIw302blmH/mb5afnrrX5MUJZnem9KBsILahmtTlLE+TTihgvqgITy/YE4UVL6JSqvx4QrHnIitv0S1MZyPLMvN6iww3zWwwnYvsilkfblcR21e9ytYlT/HXc0PJGzybfa2GoJWpYFQknCgw04aFmP4M3v+A9V3O083phBZVnLjypV7RkZU7s5W4KnZWDJToSEBBvtdynO5tqCaSUJohy3KhLRchSqEdoaCa7N6sOM2kH0oz5HCEgCNEeviLgJKfMSGEbSShCCFsIwlFCGEbSShCCNtIQhFC2EYSihDCNpJQhBC2kYQihLCNJBQhhG0koQghbCMJRQhhmwZdy6OU2g3kAW7ApbVOUkrFAbOALsBuYKzWOqdh1RRCNAZ2XBx4pdY622t4ErBIa/28UmqSZ/hRG+KIZsiy3KRt+LhsOLZdLxI6XRjAGoma+ONq49HAEM/7acCPSEIR9aC1ZtOS57kqqfymJXszd5G51yKh86AA1kxUp6EJRQPfK6U08I7WegqQoLU+6Bl/CEhoYAzRDK1a8AQF+Vk8cu+l3HXXXWXlKSkpvPDKTA5nhBGfWM8HGAu/aWhCGay1zlBKtQMWKqW2eY/UWmtPsqlEKTUeGA8QHdu5gdUQTcmKrx/hkd9fREK7OIYOHVphXJ8+fYhvdZKU7N1sW/sBScP+l8joILnlu2jYWR6tdYbnbxYwB7gQyFRKdQDw/M2qZt4pWuskrXVSZJRsEKLc4Yx1XJA0gGHDhqFOvW8j8Oc//5nIgm946uFr+O+cm3GVBPjelKJMvROKUipKKdWy9D1wNbAFmAfc6ZnsTuDLhlZSCIDVR2HKTkhISOCDd1/m2l9cw7LFc5j9al+C4VamomG7PAnAHM8vSAjwidZ6gVJqDfCpUuoeYA8wtuHVFM2BZblZOudePnr3Sbp3747LguuWQ2wozBgESa0howC+2A83dTQP942Li6OoQHolBIt6JxSt9U6g0sMdtdZHgGENqZRoPizLTXHhMQC2rXqNv0y8iiFDhgBw+yr4enB5M9qh4IZE82Bxb3FxrSkqOEpEizZY7hJcrkLCwluevoUQZaSnrAgYy3KTtWcJK2ZexoqZl/Hra9tzyy23lI2fMQicqvLjL04d3rFjB5+80B3LXcKB9PkkL36IgvwAPkCoGZO73ouA0NriQNoC4txfkJKS0uDPG3zZpWSkfU3X6CX8avxwXnznZQaNfNaGmoq6kBaKCBDNmS2+Z+rUqQ3+JIfDwby5n9OrzUpeeeWVsvJDe/5Lfu7+Bn++8J20UMRpt3HJS1juApZ/80rtE/soIiKCF154AYC+ffvSt/s2QtwLyUzTOHreS4uW0r/ydJCEIk6r1d/9ld/cfCbRUe39FqNv3778+QFNaGgoDz30EAX5N0hCOU0koYjTavfWr7nxhu9o166dX+P069fPr58vqibHUMRpNfLOOVx19WiKi/3/lPKnn34aZ7vbiY3v6fdYwpCEIk6rlq27cNFN8+narQdaa/afhL9sKe9bUlOH11VH4J0dvsV57bXXWLqlLYm9bsQZEt7wigufSEIRp114ZGuuuz+Vjp260C60hDFnwEvbocSC57fB+pyKCabEgtQ8+PIA/KZrxc9yWVUnoQkTJtCnw3Yy0hehteX/hRKAJBQRICGhEYwcv54B555LUhwMjIWb/wsrj8KfN8PWPDhWDNnFMPwnuG8dbDwGr6SZ8tLX79ZBURX5wuFw8Nprr+I8Op2crG2VJxB+IQdlRcAo5SSyZSeSk5PpALx3djvi4+N5biu8uA32nDQ33OnSAjq3MN3un9kK33juttMhAt4YCBHOyp+dnZ1NZmYmF1/3Lnuzo0/nYjVrklBEwIRHxtJ/+Hv84ubxAIwedQmPPnwPj/U+A4C/bgGXhqfOLmL9+vUMbH0xD50NczPM/A/2gDbh5s5uixcvZujQoRw7dozVq1ez4Ic1zP5qGRde8wztOiYFahGbHRUMl32365ikb3pgVaCrIQJsV/KX9ErYRp8ebbn55puJiYnB7Xbz5ltTmPNdKrfd0J8+ffpw8cUXl80zc+ZM8vPzeWv6Ou6/M4kDmXnM+iqFzj1H0K3fjQFcmqbj7Ukh67TWPmVlaaGIoNG172hSUxQrNv3M1tR/0SJCY2n46ec2dD//Md77/D06JWTw7bffls2zdFMYhSUOLhr1Cu99/hJRMR0ZctOUAC5F8yYtFBGUdqXMo6QwD+Vw0GPAuLLyY4dTydq3tmy4a78xhIZFBaKKzYa0UESj17XP9VWWx8b3lI5qQUxOGwshbCMJRQhhG0koQgjbSEIRQthGEooQwjaSUIQQtpGEIoSwjSQUIYRtJKEIIWwjCUUIYRtJKEII20hCEULYRhKKEMI2klCEELaRhCKEsI0kFCGEbSShCCFsIwlFCGEbSShCCNtIQhFC2EYSihDCNrUmFKXUVKVUllJqi1dZnFJqoVIqzfO3tadcKaVeU0qlK6U2K6XO82flhRDBxZcWyofAiFPKJgGLtNY9gEWeYYCRQA/Pazww2Z5qCiEag1oTitb6J+DoKcWjgWme99OAMV7l07WxEohVSnWwq7JCiOBW32MoCVrrg573h4AEz/tEYJ/XdPs9ZZUopcYrpdYqpdYWnDhcz2oIIYJJgw/KavMs0zo/z1RrPUVrnaS1ToqMim9oNYQQQaC+CSWzdFfG8zfLU54BdPKarqOnTAjRDNQ3ocwD7vS8vxP40qv8Ds/ZnkFArteukRCiiav1YelKqRnAEKCtUmo/8CTwPPCpUuoeYA8w1jP5fGAUkA6cBO72Q52FEEGq1oSitR5XzahhVUyrgfsbWikhROMkPWWFELaRhCKEsI0kFCGEbSShCCFsIwlFCGEbSShCCNtIQhFC2EYSihDCNpJQhBC2kYQihLCNJBQhhG0koQghbCMJRQhhG0koQgjbSEIRQthGEooQwjaSUIQQtpGEIoSwjSQUIYRtJKEIIWwjCUUIYRtJKEII20hCEULYRhKKEMI2klCEELaRhCKEsI0kFCGEbSShCCFsIwlFCGEbSShCCNtIQhFC2EYSihDCNpJQhBC2kYQihLCNJBQhhG0koQghbFNrQlFKTVVKZSmltniVPaWUylBKbfS8RnmNe0wpla6USlVKXeOvigshgo8vLZQPgRFVlL+stR7gec0HUEr1AW4F+nrmeUsp5bSrskKI4FZrQtFa/wQc9fHzRgMztdZFWutdQDpwYQPqJ4RoRBpyDGWCUmqzZ5eotacsEdjnNc1+T5kQohmob0KZDJwFDAAOAv9X1w9QSo1XSq1VSq0tOHG4ntUQQgSTeiUUrXWm1tqttbaAdynfrckAOnlN2tFTVtVnTNFaJ2mtkyKj4utTDSFEkKlXQlFKdfAavAEoPQM0D7hVKRWulOoK9ABWN6yKQojGIqS2CZRSM4AhQFul1H7gSWCIUmoAoIHdwO8BtNbJSqlPgRTABdyvtXb7p+pCiGBTa0LRWo+rovj9Gqb/B/CPhlRKCNE4SU9ZIYRtJKEIIWwjCUUIYRtJKEII20hCEULYRhKKEMI2klCEELaRhCKEsI0kFCGEbSShCCFsIwlFCGEbSShCCNtIQhFC2EYSihDCNpJQhBC2qfV+KM3Fz8tfZ+2iv1coczic3PFEBkqpANVKiMalWSYUrTXacpF3bC8zX+lrCn9hoadYFSe0YMo9kQAkdhvCqDu+QikHyiGPGhKiKs0yoRSdPMKHL7eHNsB0rxFVNET0dBdo2L/hB6Y8F8nASx4l6fL/xRkSfrqqK0Sj0ewSSu6RHXw6a4C5V78vezIa2AzMBf4JG1a+QNj6GPoPmEBIWAu/1lWIxqZZHZTN2reWOYsuxf33At+SCcAJ4HkgDZgJjIRV4Y+TvGUKruKTfqurEI1Rs0koGen/YWHqrRT+IRvCGvhho+G/zkfYvOF13K5iW+onRFPQLBLKvu3fsfTwg+TduBuifZxpHvB5DeNHw+qYJ1jz45OY550JIZp8Qtmf9gMrjj7Csau2QVwdZvwamA1EAOMwT2geeso0I2Bj73+yZPZ4m2orROPWpA/KHtqzgqUHJpB7bbo5o1MfIcAI4FygSxXjL4FtraZR9O9crrnts/pWVYgmocm2UHKytvL9xlvJHdOAZFIqnKqTCZiDu/00u8fOY8H0GxsYSIjGrUkmlJN5h5j91aWcHH8AYur5IS8DU/DtbJAC3d3NnrHf8MOM29Ba1zOoEI1bk0ooWmuKi/L4aMqZlDx1HCIb8GFR+H4AF8ABuqeb9OGzWP7NRCxLHuksmp8mlVCKTh7hg9faol93QyB6xysgSbOlz5usX/4cbldRACohROA0mYSSm53Ox//ubpJJoA2FtTFPkbzpHVwlBYGujRCnTZNIKFn71jBvyVBKnswPniW6HlbwEFu3vI+rpDDQtRHitAiWf796O7BzCYu238GJ3x4wfUaCyU2wnIlsWfcGlrsk0LURwu8adULZn76IZYcmknt9Wv3P5vjbDbAyZhKr//OknP0RTV6j7dh2YNdPrMh6mKPDtkC8jzN9humk1tLGimjM6eXf1zDNSNi4/EUKZ2cz5KYpNgYXwWbb2g/J2PGfsuErb34fhzO01vksdwmLP7+nbLhjj+H0PO92v8b0h0aZUA7vX8eSHfeSO3q778nkU2A+sAn4X+p0gWDH4zD1u4plDw+Bn+OBF4GNQD7wcA0fcgmkRk+j5JM8hv9qhu/BRaORtnEGHXs+z6jxR8vKXn9gJKPuWljjXf+01iyYPoIJr/9cVrZx8WrSN0fQ/Zxf+iWmvzS6hHL86E6+XXkDJ39Xx05r+4FCIB2ow7V8MYXwn8+gc17F8rlfQoHn1PQ5Gqy0Wj5Ige7vZmf4HBZ+PI7hv5ak0lQczljPwk/GMexXRdzwYDFRMeW/Vk9+toXHRg7ipgdWVTnvV+9dQ37Obv7vx1w69iifr9s5x5n+9P+wb3sMnc6+2taY/tSojqEUnjzKZ7PO5+QEH5OJ9nrVkxUCKefBgisg+dr2OO++gi3XJhB93QDuuDWSS9PrkJ8coM92sfP62Sz+7B45ptIE5B3bS+r6a5ianMddfyshKqbiv1SHbk6O5+ziWHYaC6bfWOE7n//BdTz20WbeT84jsXvFjlPRsQ5CQo9QUpzPvHeHk5+bYUtMf6s1oSilOimlFiulUpRSyUqpP3rK45RSC5VSaZ6/rT3lSin1mlIqXSm1WSl1nh0VLSk+wbTXO1DyXJ7vZ3PWA7/G7OqUfl916PDm0DA9LYTLzxpEbKvW9E/sgwoPxQp1YoU6WMHFZL4yjMgwh+9tPQfofm5SB09n1fePSY/axk5buN35RMc6CI+suItRYmkcTpiWGsKqBefy+5eWsXTub7EslxlfnE9ktCY61lFh98TSGrel+e3zLSksvIv/+XAzi2b1oKjgqEkODYjpb760UFzAw1rrPsAg4H6lVB9gErBIa90DWOQZBhgJ9PC8xgOTG1rJghPZfPBqPPotd93bVBamhfJH4Bzgdep0etmhwWW5OV6cz5Zss1/TP/5sUo7u4HhRHm5dQsqUS+CNOtRJARdrNp75EptX/Ut61DZSWlsUFx6lZazZKAtdmmNFbkos0yK4f3E2RwotYuMdTF4bx8ChYYz4zRw2LH6e4sLjtGjpxuE0x1COFbnJLTJt3fVZxbybnEexBY//uxW9Lgjlg5Q4ZrzUHhoQ83So9d9Ta31Qa73e8z4P2Iq5O8hoYJpnsmnAGM/70cB0bawEYpVSHepbwdzsNGbO6I31arHvt22szuPU7Z4oQHqoi6+PJTOq6xWcE98TgLSc3bgtFxuzUnj34E90C19Wv/qMgJXhj7FtywfS+a2R0VqTnbGGHcmD+dvc1pwosZiz4wSTlueQmmP6HE0ZFs/fVh2rtMtxMj+LTcvu5o+TU+nQLYS9eW4eW57Ds2uOAZCUEE7P2FCWHai8TRw+UL+Yp0udDsoqpboAA4FVQILW+qBn1CEgwfM+EdjnNdt+T9lB6ujw/nV8v/YWih7Lqd/h41aY+5j4eiboFJaC/+kOI/PcXHcsm/BiyIuCNhGx5MTFku+EJ0J/RqsG7LbcCEtnTYBk6NXvbrmbfpA7tGclxYW5gObYkZt59mvzC7Uz10VchIO3h7atMP1rQyreO6NNopOI6Pe4+U9RnH2++a6nb8vjzSvb4PDa7bmyU+UrWwcODeXQ3mH1itmi1S5O5GYQFZPIwV1LSeg8yC+nlpWvmUwpFQ0sAf6htZ6tlDqmtY71Gp+jtW6tlPoaeF5rvcxTvgh4VGu99pTPG4/ZJSI6tvP5t03aWSHewV3L+Gn3H8gZnVLnVoVdlIZfHIG7DkHbo5B4EDb1hTZH4ZMzYbenP8vC1jS89fQFDCp5gXMunIhDnvsTlPalLcTlmogjZC9KwQOvt2o0D4Gb/nQeB9PfIDwyFpx/5GTuRHpfMAGlaj+G8PakkHVa6yRf4vj0u6+UCgW+AD7WWs/2FGcqpTporQ96dmmyPOUZQCev2Tt6yirQWk/BdAmjXcekClntwM4lrDj0MDmjApdMAG7NhBuzy4dj8qBXOrQ7DOMUHG1tDs+0LYEZCdV+jG9ugpXfPkrhwmwuuvrZRrOhNhd7ts0nouVf+NVDR2nTIVi7ZVdv4LBwDu2aS8u2Wxn7SCF39X6YXkl/8Cmh1IUvZ3kU8D6wVWv9L69R84A7Pe/vBL70Kr/Dc7ZnEJDrtWtUq8y9K1l+4E9kX7mxfCcqQJ529mVgfC/Ci6BHbhQxnRLpvhtizkzk7JwWhBfBwPjePOXsY0/AkbCx30v8NOc+ez5P2KbnBf/lxgcP0qZD42w99h8cxnX3LeWmiTm0jDP/9pa7hKVzJ9gax5f0dClwOzBUKbXR8xqFeVrNcKVUGnCVZxjMSdqdmC5k7wJ/8LUyRw5tYXHKPRy5ejPU+zCufRJbJtC51RkMatOXNvuK0AdyANAZObTdX8Sgtv3o3OoMEqNtzHyXaLYN+5AfZvrW7Vr418Hdy5n79hXgmEN8p8aZTEr1viiM2HZmGZ75sjXf/fsafvln0yfKLrXu8niOhVTX/h5WxfQauL+uFcnPzeCbxaM4ed8BiK19+tNFFbtpuTAdil3mBZBrHvDV8vs01C1tIczG3RMFur+LnSGfs2iWg2G3TKt9HuEXOZlbOZxxG8/NL6BlGweNrB9ojXpfFMozc7cTGqHIPrDRts8NijVkaTezpvXl5J+CK5m0D19C97Bl6BNFaGBGL4i/D2b19HTAPVFE17CldAj/yd7ADrB6l5A+fCZL506QHrUB4nYX4bayaN/VSXRMUPyr2EYpRUIX+1tcPp/l8SeHU+mwj0OrTW9FxSWEOUCFeJ3msiy05UY5nOCoekbLsnC73YQ6K06jXeacfYXPqyJmuAM+2mo6tyVHK57r4sCy3DgcTv6yy6LXCY2l4PY+gOcUXENjVlhODSzRnL/jcQYOfQxVzXK6LY3ldhHidFaYRrtcnpjVN0SrWrfassByg8PZrGNqDbu3fkVo5B3c91IseB/AdJcACpzVxywuMTHxPj2ry2NSzQFRy7Kw3G5CQpx+jVlSpLnjbAfjHtmOpVW16/bNx6PsPcvjb/3bhPNjp3eqHX/2tQ+w5pdtiLnzqbKy/ORVFCybTdzwcTi7DahyvgXLN7Bw+lRe+OM4QvpcUla+541HaNemNZHjnqgx5jsTnYS4cgEYEtaHu49fXhYzOXQBue5UAD5PDuXSkVNsiVlpOQesoiD/HeLOOF7zcn4ylWfsiunrum0OMdnAwulOBn58rc0xx/ptu61LzPQ5ALNqXLdvVhutsqBIKI42Z3Dy7YnVjtcF+bS4511OvnFvWdlnO4o4MnAMD+5Po+j7D6ucr3B/CaH9r0CfyK3w+YO/yGXfstc5+Xr1Z1N0QT6DR8ygpDTm/kMk9bMAAAnYSURBVAxm7fiwLGb3lEN4X6FY+vkNjRmI5ZSYErO6mJd8dqzaWFVpWjuGVQpEfw6JKTGbZ8xGk1A0MDO9fhfRrT3sYk9e3bvHS0yJKTHrJih2eXxRsPQLnlhTQPpxc0VmuBOuaV/7tQjujDS+ynSwM62Abq3MUe2J/X273FhiSszmHvNP50Tw7AbfL1xtNAkltH1XJj/7SNnwnm0pZBVYtd4fVrVoybgxw9hxvPw2SF+/69sdFSSmxGzuMb+a8pZPMUs1noRy9vmM2Pxi2fCsQ0fYHnkxI2pZSY7WCfQOP0GP7JVlZQ/s9S3jSkyJ2dxjTvAxZqlGk1DQGuvgjrJB65jv+4g6N7vCvGgfb9ooMSVmM4+prTrcgJkgOihbXQc7rXUtB591lfOWl1U3c9XzSUyJKTHrLygSyubU3Vw5v5BCl6bYXXGBr5mfx4qvp1Iy+YFK8/1zyqd0+9sPLM+0KHRVXFkpORaf6T48M7wLJesqPgPD0pqOV9wtMSWmxKwlZl0FRUI5p1c35r7/HIMXOXh0k+LQSavs1SomBmdRfpXNvT+PH0vGjx/wsasngxc52Zmny+bLdTuIjQpHFVd+WLlDKTJWzJCYElNi1hKzroLjGIq2aP3dqyT/+ykWb9jObz6cD8CufYdY8MHfiJz7Irqau8MX/ecTpv7mMhwJt3Pto5M5UVhEicuN0+Hgx2eHUTj31apDlhRJTIkpMX2IWRfBkVAAfSKXgo+e5JLEHvzn73cAcMs/Pq5y2iOFFslH3bT3DBd9/wEA8x69FxUaTmZOHrf8c3aV8/50sITSlqLElJgS07eYvgqKhGKdzGPqNs+R6G1bYNEWAHoWW7QOV3ySXkxBXvmR6h3H3aw45OJvxXv4MTmP7aml85oM69aaMV07szff4uttFY9wv7SpkLHdwijYsFhiSkyJWUvMW84K46O0YnwVFAlF5x+Dm35dqfyezmF0iG/NCxsL+V0XiBwyFoCzgBGFe7ksbwM/tToPLqv4LLFWIYo7BrTlh8Nu5u0p5hdDLsDZ0TwC45HL4PbDX1O8fDZcNlZiSkyJWUvMj9KOVIpXnaC4H8qAbh30grv7VTu+3wtL2PzOQzh2risrW779ELmR8VzbNwHreHaV832/7TBLj4byj1/0xsopv63t/dOW8c7fJ+JKW1vlfBJTYkpM4w8fLmPOzsLGdT8UFR6Je3v1KwmXi5DuAylZUH7PlD07ijgysD/65PFq53UfKMHRfgi4iitM893eIpzdzqXom7clpsSUmDXEXLCnbj1lg+K0sX8FogUmMSVm84zZaBKK24ILZ+eidfU9Bavz/MYCvttXUjavr/0BJabEbPYx69h5Nih2eXxxYvKD5Fhh9JptmmDXd3Lyz74RkHu8xvlKNi2mODyUB7a5UKvNvUeXj2nl05cjMSVmc4+5YkwrBnxe83zeGk1CafXAm2SMzysb/mT+Mt5KLuDBjjXPF3rulfx94m084/Uw8k5X38e+R2qYSWJKTIkJQMfh99YwR2WNJqFguTn5zkNlg0U7imDgGJ9mLf7vlxWvUXD5eF5dYkrMZh5Tl/jeBwUa0TEUIUTwC4qEcvjo8WrvgfnFzmJuHXM11ubFlcat3pTKlOW7OHiy8sVQRwot0nQcl5wZg5W1p8I4rWHyjPkSU2JKzFpi1lVQJBQUnDz/ep5aW8BnOyo2sSanFDLx9+NwL/+iyllDeg9iWmYMT60toNBVfkT70EnNBtozqmcc7n3bKocMCZWYElNi+hCzLoLiGEp8XAy3Jxxn+fg/sWd7Kvd8/XXZuPv/cDfhSz8Bd+UrKC88tye/7R3BmoTryXG25E9vvkFxkcnece3imXjr+bg2L6k0n1Jw7y3XkPvthxJTYkrMGmLWVVAkFLQmNH0NQ+MPcrzjmVz8wrMATHrhPc4b0B/nwu/R1XS6sTL3MODgDlRYBJ2efBy3M5QjOXk8/dp0krolULh5f9UxLUtiSkyJ6UvMOgiOhAJgubAydxN95AA9M34GIMrrmgJvq7Nc/G1dIfcPNMM65xAa6L5iCigHmSdcVLc3d+23eRS4JKbElJi+xCys6yN6SnvEBfLVNy5ERzqp9PpgSJTO/v513Sk+pkJ5mAN9Y9dQveu2NvpXZ0dUmq9ztEPvfLC//vS1xyuNU6A33dxKp94WLzElpsT0ISaw1tf/5aC42lgpdRg4AVR9KWTwaovU+XRpjPVuKnU+U2sd78vMQZFQAJRSa329RDpYSJ1Pn8ZY7+ZY5+A4bSyEaBIkoQghbBNMCWVKoCtQD1Ln06cx1rvZ1TlojqEIIRq/YGqhCCEauYAnFKXUCKVUqlIqXSk1KdD1qY5SardS6mel1Eal1FpPWZxSaqFSKs3zt3UQ1HOqUipLKbXFq6zKeirjNc+636yUOq/6Tz7tdX5KKZXhWd8blVKjvMY95qlzqlLqmgDVuZNSarFSKkUplayU+qOnPGjXdQ11tm9dB7JDG+AEdgDdgDBgE9An0B3tqqnrbqDtKWUvApM87ycBLwRBPS8HzgO21FZPYBTwLeYp2YOAVUFU56eAR6qYto9nOwkHunq2H2cA6twBOM/zviWw3VO3oF3XNdTZtnUd6BbKhUC61nqn1roYmAmMDnCd6mI0MM3zfhrg211s/Ehr/RNw9JTi6uo5GpiujZVArFKqw+mpablq6lyd0cBMrXWR1noXkI7Zjk4rrfVBrfV6z/s8YCuQSBCv6xrqXJ06r+tAJ5REYJ/X8H5qXsBA0sD3Sql1SqnxnrIErXXpRRSHgITAVK1W1dUz2Nf/BM/uwVSv3cmgq7NSqgswEFhFI1nXp9QZbFrXgU4ojclgrfV5wEjgfqXU5d4jtWkjBv0ps8ZST2Ay5sF3A4CDwP8FtjpVU0pFA18AE7XWFe7mHKzruoo627auA51QMoBOXsMdPWVBR2ud4fmbBczBNP0yS5utnr9ZgathjaqrZ9Cuf611ptbarbW2gHcpb2oHTZ2VUqGYf8yPtdalTxwP6nVdVZ3tXNeBTihrgB5Kqa5KqTDgVmBegOtUiVIqSinVsvQ9cDWwBVPXOz2T3Ql8GZga1qq6es4D7vCcgRgE5Ho11wPqlOMLN2DWN5g636qUCldKdQV6AKsDUD8FvA9s1Vr/y2tU0K7r6ups67o+3UeaqziSPApztHkH8ESg61NNHbthjnZvApJL6wm0ARYBacAPQFwQ1HUGptlagtnnvae6emLOOLzpWfc/A0lBVOePPHXa7NmwO3hN/4SnzqnAyADVeTBmd2YzsNHzGhXM67qGOtu2rqWnrBDCNoHe5RFCNCGSUIQQtpGEIoSwjSQUIYRtJKEIIWwjCUUIYRtJKEII20hCEULY5v8Bp0it7RCgybcAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# env = gym.make(\"LunarLander-v2\")\n",
        "env.reset()\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "from IPython import display\n",
        "# https://stackoverflow.com/questions/50107530/how-to-render-openai-gym-in-google-colab\n",
        "for i in range(200):\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  screen = env.render(mode='rgb_array')\n",
        "  plt.imshow(screen)\n",
        "#   ipythondisplay.clear_output(wait=True)\n",
        "#   ipythondisplay.display(plt.gcf())\n",
        "  display.display(plt.gcf())\n",
        "  display.clear_output(wait=True)\n",
        "  if done:\n",
        "    break\n",
        "\n",
        "# ipythondisplay.clear_output(wait=True)\n",
        "env.close()"
      ],
      "metadata": {
        "id": "U4QXiZvSWFr8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "outputId": "9a3cc8f5-d033-42ca-fa97-8067c5e65879"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-9ad358e6bd36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#   ipythondisplay.clear_output(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#   ipythondisplay.display(plt.gcf())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m   \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m   \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n\u001b[0;32m-> 2103\u001b[0;31m                             bbox_extra_artists=bbox_artists)\n\u001b[0m\u001b[1;32m   2104\u001b[0m                     \u001b[0mpad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pad_inches\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2105\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mpad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   2383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2384\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2385\u001b[0;31m             \u001b[0mbbox\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2386\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbbox\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwidth\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheight\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2387\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer, call_axes_locator, bbox_extra_artists)\u001b[0m\n\u001b[1;32m   4321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4322\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxison\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4323\u001b[0;31m             \u001b[0mbb_xaxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4324\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mbb_xaxis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4325\u001b[0m                 \u001b[0mbb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbb_xaxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_tightbbox\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1184\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1186\u001b[0;31m         \u001b[0mticks_to_draw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36m_update_ticks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1109\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0mtick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1111\u001b[0;31m         \u001b[0mminor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minorticklocs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1112\u001b[0m         \u001b[0mminor_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1113\u001b[0m         \u001b[0mminor_ticks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_minor_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mminor_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axis.py\u001b[0m in \u001b[0;36mget_minorticklocs\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1351\u001b[0m         \u001b[0;34m\"\"\"Get the array of minor tick locations in data coordinates.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m         \u001b[0;31m# Remove minor ticks duplicating major ticks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1353\u001b[0;31m         \u001b[0mmajor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmajor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1354\u001b[0m         \u001b[0mminor_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2202\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_view_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtick_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mtick_values\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2209\u001b[0m         vmin, vmax = mtransforms.nonsingular(\n\u001b[1;32m   2210\u001b[0m             vmin, vmax, expander=1e-13, tiny=1e-14)\n\u001b[0;32m-> 2211\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raw_ticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2213\u001b[0m         \u001b[0mprune\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36m_raw_ticks\u001b[0;34m(self, vmin, vmax)\u001b[0m\n\u001b[1;32m   2155\u001b[0m             \u001b[0mnbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nbins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2157\u001b[0;31m         \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2158\u001b[0m         \u001b[0m_vmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmin\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2159\u001b[0m         \u001b[0m_vmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvmax\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/ticker.py\u001b[0m in \u001b[0;36mscale_range\u001b[0;34m(vmin, vmax, n, threshold)\u001b[0m\n\u001b[1;32m   1960\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1961\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopysign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeanv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeanv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1962\u001b[0;31m     \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog10\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1963\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "\n",
        "cx = torch.zeros(1, 256)\n",
        "hx = torch.zeros(1, 256)\n",
        "\n",
        "state = env.reset()\n",
        "state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "frame=[]\n",
        "\n",
        "\n",
        "while True:\n",
        "# for x in range(500):\n",
        "    cx = cx.data\n",
        "    hx = hx.data\n",
        "\n",
        "    value, logit, (hx, cx) = model((state.unsqueeze(0), (hx, cx)), icm = False)\n",
        "    prob = F.softmax(logit)\n",
        "    action = prob.max(1)[1].data.numpy()\n",
        "    state, reward, done, _ = env.step(action[0])\n",
        "    state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            # print(\"#####www####\",Variable(state.unsqueeze(0)).dtype,(state.unsqueeze(0).dtype))\n",
        "            value, logit, (hx, cx) = model((state.unsqueeze(0), (hx, cx)), icm = False)\n",
        "            s_t = state\n",
        "            # print(\"logit.size\",logit.shape) # [1, 6]\n",
        "            prob = F.softmax(logit, dim=1)\n",
        "            log_prob = F.log_softmax(logit, dim=1)\n",
        "            entropy = -(log_prob * prob).sum(1)\n",
        "            entropies.append(entropy)\n",
        "            # action = prob.multinomial().data\n",
        "            action = prob.multinomial(1).data\n",
        "            log_prob = log_prob.gather(1, action)\n",
        "            oh_action = torch.Tensor(1, num_outputs)\n",
        "            oh_action.zero_()\n",
        "            oh_action.scatter_(1,action,1)\n",
        "            a_t = oh_action\n",
        "            actions.append(oh_action)\n",
        "            print(\"action.numpy()\",action.numpy())\n",
        "            state, reward, done, _ = env.step(action.numpy()[0][0])\n",
        "            state = torch.from_numpy(state.copy()).type(torch.float)\n",
        "\n",
        "            # print(\"###o###\",state.dtype)\n",
        "            # state=state[:,:,0]\n",
        "\n",
        "            done = done or episode_length >= max_episode_length\n",
        "            reward = max(min(reward, 1), -1)\n",
        "            s_t1 = state.float()\n",
        "            # print(\"###st###\",s_t.unsqueeze(0).dtype)\n",
        "            # print(\"###vst###\",Variable(s_t.unsqueeze(0)).dtype)\n",
        "            vec_st1, inverse, forward = model((s_t.unsqueeze(0), s_t1.unsqueeze(0), a_t), icm = True)            \n",
        "\n",
        "            reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1) / 2.\n",
        "            #reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1).sqrt() / 2.\n",
        "            # print(\"reward_intrinsic\", reward_intrinsic.data.numpy())\n",
        "            # reward_intrinsic = reward_intrinsic.data.numpy()[0][0]\n",
        "            reward_intrinsic = reward_intrinsic.data.numpy()\n",
        "            # print(\"ep \",x,\", rwd ext: \", reward.item(), \" ,rwd int: \", reward_intrinsic.item())\n",
        "            print(\"ep \",x,\", rwd ext: \", reward, \" ,rwd int: \", reward_intrinsic.item())\n",
        "            reward += reward_intrinsic\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    screen = env.render(mode='rgb_array')\n",
        "    frame.append(screen.copy())\n",
        "    \n",
        "    print(len(frame), action[0])\n",
        "    plt.imshow(screen)\n",
        "    display.display(plt.gcf())\n",
        "    # display.clear_output(wait=True)\n",
        "    display.clear_output(wait=False)\n",
        "\n",
        "    if done:\n",
        "        end_time = time.time()\n",
        "        # print(\"Time {}, episode reward {}, episode length {}\".format(\n",
        "        #     time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)), reward_sum, episode_length))\n",
        "        # result.append((reward_sum, end_time - start_time))\n",
        "        reward_sum = 0\n",
        "        episode_length = 0\n",
        "        # actions.clear()\n",
        "        env.reset()\n",
        "# # ipythondisplay.clear_output(wait=True)\n",
        "# env.close()"
      ],
      "metadata": {
        "id": "9NLEVwgYPnpZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 702
        },
        "outputId": "86ca6ca0-10f1-47ca-b669-5546dba93161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59 5\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-5373046e58b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscreen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# display.clear_output(wait=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mdisplay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/display.py\u001b[0m in \u001b[0;36mdisplay\u001b[0;34m(*objs, **kwargs)\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0mpublish_display_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mformat_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmd_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexclude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mformat_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m                 \u001b[0;31m# nothing to display (e.g. _ipython_display_ took over)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mformat\u001b[0;34m(self, obj, include, exclude)\u001b[0m\n\u001b[1;32m    171\u001b[0m             \u001b[0mmd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m                 \u001b[0;31m# FIXME: log the exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-2>\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36mcatch_format_error\u001b[0;34m(method, self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"show traceback on failed format call\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;31m# don't warn on NotImplementedErrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    332\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mprinter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m             \u001b[0;31m# Finally look for special method names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(fig)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'png'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 241\u001b[0;31m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    242\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m'retina'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m'png2x'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mformats\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0mpng_formatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mretina_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/pylabtools.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(fig, fmt, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0mbytes_io\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m     \u001b[0mfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytes_io\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytes_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfmt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'svg'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, **kwargs)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                            else suppress())\n\u001b[1;32m   2099\u001b[0m                     \u001b[0;32mwith\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2100\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2101\u001b[0m                     \u001b[0mbbox_artists\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bbox_extra_artists\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m                     bbox_inches = self.figure.get_tightbbox(renderer,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/figure.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[0;32m-> 1736\u001b[0;31m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'figure'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, inframe)\u001b[0m\n\u001b[1;32m   2628\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2629\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2630\u001b[0;31m         \u001b[0mmimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2632\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'axes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    135\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;31m# Composite any adjacent images together\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0martist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mdraw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[0;32m--> 626\u001b[0;31m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[1;32m    627\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36mmake_image\u001b[0;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[1;32m    915\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_clip_box\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m             magnification, unsampled=unsampled)\n\u001b[0m\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_make_image\u001b[0;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[1;32m    522\u001b[0m                     self, A[..., 3], out_shape, t, alpha=alpha)\n\u001b[1;32m    523\u001b[0m                 output = _resample(  # resample rgb channels\n\u001b[0;32m--> 524\u001b[0;31m                     self, _rgb_to_rgba(A[..., :3]), out_shape, t, alpha=alpha)\n\u001b[0m\u001b[1;32m    525\u001b[0m                 \u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_alpha\u001b[0m  \u001b[0;31m# recombine rgb and alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/image.py\u001b[0m in \u001b[0;36m_resample\u001b[0;34m(image_obj, data, out_shape, transform, resample, alpha)\u001b[0m\n\u001b[1;32m    200\u001b[0m                     \u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                     \u001b[0mimage_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_filternorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m                     image_obj.get_filterrad())\n\u001b[0m\u001b[1;32m    203\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### kutd"
      ],
      "metadata": {
        "id": "bR1zxxmE_vId"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "frame=np.array(frame)\n",
        "mesh = ax.pcolormesh(x,y,frame[0, :, :], cmap='magma', vmin=240, vmax=360)\n",
        "\n",
        "def animate(i):\n",
        "    mesh.set_array(frame[i, :-1, :-1].ravel()) #https://stackoverflow.com/questions/29009743/using-set-array-with-pyplot-pcolormesh-ruins-figure\n",
        "    title.set_text('L = {0:2f}'.format(lum[i]))\n",
        "    return mesh\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "from matplotlib.animation import FuncAnimation\n",
        "anim = FuncAnimation(fig, animate, interval=400, frames=frame.shape[0], repeat=False)\n",
        "from IPython.display import HTML\n",
        "HTML(anim.to_html5_video())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "BumjOKV2-drY",
        "outputId": "0a15a08b-ca47-4fb5-b647-772dc6027600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f975345e6b12>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmesh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpcolormesh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'magma'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m240\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m360\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0manimate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = gym.make(\"LunarLander-v2\")\n",
        "env.reset()\n",
        "prev_screen = env.render(mode='rgb_array')\n",
        "plt.imshow(prev_screen)\n",
        "\n",
        "from IPython import display\n",
        "# https://stackoverflow.com/questions/50107530/how-to-render-openai-gym-in-google-colab\n",
        "for i in range(50):\n",
        "  action = env.action_space.sample()\n",
        "  obs, reward, done, info = env.step(action)\n",
        "  screen = env.render(mode='rgb_array')\n",
        "  plt.imshow(screen)\n",
        "#   ipythondisplay.clear_output(wait=True)\n",
        "#   ipythondisplay.display(plt.gcf())\n",
        "  display.display(plt.gcf())\n",
        "  display.clear_output(wait=True)\n",
        "  if done:\n",
        "    break\n",
        "\n",
        "# ipythondisplay.clear_output(wait=True)\n",
        "env.close()"
      ],
      "metadata": {
        "id": "Lc3KbMRyPqTI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### moniter dumnp"
      ],
      "metadata": {
        "id": "6iqI0Rqn__dP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://colab.research.google.com/drive/12osEZByXOlGy8J-MSpkl3faObhzPGIrB\n",
        "from pathlib import Path\n",
        "from IPython import display as ipythondisplay\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'\n",
        "\n",
        "from stable_baselines.common.vec_env import VecVideoRecorder, SubprocVecEnv, DummyVecEnv\n",
        "# Record video\n",
        "def record_video(env, model, video_length=500, prefix='', video_folder='videos/'):\n",
        "    \"\"\" :param env_id: (str), model: (RL model), video_length: (int), prefix: (str), video_folder: (str) \"\"\"\n",
        "    # eval_env = DummyVecEnv([lambda: gym.make('BipedalWalker-v2')])\n",
        "    eval_env = VecVideoRecorder(env, video_folder=video_folder,\n",
        "        record_video_trigger=lambda step: step == 0, video_length=video_length, name_prefix=prefix)\n",
        "    obs = eval_env.reset()\n",
        "    for _ in range(video_length):\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, _, _, _ = eval_env.step(action)\n",
        "    eval_env.close()\n",
        "\n",
        "# Display video\n",
        "def show_videos(video_path='', prefix=''):\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append('''<video alt=\"{}\" autoplay \n",
        "                        loop controls style=\"height: 400px;\">\n",
        "                        <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                    </video>'''.format(mp4, video_b64.decode('ascii')))\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "VSG6-fFSv1kJ",
        "outputId": "1fc00ecc-0e29-4cb4-9927-0d7dbb6158ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-65d9148f2be6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'DISPLAY'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m':1'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mstable_baselines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvec_env\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVecVideoRecorder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSubprocVecEnv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDummyVecEnv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# Record video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrecord_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_folder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'videos/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "record_video(env, model, video_length=1500, prefix='ppo2-walker-50000')\n",
        "show_videos('videos', prefix='ppo2-walker-50000')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "0uiSNKDXlWsB",
        "outputId": "8e32a17a-37ce-403e-a456-43e016b7f954"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-2d0f8e206e4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mrecord_video\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvideo_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ppo2-walker-50000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mshow_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'videos'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'ppo2-walker-50000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-561e15f033c9>\u001b[0m in \u001b[0;36mrecord_video\u001b[0;34m(env, model, video_length, prefix, video_folder)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;34m\"\"\" :param env_id: (str), model: (RL model), video_length: (int), prefix: (str), video_folder: (str) \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# eval_env = DummyVecEnv([lambda: gym.make('BipedalWalker-v2')])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     eval_env = VecVideoRecorder(env, video_folder=video_folder,\n\u001b[0m\u001b[1;32m     14\u001b[0m         record_video_trigger=lambda step: step == 0, video_length=video_length, name_prefix=prefix)\n\u001b[1;32m     15\u001b[0m     \u001b[0mobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_env\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'VecVideoRecorder' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t#scrollTo=8nj5sjsk15IT\n",
        "from gym.wrappers import Monitor\n",
        "\n",
        "from pyvirtualdisplay import Display\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "def show_video():\n",
        "    mp4list = glob.glob('video/*.mp4')\n",
        "    if len(mp4list) > 0:\n",
        "        mp4 = mp4list[0]\n",
        "        video = io.open(mp4, 'r+b').read()\n",
        "        encoded = base64.b64encode(video)\n",
        "        ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay loop controls style=\"height: 400px;\">\n",
        "          <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" /></video>'''.format(encoded.decode('ascii'))))\n",
        "    else: \n",
        "        print(\"Could not find video\")\n",
        "\n",
        "def wrap_env(env):\n",
        "    env = Monitor(env, './video', force=True)\n",
        "    return env\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "bOe4QI4K4yXq",
        "outputId": "769c31a8-d9d0-4db9-b37c-b19ed9f5aa45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-d5353d3f7d6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# https://colab.research.google.com/drive/1flu31ulJlgiRL1dnN2ir8wGh9p7Zij2t#scrollTo=8nj5sjsk15IT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrappers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpyvirtualdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDisplay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Monitor' from 'gym.wrappers' (/usr/local/lib/python3.7/dist-packages/gym/wrappers/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# env = wrap_env(gym.make(\"MsPacman-v0\"))\n",
        "env = wrap_env(env)\n",
        "observation = env.reset()\n",
        "\n",
        "while True:\n",
        "    env.render()\n",
        "    #your agent goes here\n",
        "    action = env.action_space.sample()\n",
        "    observation, reward, done, info = env.step(action)\n",
        "    if done: \n",
        "      break;\n",
        "env.close()\n",
        "show_video()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "rBr_4npG5FBw",
        "outputId": "7d7b8a4b-db5e-4c34-9d58-64d42d39986c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:565: UserWarning: \u001b[33mWARN: The environment MsPacman-v0 is out of date. You should consider upgrading to version `v4`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n",
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:98: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5bea9f0c0cb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgym\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MsPacman-v0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mobservation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-32-2ff036659529>\u001b[0m in \u001b[0;36mwrap_env\u001b[0;34m(env)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mwrap_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMonitor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'./video'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Monitor' is not defined"
          ]
        }
      ]
    }
  ]
}
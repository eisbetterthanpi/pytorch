{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vae.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPVliozikekH6IJ0J0PnFP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/python/blob/master/vae.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWm1I6g6-3OQ",
        "outputId": "80109b03-b330-4b88-fab7-73173f3d951c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch[1/3], Step [1000/15000], Reconst Loss: 479.6361, KL Div: 55.0972\n",
            "Epoch[1/3], Step [2000/15000], Reconst Loss: 443.0803, KL Div: 87.1898\n",
            "Epoch[1/3], Step [3000/15000], Reconst Loss: 428.8863, KL Div: 98.8944\n",
            "Epoch[1/3], Step [4000/15000], Reconst Loss: 281.2403, KL Div: 88.6129\n",
            "Epoch[1/3], Step [5000/15000], Reconst Loss: 401.2626, KL Div: 94.2985\n",
            "Epoch[1/3], Step [6000/15000], Reconst Loss: 342.0679, KL Div: 77.6048\n",
            "Epoch[1/3], Step [7000/15000], Reconst Loss: 445.0544, KL Div: 91.4413\n",
            "Epoch[1/3], Step [8000/15000], Reconst Loss: 518.7750, KL Div: 98.8455\n",
            "Epoch[1/3], Step [9000/15000], Reconst Loss: 495.2442, KL Div: 102.8892\n",
            "Epoch[1/3], Step [10000/15000], Reconst Loss: 449.6017, KL Div: 126.2344\n",
            "Epoch[1/3], Step [11000/15000], Reconst Loss: 380.2337, KL Div: 105.6097\n",
            "Epoch[1/3], Step [12000/15000], Reconst Loss: 411.7856, KL Div: 110.5115\n",
            "Epoch[1/3], Step [13000/15000], Reconst Loss: 321.1584, KL Div: 93.7259\n",
            "Epoch[1/3], Step [14000/15000], Reconst Loss: 401.1944, KL Div: 86.8681\n",
            "Epoch[1/3], Step [15000/15000], Reconst Loss: 326.0205, KL Div: 94.6029\n",
            "Epoch[2/3], Step [1000/15000], Reconst Loss: 346.4345, KL Div: 91.5041\n",
            "Epoch[2/3], Step [2000/15000], Reconst Loss: 385.4913, KL Div: 100.0894\n",
            "Epoch[2/3], Step [3000/15000], Reconst Loss: 254.0456, KL Div: 88.3025\n",
            "Epoch[2/3], Step [4000/15000], Reconst Loss: 360.9292, KL Div: 97.0430\n",
            "Epoch[2/3], Step [5000/15000], Reconst Loss: 404.5828, KL Div: 92.0100\n",
            "Epoch[2/3], Step [6000/15000], Reconst Loss: 472.0749, KL Div: 109.8026\n",
            "Epoch[2/3], Step [7000/15000], Reconst Loss: 400.8920, KL Div: 98.4674\n",
            "Epoch[2/3], Step [8000/15000], Reconst Loss: 413.9110, KL Div: 110.5161\n",
            "Epoch[2/3], Step [9000/15000], Reconst Loss: 361.3886, KL Div: 93.6933\n",
            "Epoch[2/3], Step [10000/15000], Reconst Loss: 310.4369, KL Div: 88.7983\n",
            "Epoch[2/3], Step [11000/15000], Reconst Loss: 278.6064, KL Div: 91.1091\n",
            "Epoch[2/3], Step [12000/15000], Reconst Loss: 447.5559, KL Div: 100.6752\n",
            "Epoch[2/3], Step [13000/15000], Reconst Loss: 375.8902, KL Div: 106.5165\n",
            "Epoch[2/3], Step [14000/15000], Reconst Loss: 294.5237, KL Div: 110.1355\n",
            "Epoch[2/3], Step [15000/15000], Reconst Loss: 475.9363, KL Div: 94.3148\n",
            "Epoch[3/3], Step [1000/15000], Reconst Loss: 301.4856, KL Div: 92.5307\n",
            "Epoch[3/3], Step [2000/15000], Reconst Loss: 386.6831, KL Div: 104.4722\n",
            "Epoch[3/3], Step [3000/15000], Reconst Loss: 334.2646, KL Div: 82.2295\n",
            "Epoch[3/3], Step [4000/15000], Reconst Loss: 418.9167, KL Div: 100.7012\n",
            "Epoch[3/3], Step [5000/15000], Reconst Loss: 336.6317, KL Div: 101.4610\n",
            "Epoch[3/3], Step [6000/15000], Reconst Loss: 246.4887, KL Div: 82.2754\n",
            "Epoch[3/3], Step [7000/15000], Reconst Loss: 323.5011, KL Div: 100.1219\n",
            "Epoch[3/3], Step [8000/15000], Reconst Loss: 351.6002, KL Div: 115.0962\n",
            "Epoch[3/3], Step [9000/15000], Reconst Loss: 460.2222, KL Div: 106.9318\n",
            "Epoch[3/3], Step [10000/15000], Reconst Loss: 356.7088, KL Div: 106.1645\n",
            "Epoch[3/3], Step [11000/15000], Reconst Loss: 317.7154, KL Div: 98.3678\n",
            "Epoch[3/3], Step [12000/15000], Reconst Loss: 280.4006, KL Div: 96.3429\n",
            "Epoch[3/3], Step [13000/15000], Reconst Loss: 355.5574, KL Div: 88.5382\n",
            "Epoch[3/3], Step [14000/15000], Reconst Loss: 357.4173, KL Div: 114.3381\n",
            "Epoch[3/3], Step [15000/15000], Reconst Loss: 399.4436, KL Div: 102.1795\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import save_image\n",
        "# https://github.com/yunjey/pytorch-tutorial/blob/master/tutorials/03-advanced/variational_autoencoder/main.py\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "sample_dir = 'samples'\n",
        "if not os.path.exists(sample_dir): os.makedirs(sample_dir)\n",
        "\n",
        "train_data = torchvision.datasets.MNIST(root=\"data\", train=True, download=True,transform=transforms.ToTensor(),)\n",
        "batch_size = 4 # 128\n",
        "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "image_size = 784\n",
        "h_dim = 400\n",
        "z_dim = 20\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_size=784, h_dim=400, z_dim=20):\n",
        "        super(VAE, self).__init__()\n",
        "        self.fc1 = nn.Linear(image_size, h_dim)\n",
        "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc3 = nn.Linear(h_dim, z_dim)\n",
        "        self.fc4 = nn.Linear(z_dim, h_dim)\n",
        "        self.fc5 = nn.Linear(h_dim, image_size)\n",
        "        \n",
        "    def encode(self, x):\n",
        "        h = F.relu(self.fc1(x))\n",
        "        return self.fc2(h), self.fc3(h)\n",
        "    \n",
        "    def reparameterize(self, mu, log_var):\n",
        "        std = torch.exp(log_var/2)\n",
        "        eps = torch.randn_like(std)\n",
        "        return mu + eps * std\n",
        "\n",
        "    def decode(self, z):\n",
        "        h = F.relu(self.fc4(z))\n",
        "        # return F.sigmoid(self.fc5(h))\n",
        "        return torch.sigmoid(self.fc5(h))\n",
        "    \n",
        "    def forward(self, x):\n",
        "        mu, log_var = self.encode(x)\n",
        "        z = self.reparameterize(mu, log_var)\n",
        "        x_reconst = self.decode(z)\n",
        "        return x_reconst, mu, log_var\n",
        "\n",
        "model = VAE().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "num_epochs = 3 #15\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (x, _) in enumerate(train_loader):\n",
        "        x = x.to(device).view(-1, image_size)\n",
        "        x_reconst, mu, log_var = model(x)\n",
        "        # reconst_loss = F.binary_cross_entropy(x_reconst, x, size_average=False)\n",
        "        reconst_loss = F.binary_cross_entropy(x_reconst, x, reduction='sum')\n",
        "        kl_div = - 0.5 * torch.sum(1 + log_var - mu.pow(2) - log_var.exp()) # Appendix B in VAE paper or http://yunjey47.tistory.com/43\n",
        "        \n",
        "        loss = reconst_loss + kl_div\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if (i+1) % 1000 == 0:\n",
        "            print (\"Epoch[{}/{}], Step [{}/{}], Reconst Loss: {:.4f}, KL Div: {:.4f}\".format(epoch+1, num_epochs, i+1, len(train_loader), reconst_loss.item(), kl_div.item()))\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(batch_size, z_dim).to(device)\n",
        "        out = model.decode(z).view(-1, 1, 28, 28)\n",
        "        save_image(out, os.path.join(sample_dir, 'sampled-{}.png'.format(epoch+1)))\n",
        "\n",
        "        out, _, _ = model(x)\n",
        "        x_concat = torch.cat([x.view(-1, 1, 28, 28), out.view(-1, 1, 28, 28)], dim=3)\n",
        "        save_image(x_concat, os.path.join(sample_dir, 'reconst-{}.png'.format(epoch+1)))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "model.eval()\n",
        "\n",
        "import random\n",
        "n=random.randint(0,1000)\n",
        "print(n)\n",
        "x, y = train_data[n][0], train_data[n][1]\n",
        "x_real=np.squeeze(x)\n",
        "\n",
        "x = x.to(device).view(-1, image_size)\n",
        "x_reconst, mu, log_var = model(x)\n",
        "x_reconst=x_reconst.detach().numpy()\n",
        "x_reconst=np.reshape(x_reconst,(28,28))\n",
        "\n",
        "figure, axis = plt.subplots(1, 2)\n",
        "axis[0].imshow(x_real, cmap = 'gray')\n",
        "axis[1].imshow(x_reconst, cmap = 'gray')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "-pb6_7sUM2_M",
        "outputId": "c07b6b7a-de4c-4b37-d658-ff43b7d257ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "347\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}

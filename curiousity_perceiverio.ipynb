{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eisbetterthanpi/pytorch/blob/main/curiousity_perceiverio.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qQjuJIepAvA"
      },
      "source": [
        "#### setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "C1GD7lk8H13h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d650850f-3001-466f-91e6-b74cb340f549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Collecting gym\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "\u001b[K     |████████████████████████████████| 696 kB 5.0 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.21.6)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym) (4.11.4)\n",
            "Collecting gym-notices>=0.0.4\n",
            "  Downloading gym_notices-0.0.7-py3-none-any.whl (2.7 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym) (4.1.1)\n",
            "Building wheels for collected packages: gym\n",
            "  Building wheel for gym (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.24.1-py3-none-any.whl size=793150 sha256=36e5266fc3e9e1ac2f0a242aab95e8a3145bfc776ccd4424a750f9fb45f9ead3\n",
            "  Stored in directory: /root/.cache/pip/wheels/18/0e/54/63d9f3d16ddf0fec1622e90d28140df5e6016bcf8ea920037d\n",
            "Successfully built gym\n",
            "Installing collected packages: gym-notices, gym\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.17.3\n",
            "    Uninstalling gym-0.17.3:\n",
            "      Successfully uninstalled gym-0.17.3\n",
            "Successfully installed gym-0.24.1 gym-notices-0.0.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gym[accept-rom-license,atari] in /usr/local/lib/python3.7/dist-packages (0.24.1)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.3.0)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (0.0.7)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (4.11.4)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.7/dist-packages (from gym[accept-rom-license,atari]) (1.21.6)\n",
            "Collecting ale-py~=0.7.5\n",
            "  Downloading ale_py-0.7.5-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.2 MB/s \n",
            "\u001b[?25hCollecting autorom[accept-rom-license]~=0.4.2\n",
            "  Downloading AutoROM-0.4.2-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from ale-py~=0.7.5->gym[accept-rom-license,atari]) (5.7.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (4.64.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (7.1.2)\n",
            "Collecting AutoROM.accept-rom-license\n",
            "  Downloading AutoROM.accept-rom-license-0.4.2.tar.gz (9.8 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym[accept-rom-license,atari]) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->autorom[accept-rom-license]~=0.4.2->gym[accept-rom-license,atari]) (2022.6.15)\n",
            "Building wheels for collected packages: AutoROM.accept-rom-license\n",
            "  Building wheel for AutoROM.accept-rom-license (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for AutoROM.accept-rom-license: filename=AutoROM.accept_rom_license-0.4.2-py3-none-any.whl size=441027 sha256=af5864133dedb87d1373cf5a0b2199bba5dd928c75a6506eef29bc5af381b25f\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/67/2e/6147e7912fe37f5408b80d07527dab807c1d25f5c403a9538a\n",
            "Successfully built AutoROM.accept-rom-license\n",
            "Installing collected packages: AutoROM.accept-rom-license, autorom, ale-py\n",
            "Successfully installed AutoROM.accept-rom-license-0.4.2 ale-py-0.7.5 autorom-0.4.2\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gym-super-mario-bros\n",
            "  Downloading gym_super_mario_bros-7.4.0-py3-none-any.whl (199 kB)\n",
            "\u001b[K     |████████████████████████████████| 199 kB 5.1 MB/s \n",
            "\u001b[?25hCollecting nes-py\n",
            "  Downloading nes_py-8.2.1.tar.gz (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 3.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gym>=0.17.2 in /usr/local/lib/python3.7/dist-packages (from nes-py) (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.7/dist-packages (from nes-py) (1.21.6)\n",
            "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from nes-py) (1.5.0)\n",
            "Requirement already satisfied: tqdm>=4.48.2 in /usr/local/lib/python3.7/dist-packages (from nes-py) (4.64.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.8.0 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py) (4.11.4)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.7/dist-packages (from gym>=0.17.2->nes-py) (0.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.8.0->gym>=0.17.2->nes-py) (4.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.21,>=1.4.0->nes-py) (0.16.0)\n",
            "Building wheels for collected packages: nes-py\n",
            "  Building wheel for nes-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nes-py: filename=nes_py-8.2.1-cp37-cp37m-linux_x86_64.whl size=439203 sha256=723b399130222ba27bde2df897ba4802b3e5d19088c620f1258e0ddcd2035ccc\n",
            "  Stored in directory: /root/.cache/pip/wheels/17/96/0e/22a8c7dbdf412d8e988286f223b223baf0f4ad90c9e699c56d\n",
            "Successfully built nes-py\n",
            "Installing collected packages: nes-py, gym-super-mario-bros\n",
            "Successfully installed gym-super-mario-bros-7.4.0 nes-py-8.2.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colabgymrender\n",
            "  Downloading colabgymrender-1.1.0.tar.gz (3.5 kB)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.7/dist-packages (from colabgymrender) (0.2.3.5)\n",
            "Requirement already satisfied: imageio<3.0,>=2.1.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (2.4.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from moviepy->colabgymrender) (1.21.6)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from imageio<3.0,>=2.1.2->moviepy->colabgymrender) (7.1.2)\n",
            "Building wheels for collected packages: colabgymrender\n",
            "  Building wheel for colabgymrender (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colabgymrender: filename=colabgymrender-1.1.0-py3-none-any.whl size=3132 sha256=6d1270139c63028f67c88d5d701ac19a5cf1da8e8cc1cd0a33fa1f89e9faae34\n",
            "  Stored in directory: /root/.cache/pip/wheels/f1/0a/2a/86955ea711b461ab7918236fed2568733f75ed677d0524b56c\n",
            "Successfully built colabgymrender\n",
            "Installing collected packages: colabgymrender\n",
            "Successfully installed colabgymrender-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting perceiver-pytorch\n",
            "  Downloading perceiver_pytorch-0.8.3-py3-none-any.whl (12 kB)\n",
            "Collecting einops>=0.3\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.7/dist-packages (from perceiver-pytorch) (1.11.0+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6->perceiver-pytorch) (4.1.1)\n",
            "Installing collected packages: einops, perceiver-pytorch\n",
            "Successfully installed einops-0.4.1 perceiver-pytorch-0.8.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.7/dist-packages (0.4.1)\n"
          ]
        }
      ],
      "source": [
        "# # https://github.com/kimhc6028/pytorch-noreward-rl\n",
        "# https://stackoverflow.com/questions/67808779/running-gym-atari-in-google-colab\n",
        "%pip install -U gym\n",
        "%pip install -U gym[atari,accept-rom-license]\n",
        "# !pip install gym[box2d]\n",
        "import gym\n",
        "\n",
        "!pip install gym-super-mario-bros nes-py\n",
        "# https://github.com/Kautenja/gym-super-mario-bros\n",
        "from nes_py.wrappers import JoypadSpace\n",
        "import gym_super_mario_bros\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
        "# env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "# env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
        "\n",
        "!pip install colabgymrender\n",
        "!pip install perceiver-pytorch\n",
        "\n",
        "import torch\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "log=False\n",
        "# !pip install wandb\n",
        "# import wandb\n",
        "# wandb.login() # \n",
        "# wandb.init(project=\"curiousity_simple\", entity=\"bobdole\")\n",
        "# log=True\n",
        "\n",
        "!pip install einops\n",
        "from math import pi, log\n",
        "from functools import wraps\n",
        "import torch\n",
        "from torch import nn, einsum\n",
        "import torch.nn.functional as F\n",
        "from einops import rearrange, repeat\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# functions"
      ],
      "metadata": {
        "id": "uYNDFUK_cp1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### gym wrappers"
      ],
      "metadata": {
        "id": "Q6rIxoaDeT4W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import gym\n",
        "class SparseEnv(gym.Wrapper): #https://alexandervandekleut.github.io/gym-wrappers/\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.env = env\n",
        "        self.total_rewards = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        self.total_rewards += reward\n",
        "        if done: return observation, self.total_rewards, done, info\n",
        "        else:\n",
        "            self.total_rewards = 0\n",
        "            return observation, 0, done, info\n",
        "    def reset(self):\n",
        "        self.total_rewards = 0\n",
        "        return self.env.reset()\n",
        "# env = SparseEnv(gym.make(\"LunarLander-v2\"))\n",
        "\n",
        "class MarioSparse(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.env = env\n",
        "        self.total_score = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        life = info['life']\n",
        "        score = info['score']\n",
        "        self.total_score += score\n",
        "        # print(\"MarioSparse\",life,score)\n",
        "        # if done: return observation, self.total_rewards, done, info\n",
        "        if life<2:\n",
        "            print(\"MarioSparse: died\")\n",
        "            return observation, score, True, info # lost one life, end env\n",
        "        else:\n",
        "            # self.total_score = 0\n",
        "            return observation, score, False, info\n",
        "    def reset(self):\n",
        "        # self.total_score = 0\n",
        "        return self.env.reset()\n",
        "# env = MarioSparse(env)\n",
        "\n",
        "class MarioEarlyStop(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.env = env\n",
        "        self.max_pos = 0\n",
        "        self.count_step = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        x_pos = info['x_pos']\n",
        "        if x_pos <= self.max_pos: self.count_step += 1\n",
        "        else:\n",
        "            self.max_pos = x_pos\n",
        "            self.count_step = 0\n",
        "        if self.count_step > 30:\n",
        "            print(\"MarioEarlyStop: early stop \", self.max_pos)\n",
        "            return observation, reward, True, info # early stop\n",
        "        else:\n",
        "            return observation, reward, False, info\n",
        "    def reset(self):\n",
        "        self.max_pos = 0\n",
        "        self.count_step = 0\n",
        "        return self.env.reset()\n",
        "# env = MarioEarlyStop(env)\n"
      ],
      "metadata": {
        "id": "rcxxhxGVFlUf"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# https://colab.research.google.com/github/araffin/rl-tutorial-jnrr19/blob/master/2_gym_wrappers_saving_loading.ipynb\n",
        "import gym\n",
        "class SparseEnv(gym.Wrapper): #https://alexandervandekleut.github.io/gym-wrappers/\n",
        "    def __init__(self, env):\n",
        "        super().__init__(env)\n",
        "        self.env = env\n",
        "        self.total_rewards = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        self.total_rewards += reward\n",
        "        if done:\n",
        "            reward = self.total_rewards\n",
        "            # return observation, self.total_rewards, done, info\n",
        "        else:\n",
        "            reward = 0\n",
        "            # self.total_rewards = 0\n",
        "            # return observation, 0, done, info\n",
        "        return observation, reward, done, info\n",
        "    def reset(self):\n",
        "        self.total_rewards = 0\n",
        "        return self.env.reset()\n",
        "# env = SparseEnv(gym.make(\"LunarLander-v2\"))\n",
        "\n",
        "class MarioSparse(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        # super().__init__(env)\n",
        "        super(MarioSparse, self).__init__(env)\n",
        "        self.env = env\n",
        "        self.total_score = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        life = info['life']\n",
        "        score = info['score']\n",
        "        self.total_score += score\n",
        "        if life<2:\n",
        "            print(\"MarioSparse: died\")\n",
        "            # return observation, score, True, info # lost one life, end env\n",
        "            done = True\n",
        "        # else:\n",
        "            # self.total_score = 0\n",
        "        return observation, score, done, info\n",
        "    def reset(self):\n",
        "        self.total_score = 0\n",
        "        return self.env.reset()\n",
        "# env = MarioSparse(env)\n",
        "\n",
        "class MarioEarlyStop(gym.Wrapper):\n",
        "    def __init__(self, env):\n",
        "        # super().__init__(env)\n",
        "        super(MarioEarlyStop, self).__init__(env)\n",
        "        self.env = env\n",
        "        self.max_pos = 0\n",
        "        self.count_step = 0\n",
        "    def step(self, action):\n",
        "        observation, reward, done, info = self.env.step(action)\n",
        "        x_pos = info['x_pos']\n",
        "        if x_pos <= self.max_pos: self.count_step += 1\n",
        "        else:\n",
        "            self.max_pos = x_pos\n",
        "            self.count_step = 0\n",
        "        if self.count_step > 500:\n",
        "            print(\"MarioEarlyStop: early stop \", self.max_pos)\n",
        "            # return observation, reward, True, info # early stop\n",
        "            done = True\n",
        "        # else:\n",
        "        return observation, reward, done, info\n",
        "    def reset(self):\n",
        "        self.max_pos = 0\n",
        "        self.count_step = 0\n",
        "        return self.env.reset()\n",
        "# env = MarioEarlyStop(env)\n"
      ],
      "metadata": {
        "id": "L4wnbtD_eRxa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### helpers"
      ],
      "metadata": {
        "id": "ncK_m9R1Pxsb"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "OvAaHBGgK2qY"
      },
      "outputs": [],
      "source": [
        "# helpers\n",
        "def exists(val):\n",
        "    return val is not None\n",
        "\n",
        "def default(val, d):\n",
        "    return val if exists(val) else d\n",
        "\n",
        "def cache_fn(f):\n",
        "    cache = None\n",
        "    # @wraps(f)\n",
        "    def cached_fn(*args, _cache = True, **kwargs):\n",
        "        if not _cache:\n",
        "            return f(*args, **kwargs)\n",
        "        nonlocal cache\n",
        "        if cache is not None:\n",
        "            return cache\n",
        "        cache = f(*args, **kwargs)\n",
        "        return cache\n",
        "    return cached_fn\n",
        "\n",
        "# helper classes\n",
        "class PreNorm(nn.Module):\n",
        "    def __init__(self, dim, fn, context_dim = None):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        self.norm = nn.LayerNorm(dim)\n",
        "        self.norm_context = nn.LayerNorm(context_dim) if exists(context_dim) else None\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        x = self.norm(x)\n",
        "        if exists(self.norm_context):\n",
        "            context = kwargs['context']\n",
        "            normed_context = self.norm_context(context)\n",
        "            kwargs.update(context = normed_context)\n",
        "        return self.fn(x, **kwargs)\n",
        "\n",
        "class GEGLU(nn.Module):\n",
        "    def forward(self, x):\n",
        "        x, gates = x.chunk(2, dim = -1)\n",
        "        return x * F.gelu(gates)\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim, mult = 4):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(dim, dim * mult * 2),\n",
        "            GEGLU(),\n",
        "            nn.Linear(dim * mult, dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class Attention(nn.Module):\n",
        "    def __init__(self, query_dim, context_dim = None, heads = 8, dim_head = 64):\n",
        "        super().__init__()\n",
        "        inner_dim = dim_head * heads\n",
        "        context_dim = default(context_dim, query_dim)\n",
        "        self.scale = dim_head ** -0.5\n",
        "        self.heads = heads\n",
        "        self.to_q = nn.Linear(query_dim, inner_dim, bias = False)\n",
        "        self.to_kv = nn.Linear(context_dim, inner_dim * 2, bias = False)\n",
        "        self.to_out = nn.Linear(inner_dim, query_dim)\n",
        "\n",
        "    def forward(self, x, context = None, mask = None):\n",
        "        h = self.heads\n",
        "        q = self.to_q(x)\n",
        "        context = default(context, x)\n",
        "        k, v = self.to_kv(context).chunk(2, dim = -1)\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n (h d) -> (b h) n d', h = h), (q, k, v))\n",
        "        sim = einsum('b i d, b j d -> b i j', q, k) * self.scale\n",
        "        if exists(mask):\n",
        "            mask = rearrange(mask, 'b ... -> b (...)')\n",
        "            max_neg_value = -torch.finfo(sim.dtype).max\n",
        "            mask = repeat(mask, 'b j -> (b h) () j', h = h)\n",
        "            sim.masked_fill_(~mask, max_neg_value)\n",
        "        attn = sim.softmax(dim = -1)\n",
        "        out = einsum('b i j, b j d -> b i d', attn, v)\n",
        "        out = rearrange(out, '(b h) n d -> b n (h d)', h = h)\n",
        "        return self.to_out(out)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PerceiverIO"
      ],
      "metadata": {
        "id": "DsVq7W_oPzzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PerceiverIO class save\n",
        "class PerceiverIO(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        depth,\n",
        "        dim,\n",
        "        queries_dim,\n",
        "        logits_dim = None,\n",
        "        num_latents = 512,\n",
        "        latent_dim = 512,\n",
        "        cross_heads = 1,\n",
        "        latent_heads = 8,\n",
        "        cross_dim_head = 64,\n",
        "        latent_dim_head = 64,\n",
        "        weight_tie_layers = False,\n",
        "        decoder_ff = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.latents = nn.Parameter(torch.randn(num_latents, latent_dim))\n",
        "        self.cross_attend_blocks = nn.ModuleList([\n",
        "            PreNorm(latent_dim, Attention(latent_dim, dim, heads = cross_heads, dim_head = cross_dim_head), context_dim = dim),\n",
        "            PreNorm(latent_dim, FeedForward(latent_dim))\n",
        "        ])\n",
        "        get_latent_attn = lambda: PreNorm(latent_dim, Attention(latent_dim, heads = latent_heads, dim_head = latent_dim_head))\n",
        "        get_latent_ff = lambda: PreNorm(latent_dim, FeedForward(latent_dim))\n",
        "        get_latent_attn, get_latent_ff = map(cache_fn, (get_latent_attn, get_latent_ff))\n",
        "        self.layers = nn.ModuleList([])\n",
        "        cache_args = {'_cache': weight_tie_layers}\n",
        "        for i in range(depth):\n",
        "            self.layers.append(nn.ModuleList([get_latent_attn(**cache_args), get_latent_ff(**cache_args)]))\n",
        "        self.decoder_cross_attn = PreNorm(queries_dim, Attention(queries_dim, latent_dim, heads = cross_heads, dim_head = cross_dim_head), context_dim = latent_dim)\n",
        "        self.decoder_ff = PreNorm(queries_dim, FeedForward(queries_dim)) if decoder_ff else None\n",
        "        self.to_logits = nn.Linear(queries_dim, logits_dim) if exists(logits_dim) else nn.Identity()\n",
        "\n",
        "    def forward(self, data, mask = None, queries = None):\n",
        "        b, *_, device = *data.shape, data.device\n",
        "        x = repeat(self.latents, 'n d -> b n d', b = b)\n",
        "        cross_attn, cross_ff = self.cross_attend_blocks\n",
        "        # cross attention only happens once for Perceiver IO\n",
        "        x = cross_attn(x, context = data, mask = mask) + x\n",
        "        x = cross_ff(x) + x\n",
        "        # layers\n",
        "        for self_attn, self_ff in self.layers:\n",
        "            x = self_attn(x) + x\n",
        "            x = self_ff(x) + x\n",
        "        if not exists(queries):\n",
        "            return x\n",
        "        # make sure queries contains batch dimension\n",
        "        if queries.ndim == 2:\n",
        "            queries = repeat(queries, 'n d -> b n d', b = b)\n",
        "        # cross attend from decoder queries to latents\n",
        "        latents = self.decoder_cross_attn(queries, context = x)\n",
        "        if exists(self.decoder_ff):\n",
        "            latents = latents + self.decoder_ff(latents)\n",
        "        return self.to_logits(latents)\n",
        "\n",
        "def preprocess(X):\n",
        "    if X.dim()==1:\n",
        "        X=X.unsqueeze(dim=0)\n",
        "    X=X.flatten(start_dim=1, end_dim=-1) #(start_dim=1)\n",
        "    X=X.unsqueeze(dim=1)\n",
        "    return X\n",
        "\n",
        "def postprocess(logits):\n",
        "    if logits.dim()==3:\n",
        "        logits=logits.squeeze(dim=1)\n",
        "    return logits\n"
      ],
      "metadata": {
        "id": "6_r7WRKMLcc2"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### PerceiverIOrnn"
      ],
      "metadata": {
        "id": "hqxWCz07-Yv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PerceiverIOrnn(nn.Module):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *,\n",
        "        depth,\n",
        "        dim,\n",
        "        queries_dim,\n",
        "        logits_dim = None,\n",
        "        num_latents = 512,\n",
        "        latent_dim = 512,\n",
        "        cross_heads = 1,\n",
        "        latent_heads = 8,\n",
        "        cross_dim_head = 64,\n",
        "        latent_dim_head = 64,\n",
        "        weight_tie_layers = False,\n",
        "        decoder_ff = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        # self.latents = nn.Parameter(torch.randn(num_latents, latent_dim))\n",
        "        self.latents = torch.zeros(num_latents, latent_dim)\n",
        "        self.cross_attend_blocks = nn.ModuleList([\n",
        "            PreNorm(latent_dim, Attention(latent_dim, dim, heads = cross_heads, dim_head = cross_dim_head), context_dim = dim),\n",
        "            PreNorm(latent_dim, FeedForward(latent_dim))\n",
        "        ])\n",
        "        get_latent_attn = lambda: PreNorm(latent_dim, Attention(latent_dim, heads = latent_heads, dim_head = latent_dim_head))\n",
        "        get_latent_ff = lambda: PreNorm(latent_dim, FeedForward(latent_dim))\n",
        "        get_latent_attn, get_latent_ff = map(cache_fn, (get_latent_attn, get_latent_ff))\n",
        "        self.layers = nn.ModuleList([])\n",
        "        cache_args = {'_cache': weight_tie_layers}\n",
        "        for i in range(depth):\n",
        "            self.layers.append(nn.ModuleList([get_latent_attn(**cache_args), get_latent_ff(**cache_args)]))\n",
        "        self.decoder_cross_attn = PreNorm(queries_dim, Attention(queries_dim, latent_dim, heads = cross_heads, dim_head = cross_dim_head), context_dim = latent_dim)\n",
        "        self.decoder_ff = PreNorm(queries_dim, FeedForward(queries_dim)) if decoder_ff else None\n",
        "        self.to_logits = nn.Linear(queries_dim, logits_dim) if exists(logits_dim) else nn.Identity()\n",
        "\n",
        "    def forward(self, data, mask = None, queries = None, x = None):\n",
        "        b, *_, device = *data.shape, data.device\n",
        "        if x == None: x = repeat(self.latents, 'n d -> b n d', b = b).to(device)\n",
        "        cross_attn, cross_ff = self.cross_attend_blocks\n",
        "        # cross attention only happens once for Perceiver IO\n",
        "        x = cross_attn(x, context = data, mask = mask) + x\n",
        "        x = cross_ff(x) + x\n",
        "        # layers\n",
        "        for self_attn, self_ff in self.layers:\n",
        "            x = self_attn(x) + x\n",
        "            x = self_ff(x) + x\n",
        "        if not exists(queries):\n",
        "            return x\n",
        "        # make sure queries contains batch dimension\n",
        "        if queries.ndim == 2:\n",
        "            queries = repeat(queries, 'n d -> b n d', b = b)\n",
        "        # cross attend from decoder queries to latents\n",
        "        latents = self.decoder_cross_attn(queries, context = x)\n",
        "        if exists(self.decoder_ff):\n",
        "            latents = latents + self.decoder_ff(latents)\n",
        "        # return self.to_logits(latents)\n",
        "        return x, self.to_logits(latents)\n"
      ],
      "metadata": {
        "id": "i8Lh8uAVLixh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### cnn"
      ],
      "metadata": {
        "id": "ZWHdTK3-efrc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Conv(nn.Module):\n",
        "    # def __init__(self):\n",
        "    def __init__(self, in_channels=1):\n",
        "        super(Conv, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            # nn.Conv2d(in_channels, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "            # nn.Conv2d(in_channels, 1, 5, stride=2, padding=3),\n",
        "            nn.Conv2d(in_channels, 1, 5, stride=1, padding=3),\n",
        "            nn.ReLU(),\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.MaxPool2d(3, stride=2, padding=0),\n",
        "            # nn.MaxPool2d(5, stride=2, padding=1),\n",
        "        )\n",
        "    def forward(self, x): # in [4, 3, 224, 224]\n",
        "        x = self.conv(x)\n",
        "        # x = x.view(-1, 16 * 5 * 5)\n",
        "        return x # out [4, 1, 56, 56]\n",
        "\n",
        "class Conv_Encoder(nn.Module):\n",
        "    # def __init__(self):\n",
        "    def __init__(self, in_channels=1):\n",
        "        super(Conv_Encoder, self).__init__()\n",
        "        self.conv_encoder = nn.Sequential( # embed pi (240, 256, 3) -> 256 when flattened\n",
        "            nn.Conv2d(in_channels, 8, 3, stride=2, padding=1), nn.ELU(),\n",
        "            # nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(8, 16, 5, stride=2, padding=2), nn.ELU(),\n",
        "            nn.AdaptiveAvgPool2d((64,64)),\n",
        "            nn.Conv2d(16, 8, 7, stride=2, padding=3), nn.ELU(),\n",
        "            nn.Conv2d(8, 1, 5, stride=2, padding=2), nn.ELU(),\n",
        "            # # nn.Conv2d(in_channels, out_channels=1, kernel_size=3, stride=2, padding=1),\n",
        "            # nn.ReLU(),\n",
        "            )\n",
        "    def forward(self, x): # in [4, 3, 224, 224]\n",
        "        x = self.conv_encoder(x)\n",
        "        # x = x.view(-1, 16 * 5 * 5)\n",
        "        return x # out [4, 1, 56, 56]\n"
      ],
      "metadata": {
        "id": "a7L9VGgY6NNY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### perceiverio + fourier"
      ],
      "metadata": {
        "id": "lErlrfaRpQmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from einops import rearrange, repeat\n",
        "import numpy as np\n",
        "num_freq_bands = 6 # num_bands = 4\n",
        "max_freq = 10\n",
        "# freq_base = 2,\n",
        "\n",
        "\n",
        "input_axis = 2 # 2 for images, 3 for video\n",
        "input_channels = 3\n",
        "# fourier_encode_data True\n",
        "fourier_channels = (input_axis * ((num_freq_bands * 2) + 1)) # 26\n",
        "input_dim = fourier_channels + input_channels # 29\n",
        "# print(\"input_dim\",input_dim)\n",
        "\n",
        "\n",
        "def fourier_encode(x, max_freq = 10, num_bands = 6):\n",
        "    x = x.unsqueeze(-1)\n",
        "    device, dtype, orig_x = x.device, x.dtype, x\n",
        "    scales = torch.linspace(1., max_freq / 2, num_bands, device = device, dtype = dtype)\n",
        "    scales = scales[(*((None,) * (len(x.shape) - 1)), Ellipsis)]\n",
        "    x = x * scales * np.pi\n",
        "    x = torch.cat([x.sin(), x.cos()], dim = -1)\n",
        "    x = torch.cat((x, orig_x), dim = -1)\n",
        "    return x\n",
        "\n",
        "def fourier(data): # https://github.com/lucidrains/perceiver-pytorch/blob/main/perceiver_pytorch/perceiver_pytorch.py\n",
        "    b, *axis, _, device, dtype = *data.shape, data.device, data.dtype\n",
        "    axis_pos = list(map(lambda size: torch.linspace(-1., 1., steps=size, device=device, dtype=dtype), axis))\n",
        "    pos = torch.stack(torch.meshgrid(*axis_pos, indexing = 'ij'), dim = -1) # [32, 32, 2]\n",
        "    # print(\"fourier pos\",pos.shape)\n",
        "    enc_pos = fourier_encode(pos, max_freq, num_freq_bands) # [32, 32, 2, 13]\n",
        "    # print(\"fourier fourier_encode\",enc_pos.shape)\n",
        "    enc_pos = rearrange(enc_pos, '... n d -> ... (n d)') # [32, 32, 26]\n",
        "    # print(\"fourier enc_pos rearrange\",enc_pos.shape)\n",
        "    enc_pos = repeat(enc_pos, '... -> b ...', b = b) # [4, 32, 32, 26]\n",
        "    # print(\"fourier enc_pos\",enc_pos.shape)\n",
        "    data = torch.cat((data, enc_pos), dim = -1) # [4, 32, 32, 29]\n",
        "    # print(\"fourier cat\",data.shape)\n",
        "    data = rearrange(data, 'b ... d -> b (...) d') # [4, 1024, 29]\n",
        "    # print(\"fourier rearrange\",data.shape)\n",
        "    return data\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tHwWgPmYH1JH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# # 224 -> CNN -> 32\n",
        "# # images = torch.randn(4, 3, 32, 32, device=device) # batch, rgb, dim_x, dim_y\n",
        "# # seq = np.transpose(images, (0, 2, 3, 1)) # [4, 32, 32, 3] batch, dim_x, dim_y, rgb\n",
        "\n",
        "# images = torch.randn(240, 256, 3, device=device) # dim_x, dim_y, rgb\n",
        "# seq = fourier(images) # [4, 1024, 29] [240, 256, 16]\n",
        "# print(seq.shape)\n",
        "# # batch,_,h,w= seq.shape\n",
        "# # batch,axis,input_dim=seq.shape # [240, 256, 16]\n",
        "# h,w,input_dim=seq.shape # [240, 256, 16]\n",
        "\n",
        "# model = PerceiverIO(\n",
        "#     dim = h*w*input_dim,         # 32*32 dimension of sequence to be encoded\n",
        "#     queries_dim = 10,            # dimension of decoder queries\n",
        "#     logits_dim = None,           # dimension of final logits\n",
        "#     depth = 6,                   # depth of net\n",
        "#     num_latents = 128,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "#     latent_dim = 128,            # latent dimension\n",
        "#     cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "#     latent_heads = 8,            # number of heads for latent self attention, 8\n",
        "#     cross_dim_head = 64,         # number of dimensions per cross attention head\n",
        "#     latent_dim_head = 64,        # number of dimensions per latent self attention head\n",
        "#     weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "# ).to(device)\n",
        "\n",
        "# seq = seq.flatten()\n",
        "# seq = preprocess(seq) # [4, 1, 29696]\n",
        "# # print(seq.shape)\n",
        "# queries = torch.randn(1, 10, device=device)\n",
        "# logits = model(seq, queries = queries)\n",
        "# pred = postprocess(logits)\n",
        "# # print(pred.shape)\n",
        "# # print(pred)\n",
        "# pred_probab = nn.Softmax(dim=1)(pred)\n",
        "# outputs = pred_probab\n",
        "\n",
        "# y_pred = pred_probab.argmax(1)\n",
        "# print(y_pred)\n"
      ],
      "metadata": {
        "id": "g9egXpRiwdkn"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# models"
      ],
      "metadata": {
        "id": "Sk-h3eIjSYVS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### model simplier"
      ],
      "metadata": {
        "id": "TDFTp2wVc-5E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGpJGeDM8HvU"
      },
      "outputs": [],
      "source": [
        "# model.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/model.py\n",
        "import math\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ActorCritic(torch.nn.Module):\n",
        "    def __init__(self, in_shape, action_space):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.in_dim = in_shape # mario (240, 256)\n",
        "        self.conv = nn.Sequential( # embed pi\n",
        "            nn.Conv2d(in_shape[0], 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(),\n",
        "            nn.Conv2d(32, 32, 3, stride=2, padding=1), nn.ELU(), # added for RuntimeError: Input batch size 2 doesn't match hidden0 batch size 1\n",
        "            )\n",
        "        self.lstm = nn.LSTMCell(in_shape[1], 256)\n",
        "        num_outputs = action_space.n\n",
        "        self.critic_linear = nn.Linear(256, 1) # -> value\n",
        "        self.actor_linear = nn.Linear(256, num_outputs) # -> action\n",
        "\n",
        "        self.inv_lstm = nn.LSTMCell(in_shape[1], 256)\n",
        "        self.fwd_lstm = nn.LSTMCell(in_shape[1], 256)\n",
        "        self.inv_linear = nn.Sequential( # inv learning, predict at\n",
        "            nn.Linear(in_shape[1] + in_shape[1], 256), nn.ReLU(),\n",
        "            nn.Linear(256, num_outputs), nn.Softmax()\n",
        "            ) # cat(phi(st), phi(st+1)) -> athat\n",
        "        self.fwd_linear = nn.Sequential( # predict phi st+1\n",
        "            nn.Linear(in_shape[1] + num_outputs, 256), nn.ReLU(),\n",
        "            nn.Linear(256, in_shape[1])\n",
        "            ) # cat(phi(st), at) -> phihat(st+1)\n",
        "\n",
        "    def forward(self, inputs, icm):\n",
        "        if icm == False: #A3C\n",
        "            st, (a3c_hx, a3c_cx) = inputs # [1, 210, 160, 3], ([1, 256], [1, 256])\n",
        "            vec_st = self.conv(st).view(-1, self.in_dim[1])\n",
        "            a3c_hx1, a3c_cx1 = self.lstm(vec_st, (a3c_hx, a3c_cx))\n",
        "            critic = self.critic_linear(a3c_hx1)\n",
        "            actor = self.actor_linear(a3c_hx1)\n",
        "            # print(\"forward A3C \",critic.shape, actor.shape, a3c_hx.shape, a3c_cx.shape)\n",
        "            return critic, actor, (a3c_hx1, a3c_cx1) # [1, 1], [1, 18], ([1, 256], [1, 256])\n",
        "\n",
        "        else: #icm\n",
        "            (inv_hx, inv_cx), (fwd_hx, fwd_cx), st1, at = inputs\n",
        "            vec_st1 = self.conv(st1).view(-1, self.in_dim[1])\n",
        "            inv_hx1, inv_cx1 = self.inv_lstm(vec_st1, (icm_hx, icm_cx)) # inv model\n",
        "            fwd_hx1, fwd_cx1 = self.fwd_lstm(vec_st1, (icm_hx, icm_cx)) # world model\n",
        "\n",
        "            inv_vec = torch.cat((icm_hx, vec_st1), 1) # predict at\n",
        "            fwd_vec = torch.cat((icm_hx, at), 1) # predict vec_st1\n",
        "            inverse = self.inv_linear(inv_vec)\n",
        "            forward = self.fwd_linear(fwd_vec)\n",
        "            # print(\"forward icm \",vec_st1.shape, inverse.shape, forward.shape)\n",
        "            return vec_st1, inverse, forward, (inv_hx1, inv_cx1), (fwd_hx1, fwd_cx1) # [1, 320], [1, 18], [1, 320], ()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### curiousity perceiverio"
      ],
      "metadata": {
        "id": "KxNSVT9rurZO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ActorCritic(torch.nn.Module):\n",
        "    def __init__(self, in_shape, action_space):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.in_dim = in_shape # mario (240, 256, 3)\n",
        "        self.conv = Conv(in_shape[2])#.to(device) # embed pi\n",
        "        # self.lstm = nn.LSTMCell(in_shape[1], 256)\n",
        "        # print(in_shape[0]*in_shape[1]/4)\n",
        "        self.encoder = PerceiverIO( # conv -> PerceiverIO ;encodes state for everyone\n",
        "            dim = int(in_shape[0]*in_shape[1]/4),# dimension of sequence to be encoded\n",
        "            queries_dim = 256,            # dimension of decoder queries\n",
        "            logits_dim = None,            # dimension of final logits\n",
        "            depth = 2,                   # depth of net\n",
        "            num_latents = 16,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 16,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 8,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 8,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        )#.to(device) # st(240*256) -zeros> phist(256)\n",
        "        self.encoder_query = torch.zeros(1, 256, device=device)\n",
        "        num_outputs = action_space.n\n",
        "        self.lstm = PerceiverIOrnn( # latent + phist1(256) -zeros> latent1 + vec_st(256)\n",
        "            dim = 256,                  # dimension of sequence to be encoded\n",
        "            queries_dim = 256,            # dimension of decoder queries\n",
        "            logits_dim = None,            # dimension of final logits\n",
        "            depth = 2,                   # depth of net\n",
        "            num_latents = 32,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 32,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 8,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 8,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        )#.to(device) # st-> phist ; 240*256 -zeros> 256\n",
        "        self.lstm_query = torch.zeros(1, 256, device=device)\n",
        "        self.actor_linear = nn.Linear(256, num_outputs) # vec_st -> action\n",
        "        self.critic_linear = nn.Linear(256, 1) # vec_st -> value\n",
        "\n",
        "        self.inv_lstm = PerceiverIOrnn( # inverse model, predict taken action\n",
        "            dim = 256,                   # dimension of sequence to be encoded\n",
        "            queries_dim = num_outputs,   # dimension of decoder queries\n",
        "            logits_dim = None,           # dimension of final logits\n",
        "            depth = 1,                   # depth of net\n",
        "            num_latents = 64,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 64,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 16,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 16,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        )#.to(device) # inv_latent + phi(st+1) -zeros> at +inv_latent1\n",
        "        self.inv_query = torch.zeros(1, num_outputs, device=device)\n",
        "        self.fwd_lstm = PerceiverIOrnn( # world model\n",
        "            dim = 256 + num_outputs,     # dimension of sequence to be encoded\n",
        "            queries_dim = 256,           # dimension of decoder queries\n",
        "            logits_dim = None,           # dimension of final logits\n",
        "            depth = 1,                   # depth of net\n",
        "            num_latents = 128,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 128,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 8,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 32,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 32,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        )#.to(device) # fwd_latent + phi(st) cat at -zeros> phi(st1) +fwd_latent1\n",
        "        self.fwd_query = torch.zeros(1, 256, device=device)\n",
        "\n",
        "    def encode(self, st):\n",
        "        st = torch.transpose(st, 1,2)\n",
        "        st = torch.transpose(st, 0,1) # [3, 240, 256] rgb, dim_x, dim_y\n",
        "        # vec_st = self.conv(st).view(-1, self.in_dim[1]) # [15, 256]\n",
        "        cst = self.conv(st).flatten() # [120*128]\n",
        "        cst = cst.view(1,1,-1) # [1, 1, 120*128]\n",
        "        phist = self.encoder(cst, queries = self.encoder_query) # \n",
        "        return phist # 256\n",
        "\n",
        "    def forward(self, inputs, icm):\n",
        "        if icm == False: #A3C\n",
        "            st, latent = inputs # [240, 256, 3]\n",
        "            phist = self.encode(st)\n",
        "            latent1, vec_st = self.lstm(phist, queries = self.lstm_query, x=latent) # \n",
        "            critic = self.critic_linear(vec_st)\n",
        "            actor = self.actor_linear(vec_st)\n",
        "            return critic[0], actor[0], latent1 # [1, 1], [1, 18], \n",
        "        else: #icm\n",
        "            inv_latent, fwd_latent, st1, at = inputs\n",
        "            phist = self.encode(st1)\n",
        "            inv_latent1, inverse = self.inv_lstm(phist, queries = self.inv_query, x=inv_latent) # inv model; inv_latent + phi(st+1) -> at +inv_latent1\n",
        "            fwd_latent1, forward = self.fwd_lstm(torch.cat((phist, at.unsqueeze(0)), -1), queries = self.fwd_query, x=fwd_latent) # world model; fwd_latent + at cat phi(st) -> phi(st1) +fwd_latent1\n",
        "            inverse = nn.Softmax()(inverse[0])\n",
        "            forward = nn.Softmax()(forward[0])\n",
        "            # print(\"forward icm \",phist.shape, inverse.shape, forward.shape)\n",
        "            # print(\"forward icm \",inverse, forward)\n",
        "            return phist[0], inverse, forward, inv_latent1, fwd_latent1 # [1, 320], [1, 18], [1, 320], ()\n"
      ],
      "metadata": {
        "id": "9xCONztqwRdX"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### alternate light"
      ],
      "metadata": {
        "id": "mLirlem_Se4R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class ActorCritic(torch.nn.Module):\n",
        "    def __init__(self, in_shape, action_space):\n",
        "        super(ActorCritic, self).__init__()\n",
        "        self.in_dim = in_shape # mario (240, 256, 3)\n",
        "        self.conv = Conv(in_shape[2])#.to(device) # embed pi\n",
        "        phist_size= 256\n",
        "        hidden_size= 512\n",
        "        # self.lstm = nn.LSTMCell(in_shape[1], 256)\n",
        "        # print(in_shape[0]*in_shape[1]/4)\n",
        "        self.encoder = PerceiverIO( # conv -> PerceiverIO ;encodes state for everyone\n",
        "            dim = int(in_shape[0]*in_shape[1]/4),# dimension of sequence to be encoded\n",
        "            queries_dim = 256,            # dimension of decoder queries\n",
        "            logits_dim = None,            # dimension of final logits\n",
        "            depth = 2,                   # depth of net\n",
        "            num_latents = 16,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 16,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 8,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 8,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        )#.to(device) # st(240*256) -zeros> phist(256)\n",
        "        # self.encoder_query = torch.zeros(1, 256, device=device)\n",
        "        \n",
        "        self.conv_encoder = Conv_Encoder(in_shape[2])#.to(device)\n",
        "        num_outputs = action_space.n\n",
        "        # self.lstm = PerceiverIOrnn( # latent + phist1(256) -zeros> latent1 + vec_st(256)\n",
        "        #     dim = 256,                  # dimension of sequence to be encoded\n",
        "        #     queries_dim = 256,            # dimension of decoder queries\n",
        "        #     logits_dim = None,            # dimension of final logits\n",
        "        #     depth = 2,                   # depth of net\n",
        "        #     num_latents = 32,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "        #     latent_dim = 32,            # latent dimension\n",
        "        #     cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "        #     latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "        #     cross_dim_head = 8,         # number of dimensions per cross attention head\n",
        "        #     latent_dim_head = 8,        # number of dimensions per latent self attention head\n",
        "        #     weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        # ).to(device) # st-> phist ; 240*256 -zeros> 256\n",
        "        # self.lstm_query = torch.zeros(1, 256, device=device)\n",
        "        self.lstmcell = nn.LSTMCell(phist_size, 512)\n",
        "\n",
        "        self.actor_linear = nn.Linear(hidden_size, num_outputs) # vec_st -> action\n",
        "        self.critic_linear = nn.Linear(hidden_size, 1) # vec_st -> value\n",
        "\n",
        "        self.inv_lstm = PerceiverIOrnn( # inverse model, predict taken action\n",
        "            dim = 256,                   # dimension of sequence to be encoded\n",
        "            queries_dim = num_outputs,   # dimension of decoder queries\n",
        "            logits_dim = None,           # dimension of final logits\n",
        "            depth = 1,                   # depth of net\n",
        "            num_latents = 64,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 64,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 4,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 16,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 16,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        ).to(device) # inv_latent + phi(st+1) -zeros> at +inv_latent1\n",
        "        self.inv_query = torch.zeros(1,1, num_outputs, device=device)\n",
        "        # self.inv_lstm = nn.LSTMCell(phist_size, hidden_size)\n",
        "        self.fwd_lstm = PerceiverIOrnn( # world model\n",
        "            dim = 256 + num_outputs,     # dimension of sequence to be encoded\n",
        "            queries_dim = 256,           # dimension of decoder queries\n",
        "            logits_dim = None,           # dimension of final logits\n",
        "            depth = 1,                   # depth of net\n",
        "            num_latents = 128,           # number of latents, or induced set points, or centroids. different papers giving it different names\n",
        "            latent_dim = 128,            # latent dimension\n",
        "            cross_heads = 1,             # number of heads for cross attention. paper said 1\n",
        "            latent_heads = 8,            # number of heads for latent self attention, 8\n",
        "            cross_dim_head = 32,         # number of dimensions per cross attention head\n",
        "            latent_dim_head = 32,        # number of dimensions per latent self attention head\n",
        "            weight_tie_layers = False    # whether to weight tie layers (optional, as indicated in the diagram)\n",
        "        ).to(device) # fwd_latent + phi(st) cat at -zeros> phi(st1) +fwd_latent1\n",
        "        self.fwd_query = torch.zeros(1, 256, device=device)\n",
        "        # self.fwd_lstm = nn.LSTMCell(phist_size, 512)\n",
        "\n",
        "        self.inv_linear = nn.Sequential( # inv learning, predict at\n",
        "            # nn.Linear(in_shape[1] + in_shape[1], 512), nn.ReLU(),\n",
        "            nn.Linear(hidden_size + phist_size, 512), nn.ReLU(),\n",
        "            nn.Linear(512, num_outputs), nn.Softmax()\n",
        "            ) # cat(phi(st), phi(st+1)) -> athat\n",
        "        self.fwd_linear = nn.Sequential( # predict phi st+1\n",
        "            # nn.Linear(in_shape[1] + num_outputs, 512), nn.ReLU(),\n",
        "            nn.Linear(hidden_size + num_outputs, 512), nn.ReLU(),\n",
        "            nn.Linear(512, phist_size)\n",
        "            ) # cat(phi(st), at) -> phihat(st+1)\n",
        "\n",
        "    # def encode(self, st):\n",
        "    #     st = torch.transpose(st, 1,2)\n",
        "    #     st = torch.transpose(st, 0,1) # [3, 240, 256] rgb, dim_x, dim_y\n",
        "    #     # vec_st = self.conv(st).view(-1, self.in_dim[1]) # [15, 256]\n",
        "    #     cst = self.conv(st).flatten() # [120*128]\n",
        "    #     cst = cst.view(1,1,-1) # [1, 1, 120*128]\n",
        "    #     phist = self.encoder(cst, queries = self.encoder_query) # \n",
        "    #     return phist # 256\n",
        "\n",
        "    def conv_encode(self, st):\n",
        "        st = torch.transpose(st, 1,2)\n",
        "        st = torch.transpose(st, 0,1) # [3, 240, 256] rgb, dim_x, dim_y\n",
        "        phist = self.conv_encoder(st).flatten() # [256]\n",
        "        # phist = phist.view(1,1,-1)\n",
        "        phist = phist.view(1,-1)\n",
        "        return phist # 256\n",
        "\n",
        "    def forward(self, inputs, icm):\n",
        "        if icm == False: #A3C\n",
        "            # st, latent = inputs # [240, 256, 3]\n",
        "            st, (a3c_hx, a3c_cx) = inputs # [240, 256, 3]\n",
        "\n",
        "            # phist = self.encode(st) # using perceiverio to encode\n",
        "            # latent1, vec_st = self.lstm(phist, queries = self.lstm_query, x=latent)\n",
        "            # vec_st, a3c_cx1 = self.lstmcell(phist, latent)\n",
        "\n",
        "            phist = self.conv_encode(st) # using cnn to encode\n",
        "            # print(phist.shape, (a3c_hx.shape, a3c_cx.shape)) # [1, 1, 256] ([1, 512], [1, 512])\n",
        "            vec_st, a3c_cx1 = self.lstmcell(phist, (a3c_hx, a3c_cx))\n",
        "\n",
        "            critic = self.critic_linear(vec_st)\n",
        "            actor = self.actor_linear(vec_st)\n",
        "            # print(critic.shape,actor.shape)\n",
        "            # return critic[0], actor[0], latent1 # for perceiverio encode [1, 1], [1, 18], \n",
        "            return critic, actor, (vec_st, a3c_cx1) # for cnn encode [1, 1], [1, 18], \n",
        "        else: #icm\n",
        "            inv_latent, fwd_latent, st1, at = inputs\n",
        "            # (inv_hx, inv_cx), (fwd_hx, fwd_cx), st1, at = inputs\n",
        "\n",
        "            # phist = self.encode(st1) # perceiverio\n",
        "            phist = self.conv_encode(st1).unsqueeze(0) # cnn [1, 1, 256]\n",
        "            # print(phist.shape, self.inv_query.shape) #) torch.Size([1, 12]\n",
        "\n",
        "            inv_latent1, inverse = self.inv_lstm(phist, queries = self.inv_query, x=inv_latent) # inv model; inv_latent + phi(st+1) -> at +inv_latent1\n",
        "            fwd_latent1, forward = self.fwd_lstm(torch.cat((phist, at.unsqueeze(0)), -1), queries = self.fwd_query, x=fwd_latent) # world model; fwd_latent + at cat phi(st) -> phi(st1) +fwd_latent1\n",
        "            inverse = nn.Softmax()(inverse[0])\n",
        "            forward = nn.Softmax()(forward[0])\n",
        "\n",
        "            # inv_hx1, inv_cx1 = self.inv_lstm(phist[0], (inv_hx, inv_cx)) # inv model\n",
        "            # fwd_hx1, fwd_cx1 = self.fwd_lstm(phist[0], (fwd_hx, fwd_cx)) # world model\n",
        "            # # print(torch.cat((inv_hx, phist[0]), 1).shape, torch.cat((fwd_hx, at), 1).shape)\n",
        "            # inv_vec = torch.cat((inv_hx1, phist[0]), 1) # predict at\n",
        "            # fwd_vec = torch.cat((fwd_hx1, at), 1) # predict vec_st1\n",
        "            # inverse = self.inv_linear(inv_vec)\n",
        "            # forward = self.fwd_linear(fwd_vec)\n",
        "\n",
        "            # print(\"forward icm \",phist.shape, inverse.shape, forward.shape)\n",
        "            # print(\"forward icm \",inverse, forward)\n",
        "            return phist[0], inverse, forward, inv_latent1, fwd_latent1 # [1, 320], [1, 18], [1, 320], ()\n",
        "            # return phist[0], inverse, forward, (inv_hx1, inv_cx1), (fwd_hx1, fwd_cx1) # [1, 320], [1, 18], [1, 320], ()\n"
      ],
      "metadata": {
        "id": "fRov_Uc2Sjf4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# wwwwwwwwwwwww"
      ],
      "metadata": {
        "id": "h7kyJMKO9uPJ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbpPda4YEv13"
      },
      "source": [
        "#### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Erf14x8KEv2A"
      },
      "outputs": [],
      "source": [
        "# train.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/train.py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "def train(env, args, model, optimizer=None):\n",
        "    # torch.manual_seed(seed)\n",
        "    # model = ActorCritic(env.observation_space.shape, env.action_space)\n",
        "    if optimizer is None:\n",
        "        optimizer = torch.optim.Adam(shared_model.parameters(), lr)\n",
        "    model.train()\n",
        "    for x in range(num_episodes):\n",
        "        # model.load_state_dict(shared_model.state_dict()) # Sync with the shared model\n",
        "        latent = None\n",
        "        latent = (torch.zeros(1, 512).to(device), torch.zeros(1, 512).to(device))\n",
        "        inv_latent = None\n",
        "        fwd_latent = None\n",
        "        # inv_latent = (torch.zeros(1, 512).to(device), torch.zeros(1, 512).to(device))\n",
        "        # fwd_latent = (torch.zeros(1, 512).to(device), torch.zeros(1, 512).to(device))\n",
        "        values = []\n",
        "        log_probs = []\n",
        "        rewards = []\n",
        "        entropies = []\n",
        "        inverses = []\n",
        "        forwards = []\n",
        "        actions = []\n",
        "        vec_st1s = []\n",
        "        episode_length = 0\n",
        "\n",
        "        state = env.reset()\n",
        "        # state=state[:,:,0]\n",
        "        state = torch.tensor(state.copy()).type(torch.float).to(device)\n",
        "        # st1 = state.float()\n",
        "        # print(\"#####www####\",state.dtype,hx.dtype)\n",
        "        while True:\n",
        "            episode_length += 1\n",
        "            value, logit, latent = model((state, latent), icm = False)\n",
        "            prob = F.softmax(logit, dim=1)\n",
        "            log_prob = F.log_softmax(logit, dim=1)\n",
        "            entropy = -(log_prob * prob).sum(1)\n",
        "            entropies.append(entropy.cpu())\n",
        "            action = prob.multinomial(1).data\n",
        "            log_prob = log_prob.gather(1, action)\n",
        "            oh_action = torch.zeros(1, env.action_space.n)\n",
        "            oh_action[0][action.item()] = 1.0\n",
        "            at = oh_action\n",
        "            actions.append(oh_action)\n",
        "            state, reward, done, _ = env.step(action.item())\n",
        "            state = torch.tensor(state.copy()).type(torch.float).to(device)\n",
        "            # state=state[:,:,0]\n",
        "            # print(\"reward\",reward)\n",
        "            done = done or episode_length >= max_episode_length\n",
        "            # reward = max(min(reward, 1), -1) #why clip rewards?\n",
        "            # st = st1\n",
        "            # st1 = state.float()\n",
        "            # vec_st1, inverse, forward, inv_latent, fwd_latent = model((inv_latent, fwd_latent, st1, at.to(device)), icm = True)            \n",
        "            vec_st1, inverse, forward, inv_latent, fwd_latent = model((inv_latent, fwd_latent, state, at.to(device)), icm = True)            \n",
        "            reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1) / 2.\n",
        "            #reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1).sqrt() / 2.\n",
        "            # print(\"reward_intrinsic\", reward_intrinsic)\n",
        "            reward_intrinsic = reward_intrinsic.item()\n",
        "            # print(\"ep \",x,\", rwd ext: \", reward, \" ,rwd int: \", reward_intrinsic.item())\n",
        "            reward += reward_intrinsic\n",
        "            values.append(value.cpu())\n",
        "            log_probs.append(log_prob.cpu())\n",
        "            rewards.append(reward)\n",
        "            vec_st1s.append(vec_st1.cpu())\n",
        "            inverses.append(inverse.cpu())\n",
        "            forwards.append(forward.cpu())\n",
        "            if done:\n",
        "                print(episode_length)\n",
        "                episode_length = 0\n",
        "                break\n",
        "        R = torch.zeros(1, 1)\n",
        "        values.append(R)\n",
        "        policy_loss = 0\n",
        "        value_loss = 0\n",
        "        inverse_loss = 0\n",
        "        forward_loss = 0\n",
        "        gae = torch.zeros(1, 1)\n",
        "        for i in reversed(range(len(rewards))):\n",
        "            R = gamma * R + rewards[i]\n",
        "            advantage = R - values[i]\n",
        "            value_loss = value_loss + 0.5 * advantage.pow(2)\n",
        "            # Generalized Advantage Estimataion\n",
        "            # delta_t = rewards[i] + gamma * values[i + 1].data - values[i].data\n",
        "            delta_t = torch.tensor(rewards[i]) + gamma * values[i + 1].data - values[i].data\n",
        "            gae = gae * gamma * tau + delta_t\n",
        "            policy_loss = policy_loss - log_probs[i] * gae - 0.01 * entropies[i]\n",
        "            cross_entropy = - (actions[i] * torch.log(inverses[i] + 1e-15)).sum(1)\n",
        "            inverse_loss = inverse_loss + cross_entropy\n",
        "            forward_err = forwards[i] - vec_st1s[i]\n",
        "            forward_loss = forward_loss + 0.5 * (forward_err.pow(2)).sum(1)\n",
        "        optimizer.zero_grad()\n",
        "        # print(\"invvvvv\",inverse_loss , forward_loss)\n",
        "        # ((1-beta) * inverse_loss + beta * forward_loss).backward(retain_variables=True)\n",
        "        inv_loss = (1-beta) * inverse_loss + beta * forward_loss\n",
        "        pol_loss = lmbda * (policy_loss + 0.5 * value_loss)\n",
        "        (inv_loss + pol_loss).backward()\n",
        "        # (inv_loss + 0*pol_loss).backward()\n",
        "        # (((1-beta) * inverse_loss + beta * forward_loss) + lmbda * (policy_loss + 0.5 * value_loss)).backward()\n",
        "        print(''.join([str(torch.argmax(a).item()) for a in actions]))\n",
        "        print(\"inv_loss: \", inv_loss.item(), \" ,pol_loss: \", pol_loss.item())\n",
        "        # if log:\n",
        "        #     wandb.log({\"inv_loss\": inv_loss.item(), \"pol_loss\": pol_loss.item()})\n",
        "        torch.nn.utils.clip_grad_norm(model.parameters(), 40)\n",
        "        optimizer.step()\n",
        "        del inv_loss, pol_loss, state\n",
        "        del value, logit, latent, vec_st1, inverse, forward, inv_latent, fwd_latent\n",
        "        del values, log_probs, rewards, entropies, inverses, forwards, actions, vec_st1s\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCHpcDteZdLS"
      },
      "source": [
        "#### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ja6KZf13p--B"
      },
      "outputs": [],
      "source": [
        "# test.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/test.py\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "def test(env, args, model):\n",
        "    # torch.manual_seed(seed)\n",
        "    # model = ActorCritic(env.observation_space.shape, env.action_space)\n",
        "    # model.load_state_dict(shared_model.state_dict())\n",
        "    model.eval()\n",
        "    state = env.reset()\n",
        "    # state = torch.from_numpy(state.copy()).type(torch.float).to(device)\n",
        "    state = torch.tensor(state.copy()).type(torch.float).to(device)\n",
        "    reward_sum = 0\n",
        "    start_time = time.time()\n",
        "    actions = []\n",
        "    episode_length = 0\n",
        "    result = []\n",
        "    latent = None\n",
        "    a3c_hx = torch.zeros(1, 512).to(device)\n",
        "    a3c_cx = torch.zeros(1, 512).to(device)\n",
        "    while True:\n",
        "        episode_length += 1\n",
        "        # value, logit, latent = model((state, latent), icm = False)\n",
        "        value, logit, (a3c_hx, a3c_cx) = model((state, (a3c_hx, a3c_cx)), icm = False)\n",
        "        prob = F.softmax(logit, dim=1) #from train\n",
        "        action = prob.multinomial(1).data\n",
        "        state, reward, done, _ = env.step(action.item())\n",
        "        # state = torch.from_numpy(state.copy()).type(torch.float).to(device)\n",
        "        state = torch.tensor(state.copy()).type(torch.float).to(device)\n",
        "\n",
        "        done = done or episode_length >= max_episode_length\n",
        "        # print(\"rwd ext: \", reward)\n",
        "        reward_sum += reward\n",
        "        actions.append(action[0])\n",
        "        if done:\n",
        "            end_time = time.time()\n",
        "            print(\"Time {}, episode reward {}, episode length {}\".format(\n",
        "                time.strftime(\"%Hh %Mm %Ss\", time.gmtime(end_time - start_time)), reward_sum, episode_length))\n",
        "            result.append((reward_sum, end_time - start_time))\n",
        "            torch.save(model.state_dict(), 'model.pth')\n",
        "            # print(''.join([str(a.item()) for a in actions]))\n",
        "            print([a.item() for a in actions])\n",
        "            break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj3tv7XHZmD9"
      },
      "source": [
        "#### main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjPLqIBgH9xJ",
        "outputId": "33a46e78-9e00-4491-a4a2-6ee5177bf2c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/envs/registration.py:565: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
            "  f\"The environment {id} is out of date. You should consider \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(240, 256, 3) Discrete(12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/utils/passive_env_checker.py:98: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
            "  \"We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) \"\n"
          ]
        }
      ],
      "source": [
        "# main.py\n",
        "# https://github.com/kimhc6028/pytorch-noreward-rl/blob/master/main.py\n",
        "# import os, sys, cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import gym\n",
        "\n",
        "lr=0.001\n",
        "gamma=0.99\n",
        "tau=1.00\n",
        "seed=1\n",
        "num_processes=4\n",
        "num_steps=20\n",
        "max_episode_length=500 # 10000\n",
        "# env_name='PongDeterministic-v4'\n",
        "# env_name='LunarLander-v2'\n",
        "# env_name='MontezumaRevengeDeterministic-v4'\n",
        "# env_name='MontezumaRevengeDeterministic-ram-v4'\n",
        "\n",
        "no_shared=False\n",
        "eta=0.01\n",
        "beta=0.2\n",
        "lmbda=0.1\n",
        "outdir=\"output\"\n",
        "record='store_true'\n",
        "num_episodes=10#100\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "# env = gym.make(env_name)\n",
        "# env = SparseEnv(env)\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, COMPLEX_MOVEMENT) # SIMPLE_MOVEMENT COMPLEX_MOVEMENT\n",
        "env = MarioSparse(env)\n",
        "env = MarioEarlyStop(env)\n",
        "# query_environment(\"MountainCar-v0\")\n",
        "\n",
        "print(env.observation_space.shape, env.action_space) # (210, 160, 3) Discrete(18); mario complex (240, 256, 3) Discrete(12)\n",
        "\n",
        "shared_model = ActorCritic(env.observation_space.shape, env.action_space).to(device)\n",
        "# shared_model.share_memory()\n",
        "if no_shared:\n",
        "    optimizer = None\n",
        "else:\n",
        "    optimizer = torch.optim.Adam(shared_model.parameters(), lr=lr)\n",
        "    # optimizer.share_memory()\n",
        "args=None\n",
        "# train(0, args, shared_model, optimizer)\n",
        "\n",
        "# processes = []\n",
        "# import torch.multiprocessing as mp\n",
        "# p = mp.Process(target=test, args=(num_processes, args, shared_model))\n",
        "# p.start()\n",
        "# processes.append(p)\n",
        "# for rank in range(0, num_processes):\n",
        "#     p = mp.Process(target=train, args=(rank, args, shared_model, optimizer))\n",
        "#     p.start()\n",
        "#     processes.append(p)\n",
        "# for p in processes:\n",
        "#     p.join()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFrRKvOwhYM_"
      },
      "source": [
        "#### run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "-KuzIfVWPBIg"
      },
      "outputs": [],
      "source": [
        "max_episode_length=2000 # 10000\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "dHLw7ewldCLm",
        "outputId": "81269d3c-dea2-4d59-866e-c64596365a25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:134: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:135: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-a8592251c8e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshared_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-62c793172027>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(env, args, model, optimizer)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# st1 = state.float()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0;31m# vec_st1, inverse, forward, inv_latent, fwd_latent = model((inv_latent, fwd_latent, st1, at.to(device)), icm = True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mvec_st1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minv_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwd_latent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minv_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwd_latent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0micm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0mreward_intrinsic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvec_st1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m#reward_intrinsic = eta * ((vec_st1 - forward).pow(2)).sum(1).sqrt() / 2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-f1d2a61093ab>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, icm)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m             \u001b[0minv_latent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minv_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minv_latent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# inv model; inv_latent + phi(st+1) -> at +inv_latent1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m             \u001b[0mfwd_latent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd_lstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfwd_latent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# world model; fwd_latent + at cat phi(st) -> phi(st1) +fwd_latent1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m             \u001b[0minverse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0mforward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-a157a38131f5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data, mask, queries, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;31m# cross attention only happens once for Perceiver IO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_ff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0;31m# layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mself_attn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself_ff\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6c7254e08183>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mnormed_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormed_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mGEGLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-6c7254e08183>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mAttention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 14.76 GiB total capacity; 13.47 GiB already allocated; 3.75 MiB free; 13.50 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
          ]
        }
      ],
      "source": [
        "# train(env, args, shared_model)\n",
        "# train(env, args, shared_model, optimizer)\n",
        "\n",
        "for x in range(20):\n",
        "    train(env, args, shared_model, optimizer)\n",
        "test(env, args, shared_model)\n",
        "\n",
        "\n",
        "# early stop ard = self.fwd_lstm(torch.cat((phi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlV2MvSK-aL_"
      },
      "source": [
        "#### save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "TN-XW-LvZ8Xl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f9aa91-492e-40af-cb0c-1d9009667908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "PATH=\"/content/gdrive/MyDrive/curious/\" # for saving to google drive\n",
        "name='model_mario_perceiverio_fwdinv.pth'\n",
        "# PATH=\"/content/\" # for saving on colab only\n",
        "# name='model.pth'\n",
        "\n",
        "model=shared_model\n",
        "torch.save(model.state_dict(), PATH+name)\n",
        "\n",
        "# model.load_state_dict(torch.load(PATH+name))\n",
        "# shared_model=model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xl6PNxVu-W6K"
      },
      "source": [
        "#### video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 941
        },
        "id": "W6fkhEcBB3tM",
        "outputId": "b1537302-6d26-4b35-c90d-4bbed05b8ca9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Imageio: 'ffmpeg-linux64-v3.3.1' was not found on your computer; downloading it now.\n",
            "Try 1. Download from https://github.com/imageio/imageio-binaries/raw/master/ffmpeg/ffmpeg-linux64-v3.3.1 (43.8 MB)\n",
            "Downloading: 8192/45929032 bytes (0.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b2916352/45929032 bytes (6.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b7143424/45929032 bytes (15.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b11288576/45929032 bytes (24.6%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b15163392/45929032 bytes (33.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b19324928/45929032 bytes (42.1%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b23420928/45929032 bytes (51.0%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b27197440/45929032 bytes (59.2%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b31383552/45929032 bytes (68.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b35520512/45929032 bytes (77.3%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b39690240/45929032 bytes (86.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b43819008/45929032 bytes (95.4%)\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b45929032/45929032 bytes (100.0%)\n",
            "  Done\n",
            "File saved as /root/.imageio/ffmpeg/ffmpeg-linux64-v3.3.1.\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioSparse: died\n",
            "MarioEarlyStop: early stop  310\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls>\n",
              " <source src=\"data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc28yYXZjMW1wNDEAAAAIZnJlZQAAj2htZGF0AAACrQYF//+p\n",
              "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE0OCByMzMzIDkwYTYxZWMgLSBILjI2NC9NUEVH\n",
              "LTQgQVZDIGNvZGVjIC0gQ29weWxlZnQgMjAwMy0yMDE3IC0gaHR0cDovL3d3dy52aWRlb2xhbi5v\n",
              "cmcveDI2NC5odG1sIC0gb3B0aW9uczogY2FiYWM9MSByZWY9MyBkZWJsb2NrPTE6MDowIGFuYWx5\n",
              "c2U9MHgzOjB4MTEzIG1lPWhleCBzdWJtZT03IHBzeT0xIHBzeV9yZD0xLjAwOjAuMDAgbWl4ZWRf\n",
              "cmVmPTEgbWVfcmFuZ2U9MTYgY2hyb21hX21lPTEgdHJlbGxpcz0xIDh4OGRjdD0xIGNxbT0wIGRl\n",
              "YWR6b25lPTIxLDExIGZhc3RfcHNraXA9MSBjaHJvbWFfcXBfb2Zmc2V0PS0yIHRocmVhZHM9MyBs\n",
              "b29rYWhlYWRfdGhyZWFkcz0xIHNsaWNlZF90aHJlYWRzPTAgbnI9MCBkZWNpbWF0ZT0xIGludGVy\n",
              "bGFjZWQ9MCBibHVyYXlfY29tcGF0PTAgY29uc3RyYWluZWRfaW50cmE9MCBiZnJhbWVzPTMgYl9w\n",
              "eXJhbWlkPTIgYl9hZGFwdD0xIGJfYmlhcz0wIGRpcmVjdD0xIHdlaWdodGI9MSBvcGVuX2dvcD0w\n",
              "IHdlaWdodHA9MiBrZXlpbnQ9MjUwIGtleWludF9taW49MjUgc2NlbmVjdXQ9NDAgaW50cmFfcmVm\n",
              "cmVzaD0wIHJjX2xvb2thaGVhZD00MCByYz1jcmYgbWJ0cmVlPTEgY3JmPTIzLjAgcWNvbXA9MC42\n",
              "MCBxcG1pbj0wIHFwbWF4PTY5IHFwc3RlcD00IGlwX3JhdGlvPTEuNDAgYXE9MToxLjAwAIAAABrS\n",
              "ZYiEACP//sdv5lIWkEF5V2eiTJ559f0VfhQe/2K0PHi1DFu5CrqcTcNf4VWsQpJhScta1mO3EBed\n",
              "HH5YcvaGOm1ahFOpwfzsauGPTiiypKwCqlo+bqB8Ef02BU14fkJTTsaPh1f8aysnSuOalnq9IJr6\n",
              "xrz5+xhtM1NWgMyCJ9TKIuO9FPyOrz0b0zDTCMIqVq3wAc1XgEDVr7Rk5qth26EODzSLNv242ZoU\n",
              "XJPTDvnjeBxATUTYoIjjaTAwGMyfsnCzoCv61U8efnUAdvHrrUJzNNl9k/R4unjydmNNC1/1p8D+\n",
              "DfLL+hxFoqbUxNl8qNgqVSaYTxpZ4d2QAFbjIelSztaTQopp6v8tTy2KswS96K/G7B9gXWRVS+cv\n",
              "+Z4SKaZ0xsvF1+WFjkr/oAazhpsGS/Gj2eSiVbs/bPbIkrgriZEhe00jmXwv7N9SKBwDxDd0jY5k\n",
              "ZcH/XpwTPdljMStmhpInFRKUcVEFiNMvPO8Ep+Qgrp2r7WLwEmdMDSIks6A9Tho0Udz+30O66USw\n",
              "QVD8NH///3oVQx3bcQByLXDQDDN1tLocjzc8kIiXwRB5IL8UOjbQQJKn/sPZy4NF1L+VK1dUu4wl\n",
              "aDa4OH8fl9lY+15BGRd2q5wAQpEUyvrm536KttLHFrnI6N8n+92W19P6IjLCtInwxHhM2OHceFOd\n",
              "D38u6uTgYCspmbypWfvs2o/8Ktlq+FD2w+MBGY/++PIWtl3D+ccM2dICwwhvDsj4Izhzx9JRtdsb\n",
              "fU2W8arQca52a8xeI22P/Bn3zML9SOc7yRGNTU1YPWcvdQbslLrFHOsd/v9nRy+Qz20ORYcoe8fH\n",
              "z4SAdACRPMnFUlup0CCFK8y5C48tNv5V3YyccDLPWLljCX8CYzsndu6RFpLkpd65QXjdQw/kkIb+\n",
              "7t+6FJE+gBefwllXng8Cw+OZu3BE/1FwbnTJ9PXQPB6CMrbtBKnxs3rb+LJoyH8eG4FGGiXwMT8G\n",
              "2f4xN1xd2OBDVhSu7FyELiCin6HUdjnnUjoIBNHs+iRQnuU3xnSCMmzL0Nzaammub0EHIghPXuYI\n",
              "L4O0yioU8xHki8+S5dqCP6v4mghrWcrgtDmyWzgZFuJXo+S3tzWmoRt5KmtsxbJZefknl/HcwA4W\n",
              "8Vhaei0LAfbWCcq0OPLJ/VPDpVT4xzros2nIKiraUTi4W1EcuypIOAnA4PrwG6pxS5RWn2F382BI\n",
              "tk7upLLvuiUreS2fffVN8NgUTu4GxXMHxLzm9tcgI2cU7sOP7Hv4Ap/6q3TNSz4pd0J5cp2WFDO1\n",
              "thYlTKMrS+txPiUBw3KkORzt2OSblCSasmRfx0V5DZsXuz7vhD5MVGWy8sjrVlKrO81/FbeAAUAJ\n",
              "wQRM4WPvUDfhlKxWdI7G6wsZIffGpYhEVQKNyy17/WJqsYNWR8cV3sXgzRoGx3yeNeC/3XiGIL16\n",
              "IXYmOFKrjz1f1CUoGl2ECat/q2qIHHuCS5wa0oO7ZI34wW5+uWvEfJ56st/NLOZr6HdvpKUyWnbB\n",
              "6KzQxVmSbJ+rSD/rPwst0XWzX6kQ+RWO3ho/SAUhggpW51dpHIcoL8dlR5ftKx23UvnnNaau562a\n",
              "YPhoPowoAkSd1BrqrIhTqvTtlMh2/8CMVE3UrVDByUwxJQTUw4t8YxTCcZqfOHoSPDCpNyMEXJSG\n",
              "DkGn941R7RaJg0CtzvtHcQ9hrgumo/C0FY72uR06BpBA1KwGTbdkhqVggBauLDkqGPOJ/WVg9w1N\n",
              "dzznN8pDk7FjIaL80iWUMy37RC4SgxcMUnWo8d73OjXoOnJkc0CtrVr6ppc7h6XLj/th6LYasDDb\n",
              "JrwSQFOKBgbV+wFNz50oD3G6Lrx/QrCeWGoTt4wbaHMSK+naED2F/HMXU9wBpjduXC0Bp8OFlYT8\n",
              "1Za9g9KPHiv7BaIa7D6HwppY9mBkdKA4qdok9peQ9+Rx4N85mmUh5FIXeKQMgsMDG8gMxVGQDYM9\n",
              "LGliRGtCv0zXKx5qWEEYTh8unsVZbtPOcOej1ME1+rp8ZcnvA5d9zZNWIm75qZfxbPHR4BFsu65K\n",
              "VK3lIc0agRr6NsZRgkTSQk9vakt8uff9WWy0YpdYeSxw6g5XkdhJ+EkAoRmHOM584DXtRaUVe4VP\n",
              "0/B1Qaw0ZpViaK2bIXfBamQth74c3F3XyCvPbVYbmBSpL/Mw8T9KJ74ssOF2a7Gn1zyGIRXhwj2A\n",
              "2U8WwNEPix8A9f2hBc+YgZIaKZIg4OkTsV5MZUlWB3+dRMdg1iMYI9j8nKkP4XJ3XKDK3AdPa9L2\n",
              "kfB9ZGq+6SKXg/DwQm8YAn8ww8LaKXPaq0HmfQBeyowJ0rB+0F20pgvUKMgJ7M5q1Q/7MCRbDALU\n",
              "AAAHnDGYT6SNF8bs3v+IXo2yX+kOVzZoNMA1Qgx+ilg/H3rEMULcCXSbjOCtHKsmTFf2IpaGSZqZ\n",
              "ZFrhygF6ySyGWRdqkF9Cd99m3uk1+L6xJyQlJgvAlUe5khBqmXF38SZxNrF9dnHEi20FQBqdeco6\n",
              "TjV8BKLNp9OzQJOIIDt8u6ztza+kNPAvDeqQ1KgeHf3IgXhpNmA5LmYfgOVMpqq6YmdjBJy5P7G1\n",
              "oBrv8a5Mi3tcUyVntynEj9pTMlpK8ufMPlyPn7ZFj4nJjkYIOZ1Zdh+Ebz1Tosm+P+HHszi3ZKgQ\n",
              "KoCQJdYPNSV7mbQd3+4kdHqGjSnW4qFmK52pES4Vb2uUbyRw8vS7zn3QrR2wLg1IbtUe4ke1L34D\n",
              "Ui8WhkVPPjwJAjaTkIoIjatF35PjEje3z2eU9wts2yrc/M6U82GGaAfhq8Wwwqg6ZbF1cx6lq2bB\n",
              "+Pqn6ViI0Ro4zS0mc8WmeubyWDWfbKg9ac8dnv5GWifi8SyfHxT6C0frPVjRwZvjC0eeQCpXcxtx\n",
              "joImDS6FwDWQW7BxRaylRNJS8SQB3GC9f0VwdMDVARP+bp+NLdWejIexU0tHsay8k+6iT5bviXfW\n",
              "3dzs7Pd7MwqEo/1ouZpKi3M1XZmUR3VzeoU8lgcgKXxi2wWmzqGOWELA65I9+T8mwFpjL+dCnYnA\n",
              "sKJSFb6fmHlnhs3wgx/j1t9aJHGtFj/2wc5+QGNXZw64onYSHcjNICYy6m+TznQAANruxOECd9Ir\n",
              "04biODEqY1ze6omoabo9zz2Zjt/e+6cX6E/wftyLQsHpTPWyvVoymymIQ6+8qLPQ0IdumP1AyMWh\n",
              "9xgfhB4DFJFMxYOMtSeVgJz7vacnPoJm7P9izGxbTROK1gXB2hZjtaIDPA+3udGQT8WfPe1MJF5r\n",
              "NSd4qvUVE48O9ftbvUW1yrdcecUXfdA7kG8EvN+YM4oeBIMtIvPk5prkMs+6wGEzjciAUk8lDS2m\n",
              "GM33c5+7Q2pyyRkIQe687Z52wKvne/S5D6/Qgnblt5T5aJ23azLOyndDRebFuFM9/GeFOy0fo1iC\n",
              "/9CFrks+EDCww72vqSVAVPSQJIvPk5qUkrS4m5RW1WnH+PeF2TU1cjCtBuBk4MkgrqKHd7pGPaud\n",
              "IFiCtIW0mDocUogcziDxuwe3TtDwPt7oGLJFrTBnEhhUSnOaOpWfeX6a6rfv+aZ5hQiczyzoZALQ\n",
              "8bW9RP4dPNM9x7/F9nYmJw0MRTsDKYYAtJUtZRhaQf+NadVbCDgz3hJRngnGHMiTFiIUp3Z3X9C3\n",
              "l06FiqnMEmqSc/ZdQop/0Ea9SkLp0yhzRTscmjW1XX3kdyFKR9nUrrAWpvFDrlCyQ6Bf/y/VxU68\n",
              "J1tHte5BooYRPpA82CHT8F5t+iGHStI5rXQOjlfgwJMiXb/3rXRNdl4C9f9gg0AsjAh4J78B+xDQ\n",
              "h7lvziV9sfOKlhsRoDesN983ynfj2sTL/PIxkreABsI2kVzenWapkslexDWDj/7pws1KrHCT3Z1u\n",
              "4vPuKL/iM9e2RDmdgb5fCOY+ZeKG54HX+m9o71Q1rB4t+2JjEOHdjQvIbM5wN6b0pF8BeEuQPfWF\n",
              "vRlh25FWsGtPsON3HIG7sdL+Obxl5ZiW1rVXhuBhnay77swS05kuHX5rsFRqEw/0lGtC3YwrMqE3\n",
              "tCnGcTGhgaNFUki9oOLh86SmZTvWeNAXynSIzy5aAsztS0KP5gZrH0dlHHjTZxVJPt1z7/jv7Ctp\n",
              "NFMio1C1j252HvHQP6/yGAKbCnOgHc6JicwrOkpXVgBoqYe/Xl2KPE0wdOzbgh65t40K5B7islla\n",
              "bAi48Dq+cCZI6L6qNhfhbPxes5u93J6qaqpzx+UawoRwe+agUV8lp2JAGyKzWBrh19XBxoDQbn1T\n",
              "LmJx0mqDOjS63iGzXykXDDvdJZcEugiE9tneQMd6q5Twf5WsRpYvFJgSlb2E0/5GVWQzH31pYCTm\n",
              "mGIn6gcwp2xlG+sHCpRydhiWSvQDTVIB+k8DGvxuGJl/nqYNJQ+oyA7pLWGxERMCQWcEvKU7Dmkx\n",
              "S0XgbtfXkeraqvvUj2fvd9ypJfepgRZdUb4Dj/aQLs4+JdO4i8tQsarhN0Z75jdXQ7nhuWjw8V9j\n",
              "YJecFc7j9so+f+/hNXbLbupVj9FPFIWd23Nhe/l5nVcKksUCej8WlE5qTafLnQEWYGdkewZkWoxB\n",
              "NKA4lwL2GpoUBFGFXB/JNZELjpSLwhzDw9y3/RD79Cyy4rGygwyANKqdDX4gd8DuPkOs9kZXiJ/1\n",
              "qeAOTUDUx3RxTY5J/GpMvlStIHvjFUwW2qj5Rl4Nrb2DhZYStKy9wQ5eTfgA27a43SaGheeBym62\n",
              "WTyafLnQEOV/N5NqQx+6kFBOMfIAXsnPS7NSboLrVohB5wz2UXhDmHh7lv3en36FllxWNk/JgsaV\n",
              "U6GvyCe85cfIdZ7JKGehgvfKeRkRsrj6OKbHJPH/Jl8qVo9A4oaXQtmo7w7KwIVhRnbX6lB8gr4J\n",
              "XvDE23ZuOhIGsJpMPxgWbeo2WHLnQF9m4b3aBcz7j6vIQW+QAvY2REwIopUcu9V0viXCcReEOYeH\n",
              "uW/eqffoWWXFY2T0GCxpVToa/CloYHCb5WlqY44if9angDpP3kEMe3wsck6B8mXypWkCy8IcbYjj\n",
              "OuBEYGKOor7DUE1LuqiL42UIyW7KbtO/y+HQMcM2LjF6jZYcudAasbhvdoFzPIQCjQmOJcC9kVET\n",
              "Aiii60fyTWRC41ci8Icw8Pct+6P7v7ssuKxsnZwbutMAIa/DueYHCb5WlqaWz0MF75TyHfAHJbV1\n",
              "9E4qdF3+WV5rUa6E3rb8kqJw5GorAwRC0ow9qITE3AkcAVeojwts1dSc96rEsLCZRssOXOgNeNw3\n",
              "u0C5pEIJN4THEuBeyqiJgRRRdaP5JrIhcauReEOYeHuW/dH9392WXFY2Ts4N3WmAENfi3PMDhN8r\n",
              "S1OLZ6GC98p5DvgDktq6+icVOi7/LK81p3ioWfoflZKv/bGOSdvCIo7OpQIS1v0Wr9pJGUrCdVZn\n",
              "Ku5z7eIeTyafLnQIYr+bybUhpkILN4THEuBey6iJgRRRdaP5JrIhcauReEOYeHuW/dH9392WXFY2\n",
              "Ts4N3WmAENfi3PMDhN8rS1PDZ6GC98p5DvgDktq6+icVOi7/LK81qNKUZLp+kWCKYuYGjbZdZ5op\n",
              "we15H6x4kOPPQi6bNGX8WX3l9QIYk52Kqlkiyv5vJtSGmP6wwqO4tbDwpP/twHiSEphy3oxx71PM\n",
              "0D3pm0bvgDsDeKI/uJOTMiEhdvXpm7EsTvhe3wvKIyNfPQOmMdBM2Fk1HdAdyiB5UZZHvX6jTt8e\n",
              "RiRZGbPHIKdF9oweOaN0cQHKAAhwEQ8YvdYQcy2T2C3b3fAtb2e73oF/Q4b3NXPQFczy1HKMfh0O\n",
              "PurfYEUVoOMAnOp5WN+A6vZTOeHuU1h5rYWuozEvEn2Ys85HI1GYRb/rYEJubZ55lZrXmkqF1w7I\n",
              "uoEIeGLIeO7e9HC+YMdCOb+4tUqa4/5zyXUIiuq4V8DvOuC2bVeI1yQVKIaXxhv3SRsHNmPBQADF\n",
              "oYGyPYKH+gLZjSgOXoU24zauzUjr/hAJzqeVUw5F4SU54e5b7zuTDc8suKxsmwnY8ihLoa+84fgH\n",
              "Cb5Wlqee2at9angDfvev84Q4psck4X/Hllea1GAy2U+cRIqtQ+lYV2YlAZ4mAXBvmpR4zMYec5sZ\n",
              "9JFMaX5VkfRpJXhBQADE3Oj7tAsga1e8PyBcEXlnHX0uzUlkBL2ISTlpaGVCKJKc8Pct+n/7v7ss\n",
              "uKxsnJxtetMAIa/HYkgHCb5Wlqfm2at9angDnPiweOq6+icVN2+PLK81p3rwRDLavXiQ2/5OaCAl\n",
              "sXaRungd+jpAFiToaJBL3/PK17yyQK3VCiMhkFM0amgC5Sf45W9bWTBdtyu+pmC8ZYv9WiVyxu4F\n",
              "G73XgBUl1SuQP1d+kfXtBOph/kvOFDlcTU/PkZrwxHmQZQSAizFIQ54No8Z6A69l7QSjFVAC17GU\n",
              "PPuA8GK6pV0GsaDn4qiKexlB3ILwXb8PnEY5Bwv0zHlmyRxZdJjeiqvNL0cEyH2YCkf49bFzlGsA\n",
              "CqneYX1btOUO8nMN2twDukkljy8VMZFjkkEvO41IA4kSnG9+7Et7vjISugIIb8I/Xj1NqML41PZf\n",
              "Am+d8mef9GSKStRTd7K/5MXNl1o35yVJz7REXMOBlgQkisnMCljj2L9jvTdlMaJIxYEbuLhaBtph\n",
              "6c6G/plSkCj7D75w3eqTm2AJ4e0Mg+8x2ptnUdJqeptBu0BWhIGwe3L1mNSPegAdgHMjI/yfyc+o\n",
              "7CfIcvoG00xrMhbpLe0tvvVBBRcnn83/wPVCrIxvmw/5D/JtqWuMdCS+OtoyGO2xnGYvYF4Us34R\n",
              "AQbSsAMP5756wDbfjVUM3kDCo8YSKWSm5yp2U7zmpQMShS/N3zWCQk975aGYfXCb6fJbX8mbIwVL\n",
              "GoVc4twjmM3jKSP8xsIj53xYgvrjRB9TsCG+g1+yOPmooreasz7rlFqFsvIAdM3IaDrPsTFR9Zti\n",
              "iZStu7q6t61nUX8Q7LFR4AJh9Je2ouMsT2dKIJG5vVsJRwogTiQgH2/Tw/k5Oak1hGWPaPzWCQk9\n",
              "1avvXD/djzHpYreX3w6YkJedxo8TtEWUcbCshTYLBUdsbkOZSmR7cqlTOTxy71e+G5giFO35BgbU\n",
              "Zw3Us32oNiK4fQAtGk3819P/41XWYyw+DMMFhGur4d0B/pxdtK3ax+B1dxGHCy7lvcEtslv/JD+t\n",
              "3qlNr7RX2whnLgzSgN+pzMBXmKO4nI9vbCwAfp3l6q2b0m1s6xXcHBzKw+KT9n2WLwRPNEhA6sTs\n",
              "OMdh5mb6nE+q+yLkMHZ5Ja0JM0MiIE21McLjOD0hMICFG6lq54nJD2K6L2Ogt0zRlWJ4ThXHYQsa\n",
              "rygI+JIqS5yJQ/Tw/k5OalIbwu6eEYICQlSnH33r9le/6fJbX9uUU80JPoVc4+HDmM3jKSP84cEj\n",
              "53xYgvriSg9TsCG+gTXG6pfDcwkCnf7zfMKM4bqWb/eLyIgTbUw7GsIFlfRKDiXHVJBbdZcMXEWm\n",
              "dWfoY7lpx/zFZ6Vz3+7ta7lvcErc6n+SH9bvVKbnP4vphDOXBmkIb9TmXTDMUdxOR7fvBgA/TvL1\n",
              "VsqptrZ1iu4ODU3pHx1dbP3oqKRp845k5O+er1S9o3/3+u/5BkYUZw3Us4K0NiK4fQAxl8cnKtgF\n",
              "t2yy5eioC+C5f8w4dKimsXrh8CB3f5pDs+rs6I+JIqS5oLGnK5ZTvOalLO1XfjH5rBISvgtX3r7o\n",
              "e/6fJbX92d080JPoVc48GzmM3jKSP85htgqO2NyHL3+g9TsCG+gTXA6pfDcwkCnf7zjNKM4bqWb/\n",
              "eLyIgTbUy3xtInp/9c7Qyi8Go3ydDnDMJpe3QyZhGY32RtWJuiGziXct7glWJb/yQ/rd6pTc58V9\n",
              "MIZy4M0nDfqczCYZijuJyPcA4MAH6d5eqtldNtbOsV3BwY1NmKL9n2WLv+SdEhA6sTsOMdg5mb6n\n",
              "E+s+mqv0HZ5Ja0LMUMiIE21M3BccmSWOuiZEY350buuRX/Xz7MC6GvpLsBcTtIVBjDHB9QR8SRUl\n",
              "zCV9OVyynec1KcNqu/GPzWCQlfBavvX3Q9/0+S2v7s7p5oSfQq5x4NnMZvGUkf5zDbBUdsbkOXut\n",
              "B6nYEN9Amt72Dmoor6q7r7zjNKM4bqWb/eLyIgTbUxXbjI6TuEQLu7qK8zezeJ3s+qpiXOrbCAVG\n",
              "SZ/nBURNpzl3Le4JUCQ/8kP63eqU3OdJfTCGcuDNJw36nMwmGYo7icj3AODAB+neXqrZYNZmzrFd\n",
              "wcFzvkfHV1s/eilJGnzjmTk757nVL2jf/f67/kGShRnDdSzgrQ2Irh9ADQvtf1M8h11xeUVTi//q\n",
              "pxEbwhbCiYkulTpQO9t+Ii1uXhUEfEkVJcsm3LfGbk8fRVfwCKlTRHHMlUGTj77190Pf9Pktr+7O\n",
              "6eaEn0KuceDZzGbxlJH+cw2wVHbG5Dl7xQep2BDfQJre9g5qKK+qu6+84zSjOG6lm/3i8iIE21NN\n",
              "jfIMtQ+vm+1rGaMAVB7ER2ZMmNuOQkub5OTvLVzh1pGIRtb3BKaPl/kh/W71Sm5zpL6YQzlwZpOG\n",
              "/U5mEwzFHcTke4BwYAP07y9VbHhrM2dYruDgsQNgpP2fZYu/RJ0SEDqxOw4x2DmZvqcT6z6aq/Qd\n",
              "nklrQsxQyIgTbU0fPbK1REIKIn4IPZV/Z9L1yGB2FExKIx8v4m2R63wOXOhVyCPiSKkuWzSlvjNy\n",
              "ePoqv4KYZUsm8IbpD6Y9fgioCr4i5La/uzgoySQS87jTOf0Sq3aCMLnMNsFRrfx45e8EHkbWZC3U\n",
              "zhbYOrCQBHtvmbkfcPCoEvE/WPh7keq5nuHy18BfjPYH4g7i0us3yuJxpxMbagQj6B5Tk7y1Pv4U\n",
              "jDlsEKnCZsLudKs3SkMP3wyzm6OgEh8nFRrA6jpEwNF1CAKyr4IcHty9ZjUjPUEX4+TCJH+V7nMU\n",
              "/YT5DmUUQel0i4YndS25g5qJmHauw/SGyhrOG6liFk6GRECbamso+vR7wggG8Kb/K2Jkd8t8zc2F\n",
              "Ewmn0lUEiaKuKklcvqAIFLMkFl9BH6eH8nJzUlzaIvkLfmsEgmTEevwQcsunTHpYrcSyUZJIJedx\n",
              "paP6JVbtBGFzOU2Co1v48cvddD5ma/+N4zv7VS60hBReJdk6K8nxxWvLrLkLLaPjiZqYYuM339fR\n",
              "+Wv6zkdUJG30QjYUTDDMKRduTwhxX8mmR4EAAACkQZokbEf//ISbcQBLFyEg02mr+m67Ufte1UYD\n",
              "qbXLK23jGzmnLiZcq/dZ7/aq7CH87pt14iITLMVmZe/LqHMHEoIIQaDXh6q5/yDIDVoZPW5+wFeN\n",
              "xtQdoCZrU4dD/cD4+idCLzdDRLGdEnYvlMOL1dDsBXdtEtQAUuTiF/1u9yQnrrIYmjOnd2l975Fq\n",
              "bhTdc4fcdrT+hoIZPl6PfAAxOlcIBYAAAAAUQZ5CeIv/Elqbl0LsYYVXIPxC6QkAAAAJAZ5hdET/\n",
              "AA5YAAAAPgGeY2pE/wAutcW+q9H/ABXlN2gkdMr14pfh/zfGdhgCnTi0sCk7HVMHBcSLJKATz46A\n",
              "0uZO01YZ6cGGLiOBAAAAOkGaZ0moQWiZTAj//IQGV2GCt0k4SWAIFmHDRMfxcg5+4cidU6V89n4F\n",
              "T8ZfNDlFMT3r9S/HzG+aubEAAAAPQZ6FRREsTwoNSS5fDimrAAAACQGepmpE/wAOWQAAAGpBmqlJ\n",
              "qEFsmUwUTH/8hAAL5DLvjZL+XfXAC8RnyfSb4CYCg8xkapLZXCP6CFvStM/Ke25dNEW8K8kvB3XP\n",
              "NS+i1rfwNe+ccC+9yb6bEX5PqZRXgmg3O/IK93p3O9DgZo5YvDkxxzz7+GvAAAAAEAGeyGpE/wAu\n",
              "Vpqq4XHVtzgAAAA0QZrKSeEKUmUwI//8hAAL71ow1icuAKlljZF48Mij1rBQ8Zkd7WaQlueY9aGQ\n",
              "tAr25WeLTQAAANdBmu1J4Q6JlMCP//yFeNngUrQ1WXgZEmBbxINhbEkWfkDkFawGOyumeUYXEUU9\n",
              "2IBpHkEsMd7LXxx+BH43u8LNVcTZ7V+QGUnKOzD+JgP+dw+dhpKiBo/SHqbXXgn+TlhTEfjq/zrg\n",
              "CAQdF6RDWCNbuO8cQHLyBYUGkJzI/ZpMUROA+2hgLcX2OpvZee2KKnT1E/YeMjCchY261KdxVwzM\n",
              "oeBFNaA2+n1rMz08qdrUg6MMRy5R/RigZg3KYT2CV50yxbUEHJ3Xvq1bdtkCYVSG9IpsUCbNJgAA\n",
              "ACBBnwtFETxPHFnKGN4V5240AcKf7wsS1vNDTEn5b1MdaAAAABoBnyxqRP8LRrXFQYPH8U9WIU+A\n",
              "CrSJ4MEs8wAAAF1Bmy5JqEFomUwI//yEAAuordR4vHlACHrM6gsw5GlI1/kv5RdVlTEusi72234Y\n",
              "Ha+8rZc+y82t+Vt+h4+ZlQjNxlA1N2yQgYK1MKIHk4/rJxaJiK9bkX3+ienkrm8AAAA+QZtQSeEK\n",
              "UmUwURLH//yEAAuagZ8mADghy32rB/2doC/5TZOP4C8+yx08pRV9wsAt9vjW1DHd4OqNul7h5A0A\n",
              "AAAUAZ9vakT/AC1qxP73EQBEAsgsTJwAAABMQZtxSeEOiZTAhH/94QLRCAG1owWTn8Mt/sAFweP3\n",
              "9XO5JFYPbMkksxHnXmW6JUOaUcEjLKQuR36UYJLR3kD8w5M6Ck86UlW7CTOM6AAAAOxBm5VJ4Q8m\n",
              "UwIR//3hBgk/mWqDMQHMeWCrB/rHcGR4v/eFS7JWoeZPyMFPNZSOB4Ua2KM8lX4AO/rkzQ2hwpPh\n",
              "w7KjgCGguWCI1SOwlZrOMFMQOSyWVmIen4rzfpFN6B/SLB0TmgMNVlmI7q6L6581sGIB9m8yNRh8\n",
              "bFuaN3oAFTH8qbwoCbx/aTBG10azFbTQGwk/5I3ukHBtCuQB29l7hNwsJR8yZHQS7smyDklKf2uA\n",
              "TwpCsihO4dHazIjLeeSvnLOYL0bWPfql2joVqaCBReYSGcCr58JTf5UB45pKx4Zpuwt7cK7ejg/D\n",
              "WQAAADFBn7NFETxfDKj3DyZgJKJ73b7WSjwiAIalodRuD23etvuHt7UQBU068165RMB6g6SSAAAA\n",
              "FQGf0nRE/wAtNdRZJRaAGyZEoQnkNQAAAC4Bn9RqRP8N18yfHF4VfOHKuHp2oAcNPzG8ZB3Xz3xq\n",
              "DsR5+atiT84BCJe8p/dxAAAAzEGb2UmoQWiZTAhH//3hJ6NWUAZ5++zegp3gO5P9QAzbHGs/sRx2\n",
              "tqMfwhiqI010NwxHlkE1U+ERcP7hT/WJ6WRMwGtfkxg1ZX6KO+ujA+BgQAuT58KigEocY09J4VHY\n",
              "8nJRfGom+jcqnGW0DV/s9dKmI7rbe+7GzgijWHh7RJ6Zj5dZhliHS0c0GVRkYgBSg6eZovREFs5j\n",
              "8ddhkr/FEhVIdzldO77rzPGuWcO5lCfXdOSU2l7KS6wcNScxC2bAfKq3XQnMSxVyiIvvQgAAAD9B\n",
              "n/dFESxfE6I9oJpc7D90oUfeDCJlZPJR2vAENsceQTxPcfju8qY8kumJW7uVs4AYyzazMu7FzeC0\n",
              "WUMVJeEAAAAzAZ4WdET/CEA2JtzmoALA5YY8Fr0gNgs5+AH+bbj2wIs4VKvYgm8KujU5eD/Bz4/L\n",
              "WraZAAAAOAGeGGpE/xWKu1QRZaJ7og0D0UAETf/YglVEXqeWpuwAvSLvZPrpO+qpU7yM9kBGRjXr\n",
              "tQ2oE82QAAAAjkGaHUmoQWyZTAhH//3hAAcb+nIDUtz/r3WIbz3t74YxzN2FLSDfGuigLIoTViMz\n",
              "Br3DlDZABHeWlORE4R+g4OuLGsNMSdV3NL22YAoH1fJnNQ3wDa3YQ28lVbk9vxTsBCCm2XMqd9Zq\n",
              "SmhKPcP/3mQyp7MWQVvwgsXQNH8694OjeBhYu70dSFhducL+zWEAAABJQZ47RRUsXwdsQ5He5Wm4\n",
              "i5p6yZ5cANMcloDy+MUO64zG9bkVsRmujs4yZvsepZpOyEyx7/0F9OEYSf2RHqJdv4A38I0Y4WHJ\n",
              "YgAAAC8Bnlp0RP8IKLyoOfxdfU2vNZt9ADc4CH2Ihc+SngVi/mjNDhLaJ4luBxDyuDPRuQAAADUB\n",
              "nlxqRP8IKLynhXXFGA7zUAEYIeJAYSdSTwwbdKR7J9/EhySlYCy2NKy45fI2fcZe/FEzwQAAAT5B\n",
              "mkFJqEFsmUwI//yEeQrPUAZHkVvUSwVxwJoopwPVEvU/DEtOXFonLOF7EYLEYHq7eUfs40f7zcE2\n",
              "HStoGdZfQTnAums39XWQr5jp4HyDfoJl5W9hEbpKui1lWgg0OlmtrQWnlH6rkRerA57Nrdou3kr+\n",
              "fRe7WVJ4zxRrIEgCf63Wg0uAFsTcLxJxtVbLtmjOC+xloIR8WYYJpcoVRx47IUEVBdqF/axqYqsZ\n",
              "yveciYuOReDlWQaJfYeEYVRoVTxu0jd505xQKsX/xoLQuw9E1AD4uw2P+vpl8nth7bFjWfsWLvgS\n",
              "lvBNKC3BZGuXgyjl4BCNypxhMu5VohgyOnNUhXQIi60Ex+XM2R/4U1yDgcG+0ooCUsYjqHYqUGNu\n",
              "Ps7AVKfsuhfdrIbu0X7cafl3MjuWGfsVL3wydpaM98AAAABWQZ5/RRUsXxOiQJc0o1HJMfBO6Sm8\n",
              "QS3W06bY+p3t5aSGn0cPl3AFyhOkUi5P5qfwFbpqBQpJlFSKxJcc12auNZWKk9Bbiae7ZS/CBSp0\n",
              "wC3zogrQn+AAAAApAZ6edET/CEA2LOhayIiE7x4Ar57Lcv7RUBQmzoUd9JKdyfyJozDbgOEAAABS\n",
              "AZ6AakT/FYq++4lLsqK3TG1x89LKmsqKADhfQn9BqZ2HfwFn20GKhV5Ytyn2cY1PFj7BKEauf0LZ\n",
              "U3zSMPICSB/BFK7TS+LnS3K6DQCCTxIhEAAAARxBmoNJqEFsmUwUTH/8hAHbv90yz2T+sNh4rVsz\n",
              "gwrYee95/J19g4t5ipjWy9+BunIIysXWYXczQ14//+SGO1bb6Zl4yXhpAXamBMLfYH64HE6jgNG+\n",
              "6iOsKku4wIVHO+lEwRp2cegzibWzlVjHcD2xiCk0EOv8iIP2Z4Rd117/VdNWehfJE3Kr53m7ZC1B\n",
              "nTa3e7R7U80BVtWQb6TMl0WIQ1LovH6Gu1p0FVjNkLy/hPwjLQ07UbPUMfxNJU+giyQHL2z/eJ+C\n",
              "W4LpGIaiM22rRx7pxIYdi+07kAtpmdAu8Z44eCv9SRKseg6vq/7S++EloyR5+Gh874kyRepcWI61\n",
              "miboITzztaTE3GpfUzOTmTMUT+QQImeS40JbUQAAAEEBnqJqRP8ISZuuPCPkrDepIrSwdvPuIiTg\n",
              "oENPHZwYqtXCFdxCN3cQBSiaZirvXmrMlw4iIgcL03jHMD2thwgUFQAAAR5BmqVJ4QpSZTBSwj/9\n",
              "4QB6r74gArQwCCff+nR7X5ptWxK9AXiY2w14vPyWyGDU7+xiW4nk9VyO81tWMWRHsQOwUaic4/Zo\n",
              "IueVmdVY3a77udT/JuPsmLpLqRzReAV4q67uFZ51ibIuan5iFh7Vu547/EQUW2GERK7V3AyvC2rQ\n",
              "KA0bd/fQ0dJ0sLNcqFEYmMx2DyRTG2EEAf//6nu4rzLZ6qPJJhvh8cSRu7mEm3fmHEDAFvw9oRZS\n",
              "KKIrHI2q4N91K76cUBoHVsSGWWoCZi/7mN1NueWl50lZ/mapjMzfG3HoLC7vSlIMaw/HRVJ4DLIR\n",
              "46sFim54jXdHkM5jR+fg5uTuFAOvHA41jHZ4F+hrgZGY0UjlrRg7i+9l4bsZAAAARQGexGpE/wZ4\n",
              "/WUnBLsoxZHGe3kVRc5H6r0m28P9EdDS3eQEKrnAYAoLoVJ4BHGD8h1dS41+H3/213O63HeimM8F\n",
              "uzDCbwAAAbBBmslJ4Q6JlMCP//yEdLd4gNJgI5Vn5yD5uMNITVcpAsqM0oK2Wcu8BWS3jK3o1B9F\n",
              "V25tGSrbI+gbCPWa9yV7ZnG83zgt14MyPIGXSD7MzX4LWs+FuitFdWCz4FMgFBXVWCvm5Jja8rLn\n",
              "FdRSortGPxIAbGLd8C7ss/gXcLzlVo31cf79sUXVQT76LS+hBccwVDZTxDYFTjT//tjVQxWd4+YJ\n",
              "uU+GnUhDff8Pr86bNwQOaGlWBI4xGsV2e1r5pRbuay6ITW91JNWx3vSzo0SeEDCd34SKByrDhciD\n",
              "avf9LX6KdR1oSd2TifMUcxmgLB+FpKIHEpO5XTBWDWCfFspRYugiQBGNTjEjsplTH+gRQHXAOVak\n",
              "U71Gz3Ku4/WoESW5atkn7E8EE/GNNvb/8Nn2rjc09tZla/bwreWaC+kLi4UMBoQDvFhkcDIQlnv5\n",
              "4xl5Zcp/IM0TKAtEsTkWk9Q3myiuHX4NL/jQpAIJpRr1AZsnviX52k9/YLni3j5jBTaspgwevrY8\n",
              "1p2NJz/LHMNMaj8UcY0iSPdFgYnXNzy1tHyY6hd7PioL7dwC5aZayEEAAABqQZ7nRRU8XxOiXSSH\n",
              "9sDKRzDS9kwX6QqbKsmADlFj19/zAnx85WDeqRiaIvrjoMe6lCnUvptQGDkJqoGwjSwccJW5pzdo\n",
              "RJHu9OAHtYrw8E4f1tj1wfabMmbnZ2J3kL27RIG/03QMsW8/gQAAADUBnwZ0RP8GfluPPEiu1o9A\n",
              "s1W3mP+TpRTfaQm0Ut6cS/LRBUcTGJSulzWcL+wUPLqq2MedZAAAAFIBnwhqRP8ViucYSBAu/HYC\n",
              "uZH9asu9IlrvdaIKoAatqWr72PO2xXLEt/CxKC1zWeS7v/y1oakQhetMRAQcZgSv3zAu27Oe7Q4/\n",
              "a0WPp9EeRbUYAAAA7UGbC0moQWiZTBTx//yEAdSj4zVcW4vgFiEo+7e4hufzdEjeYrUhBIPHINNh\n",
              "8A65fBKjQLgfmJ4TSFAxJQAezlPs3WdeCAVH4XaSXdnZWo8bOvMuWkmJBc8wi+9QC5Y8qRUWllFa\n",
              "rlXbaZcDQoQ1JV51a1OmpaLIS/DK7IlL/rQjXzbSw8yclpMw977+NXNY772vZjVb5wKY5CpY0TnD\n",
              "J/H2JbFRLH4LIClTaPpKYcRnZV3m4Wb7Kykd3AkUiKHyk1CN0o6u8r8k+ZS0WgkB5k+E/Ugi/IMe\n",
              "pJgfH4biJPhHKUXf2tkdvjVyu1UFHwAAAEABnypqRP8GeP1lJOMzPec0IU5ZsGxrIpBtolbxXIeJ\n",
              "nsKY7A/z1QBGIqZ3WZjB2z8lgWLd9GtomoftnYABmlbAAAAA/UGbLUnhClJlMFLCP/3hAIDSFawI\n",
              "uL5DOJfh7a6t1Qz+rZxZ+8IjTEn9PiXYnEKO78toaoS6+rm7RVr/SDj0rWqou8JrGOMPVO6lexgx\n",
              "70dM2mcE4MV6bksdceW2ImQdXrwQV65TdVSvZs4CmnxVEdle2h7h9784x67fifWanFLj9P/XfZ5Y\n",
              "RsSZ0R9Vy/bbAtCtOBRP/+feEA3KUvo0n+EIiKTIjQrbErnZTANF4+1pSumofgyKMy+i3n8renmF\n",
              "jBWPr0ECubBQDSA12sy4oyYkOmJoKD+fBymSdl22QQUv/fGPYyI2PXR/wxSLsOVRuz7sSq6OcvBy\n",
              "PzjcrAoAAAA0AZ9MakT/BqD9ZScEuyjFkcZDCL6HYeUz3Gs6AMKkhvVI4uJr5TInJnxtVwJewml8\n",
              "KPHr1QAAAMlBm1FJ4Q6JlMCP//yEdJzQCnGZ7chsVO2S2vNZC5czV6S43HKxiZVdnaTNJNGJzDJR\n",
              "unRskzLxAtuHVtBfUsW6N+DLB4th1MN60JN98bOV+iXDKbLDb2Q/G7+H2xUduRS0664eqAE+XtPB\n",
              "nISZwvWmo0xYjFfXw6FRK8eNTTREOwfZS+wHgY4xyhgzY/BBqn8QfXAhkZdGvxTfXc5HU+fiXK4w\n",
              "TUApc6s+gcyBeuoQ/R474jqhOuG9XPr1BceA9ARbxjifNQxefVkAAABtQZ9vRRU8XwXzRU+I6oMb\n",
              "SJ7GnkpZN7m2UXubSwK+9mHXDyjauhVqUt+3Awfp7JwS51M0J+r2vJ+fM6FbhLqac666UCREfx7/\n",
              "JHfCtPa6EQfsqrmKtWTxacI8NJDLMpSmZ/+VFPwc0hbSXANgqQAAADcBn450RP8GpluPPsIwB9Nj\n",
              "8NUUXuTUzxk9O6nXYNjn7FHvLFSscjVbv2v2f5PC1JT/k6Utzmt5AAAARAGfkGpE/wag/WUnBK9J\n",
              "OkTnTzSC95jYhByWmpeTwcRyOCZOeygCv102Vjjpc99hrU8EED00VRtYZokGz+U89IRDpMEgAAAB\n",
              "OUGbk0moQWiZTBTx//yEdeyVAFFcZ26hbzGeoborFrrOEgIztNUE+xZwC6N2IaPXYTsb9SduXaZa\n",
              "EvZWDXC5bo6W0MSuPZzRctY/gHHlKYrv8xGBte+AWYv8VkSQ/8380pmhZFrF7nXaNC9Fq0QUrQGP\n",
              "HorFm0oozvURX97hgp3XJqcMZ30XHaIQ01jbCiVS8qwNDAM4wcM4PXMF8IZV2FDi2V7l9SzP25zy\n",
              "xpstqn8QF8J8cqRWTflbwPQxQli27Tb/khCNrK5tyfIy2f6cSC1tRDpjdrWWufzvn1denFm6FF5W\n",
              "swy/c8DFvY7pTu529RWQiMsU70kBWDX+j9l0m4NwTZ2tshmlQ7Z0PWfgjhdOLFsIIi+jLmhJZ7y6\n",
              "5bjbpKzqxBJKX9bZS7CYbJRq5rxYozRB0aUzgQ8AAAA/AZ+yakT/FWaNQDOr4m663G2cl9fdYGwZ\n",
              "pQYDTfWo6tCmEOgiWEmIApzcQzJng+TS0b7Six5gaNXSzHqUkWBwAAAAxUGbtUnhClJlMFLCP/3h\n",
              "AIgWDLfmYqv/iaV5YMH97WmiANiFquuqOIHmt4qDQ7+j1qFPSnjFvbsKsutzHv+klrLkS8uNMh93\n",
              "qMQ5XrxBxE54BrjVWRI1RPIa3cS456OSf+nA9I3p6QnVuf/GBLBHuTlW/IxLbCOqdYjct0GC2VPY\n",
              "UuovlLOK5wZyUlkTmNSTi+XG6BpGWV7qnKobgsSowlWXWnI66MCVgNQGZXvPUZdl0viuKJMT5FYX\n",
              "/uAyDTwgnfbEJgSAAAAAOAGf1GpE/wbI/WUnBLsoxZHGQwlY5SFnZbUS2R7KugzMM0CIADclKhuT\n",
              "I1KXe3Rmzba2MYkOesHBAAAAeUGb2UnhDomUwI///IQCAuACKTIbVdmgHxbVU/hdW2aLzrXEmLAL\n",
              "hJvD+3nuTloNZMxtwWiIUOVcCmVcKHbhcVimZbb5Naxzp27dKDdcCbg3vI6rSZXD7F4B0+Tqp3eL\n",
              "HCbybWQtIpq+nHUZvc7ZMzzpDXoq4HZ9jzwAAAA+QZ/3RRU8XwYZ8ojntcMbSJ7GnvTNyZSLY5kI\n",
              "2vMPHgbFuwDJRaNUAfZ8/VAfN6Vk68N6+gkBHk+i+8FFymkAAAA+AZ4WdET/Bs5bjz7CMAfTYfvN\n",
              "F1T0eZ9t6BeD+hBx67onlm1qAKy9CP+eE0+2wI+AVc3KdvYka57PSwCskcUAAAA/AZ4YakT/Bsj9\n",
              "ZSTjMz3mQnJqOPVqr0t24cGIuJDOGAAw1ALZSc67uuNCsxc92g36GCjHlVn60r1PK7HWKyBzAAAA\n",
              "qEGaG0moQWiZTBTx//yEAgLVmHW1ylskDHug7fMM+tZ9vzJeZdG067jM5n1+hrXh3DZ0OCWXM8sp\n",
              "te5WkRA6Vg0rx0T6ane8vs/YjlAQUnnhEkvnxB8+ABrAmfE517ixy3iG8aWlUTnRVJYmnimS6vSc\n",
              "yRKg73IyGX+rNci5ZvIeKNVYIUnotp0/G0uVHamIowB8qcHSHO/S008PfZtfBLNZaxu1umHqxQAA\n",
              "ADUBnjpqRP8G9mw8JT3MUia6b/QNxM+x481N3kJ+0kRIzHAc3iWaDrvSZTT3LViNBB/I3PgNMAAA\n",
              "AYpBmj5J4QpSZTAj//yEdJzQFTh+kfpu/hEVBhyys2U37EZrvZfpWneKurilzEqDTUwrmX1HJOH3\n",
              "WGrptLVl74yrpJSgbfXyG5pbf8G1cZgXeEgsFvuDLmNTJMc0W0t81AgJqcC5ZmueN9ePlQvYzYFR\n",
              "9IVi201Vd8oIECKzrKjvdYwWmm+jPxKLCTxsxxVuu9EVaykm9G910a8DeRYNY4Z9LdlaqBjdVBwI\n",
              "KdPEpfPBhHgOMBYALBN0T5NFJJ8HUx7u871jt8T8cl93FrT6n6Gw86vvFh02rAcdKu350s0JfoAQ\n",
              "rTUK8kkBTPJEAeJwdchZ8H135yU50Msim8cHYoaM+zYOhAnRmOPjPCtuzq6WStNDeBo0Palf08pQ\n",
              "V91zRgJL0eRBZwQz/4LrntVevFb3gcVLrtLtZhzgVcdWQke7+0KFyx07GUjmMipB9UyGa/KWbOmc\n",
              "0R9xQ27tYPe7TKJp7ECQcWDy/w4Dg4iUMPCemSCgauKlaMj2EMOqU9iaPXE7SqyBUcEEbqx5AAAA\n",
              "YEGeXEU0TE8NUHsMrfjxIQu0vyDYGb3XGjLnh3c5/5SnlcS/hshwg+O0W9jcAR7RHCG7iP6yJjaw\n",
              "pqLfPkC3MpPRAmsWkPzim/7g0XSxmtRXj77AVHTNlIL+LbPdy8tGQQAAAGcBnn1qRP8HyxyJxkQg\n",
              "g6Wuho6gf2ztpMwqTTJ7W67xQbcPGvGIA+MXqBGrAD/zkhht6/fcbuySQJYTQDTSX6icctPDFDEH\n",
              "EsCY0fJyoV5YsO6jpqOnnSPhzIdFLPxAPGYxYI0zUBGOAAADeUGaYEmoQWiZTBTxv/pYBWWzAx5d\n",
              "cW8AIwpnZEXbEbIjOj6Gir5qFTgrI/ohX4dcOFImDc2CGsWecy6nxHToOBQm01qdvbp+4x60ApQp\n",
              "8fmEUQHgzWyce/eQO0DJKOXODN8KRxDsbywVKQvTjQgkA596RpdKspgPninHntDMQfwfrkCg6uCn\n",
              "/sa/hoAobfA918ja1eCoeOKBtszLrzOF8hYRNJv5uH9OUp2K8DZYTUpNcliK/+numD7oz+sqUVXV\n",
              "iWFrf7uehtM/IQHTiDhpeja2w43bhbcNQa9dzGDgQD/F2Z9Fir2iyVDU3LtT7hNbqHlPr6hVm5rN\n",
              "JGEFHvTKCv3ni62fXiRb51yNnP6lAx9GVMoyZuZUcxUChiz5I18q0fUh0+xx8CVkoeSZtm/CYpoU\n",
              "bWXhk086fr/eBnMjwPAzJnyV+bJIVoFJqEQw4gffOBln67n6snqjXBbQyV4W5URCN8wstHkr4VDT\n",
              "yMeeA8CXpz/wAgiN9i70aD5LoRjuPelwtMOaQyTdhrSJMqOutMjUuBXv4UkvHF0ryPaWMH7WYcUk\n",
              "hZaLWXISNYfDNuqdO+9HAxpRCjwSmaSY5rEIo6dXv2GdMtKUrPObQyFO9kWo5J8CZKYSEwkkgNqN\n",
              "+STjaZeweeFe+MPA4sXRGPhDMnoIHY/t6m0WDjEO2L6t2vtRkJ4wz9b72UuC2D3wLmmHWaqc2FD9\n",
              "Q0w9ZyeshNM+V/JWujisO5vbPznE7/0LPkjBmStI6cOQikST5ksFl2PTbMsmcsnjh6UIewnyyB4I\n",
              "B2ZjCaErStMjJM8sEKQbYgjrzsmxP//74mMKYcENw6zpX3R84P0CC5ZArpn8u9Vt20cWoEnKgBC6\n",
              "T+gpjvddA0BZK2ocG3Ycv40YSWmeJMmfguhDNA3QZxK7F1lY2/KQYfmtZ1FgHN3R3xwbh8Iueg9H\n",
              "/3WesGR700hvDFZstwGhAsL5R5d2mR5/2KtV/8bE8FECzvQkg6Ejj0Wr563gq9V7R+3Eo2VvUnFn\n",
              "ZchZwIyJtOSdHZLBl93ibSJrCwX97wHVfuqlbyw0rRBLMcz6/H73pHpRugBNwlW/4LgUyhr8gKZN\n",
              "2ndiXYJF3RK9HGboQJQDC/FwbJN2gdMG05+341DtABftGIVassGuQLNU7mF0RcgwxU+4G+4zZ2wG\n",
              "5PNmVNzKyW6mOF2NOUMAAACGAZ6fakT/B8sch7G3aSGQq2hlPkF3lQAaY1m8DAtIdLR4mFl4wMjN\n",
              "zB9/n8e9q22FebFazQZ/FB/7kgZ7LUClDbrRw4EEKe3zikO8zjGsCRN9xyR75XqkxlXGh4eZudEZ\n",
              "oH1K2icAr3XpNoSWspM9CTXS7UDtsJ240LKRoslEMVgAgQUTjWsAAAFKQZqBSeEKUmUwI3/6WAXM\n",
              "OBkmV5OAHEObY/HvCWzASW7O6AQ92+1L26VO7EW6pIJKxtf6yksBSNwMIEUjMDE4v7Ewmus6M0zs\n",
              "ILRnTdlOk1Lb988PVnRp/tcwthuwS39e4wPG4+3+DnxFBaUZ/07dlJlZm1/meEM0HQkeD7A5jQc8\n",
              "NPuu6JhzaPtHK0KAqj56ESLJEDp6IqRC0uGtgCJWjJPxFwwZyyjMiP/xxJ+V5XRlsaW59wjYKXNO\n",
              "w30Zy01eXDJ68qawbJ99BzWFAh5zhEbunUVCMX+ro9ECDV32kiSiUGxBZHVlXOqinN1Y+Fe178HR\n",
              "Ek50YuFyBUDka3mzM1PBwLFTJ6HfHUxLF7my6ODXLGfwQHU6F8yhpaSUUcSCz7UcQqycjhENrwsg\n",
              "LtJydjiMF/vEclBTwytgkcl9VhZdToQrju0xdy1wAAABb0GaoknhDomUwI///IQDEbmAnWLgBEhM\n",
              "YOGaXAqgGThSNeL1S9PDzXOnXf5q61ruwBJs7LnzE19mFeGnE37usOxSrtrEtXvbXDYqDKpA28yB\n",
              "zPEnYg12LPyFGpDLnI88k7/ch+ixgA2nR++yGxKDmHEYr4Uos7IpztS+tLW8nCy3G5nCplC6jmqf\n",
              "7f4JhixYYC2dILLzaBA3FiqxtfWtfT1Q1RQszRMrW4hY2k8a9uXtf7/DSusa1hUj2RUswlbYKBvp\n",
              "pzVEG/EGrvZUzJoIdc0f5L8FBvad7pvvxYD42d/+t1kueYY03N05epqRi0hfda6i46wuNfZbRWSi\n",
              "LeF+eOx60wFofAYtQGMmDl7e486/XI2+u0xImM2VH0Qv2+gsM7ifvFS8WpC4YGN1LcUJzwAJaTqV\n",
              "iCU6MDOyiavsUEcPUyc0wu632JqBo54OgJCq3tuD7RpAes8U73ZV9T3JgCvyELRZJie7cxaBY9YE\n",
              "CyEAAAJBQZrESeEPJlMFETxv+lgFxD505QCgmEjPUoURHA7WnAVKykgNPO1Rrt1IG52Rt8Dn+2WK\n",
              "gDdIm2M+wr0D05X4YXPhvKokIf8lvC0vY90Fv+vQFCnh8zk/QgVHL5KJgfx9zuEUjXblaXr67v7d\n",
              "Lewwfshc9sdCgWDjFKYuHHTrfOb0ILRyAKx5bYZYu0bXc4tAAOoGB5Fha6C+wlpNF2G+sU5bVCUK\n",
              "F20JxSVKV7KkDOKB18iJ1n6FtZKru9t8MYgP74DPzjoB/Q9Fb625F468wEYhBo6S3TC/cOABr9wd\n",
              "SL6q8OIqRLeshBaNnJamm4BKAKSBsq9dOPE11EbRO4M2nLao6a0JIpqUR/zBiyp3SfoWXmdfeCdV\n",
              "t6X6OEXYh3SQz+4VhEt2HJbc9beRnN8rEoDDsIC7Lt9JA/2BgL7t0TpxTSKazgYIA6PvJ/DZwsfT\n",
              "A6hbXSlWm2usOOhEhOpEgf9l661VL2xQtEKMhB5PUN4Fw6DvubAKCjgf6U1PxDLYhWFgL11nQ/h0\n",
              "k1F8/yXzFLx1z3zBTAJKNtCa65G8nohUEqiwmpb2HZ6/X8ZGzcFQAgCfDzGWjPKVgZFCsRdPqSE1\n",
              "gcV9oWGw/UX75gji4zyJMqp3Qo1mEYAc0qPFem596rLwX2zds+r7MwGmnOkjEEWhmQsNPLgk+GqX\n",
              "pZVHxj0qRb/+DsoXkq0GXhNV1zfBZFIvdF7C/TfyzYQ6nzXpwrK9TZIdJIg08dWAc7cF5HoF3tNW\n",
              "G9EhUjjgjMVgEii8wAAAAHYBnuNqRP8H/2hwwKfcVojRZie96A9WYnQAq+2MtIbu/ng/qz9WQHN0\n",
              "Iu7SADIdwW3XhufEJQmdoqqzCzKeNC7VZsmRRLuMVE4T5x/+eike7qVw3SMmRhdPNYZntLKnv7d0\n",
              "NPGZ0ko8t1v4ph51TxLX5dwAahcHAAABgUGa5UnhDyZTAjf/+lgFxAL0bc7gByJei3NTyv4j6jpi\n",
              "TESXwZS89iUaZ8D7mPcPczAATPX8gCNb7P3wCYSOSM513/Wc7lmzFGiTRGuVjTbYw52BDMXXacfr\n",
              "yjdI0h4FZYMiBoU+d0N29pHIzA+3RH13jaaoOqbN4L7hEU8XXhAsRvu1a9SEv7pBwH33le42i1oq\n",
              "PPrpPDnNU7WMYJApEdMdm4BWzdAIaEEFWs6QNc/aAyDn9gQ2iAIr3p8DUa+9VYNbUF5XTm9s5xMi\n",
              "9BA96ZEQgRulw6qE9uRjX2SFFDPMM5Fx29wdNUVQ5jRqv6m8aCIGb7cVkSpJ60LtZRfKQhnbTD1+\n",
              "DXBvw9xaLIjCp1NDSbkUXusb/i/m1oRFiOeLJcmdvE5Zn2jEpnBvZULu/OB4pkPkxIcVbSaDpbm6\n",
              "jTOCsvbiajzec2cotJUt5Cgvm8nkkI1iOr4Eu0DOnvasFhV3x+srASYdxgFUge1sKDYoVVju39Ru\n",
              "kQiPn49jwQUnEEkAAAF1QZsGSeEPJlMCN//6WAY3OeL4J4wANcyhycyTkLMsDXTE1dzsEGH1Kqnq\n",
              "DyuLJ40TDVB7tadmKouR0ZkI2Ytq2n8CzTIsB2mXp/9Ccg6pbNsyd8tFM5VY+gnmMN4JHau4MecR\n",
              "b3GIrU/KQWfW8MEPjsQ2hjlDAaFvLAQ7rKi+LlttmhM/UbHXXOPc9UYnVw1+Qxrr7JMQFPZPZ7hL\n",
              "KP20JE+B3kYz1Y7m0Vqfml9KAIV33OilZBAFnIWqBfCO4E2Ca4jqThDSRP8uq61J14h9x07Up3lJ\n",
              "J8Mz9S9t6qzHDdD7PIntjVdP30hAMiUhNOUDWzYYU4G6TwUYf9JKUe1j0l5BzF/xats9dBGrk806\n",
              "ChyiFdjiqYJog7WA1pSmMLzuKQFIw9D+TUYS3aTXwjuMxETEivEoY+pwgWrmm3HO193UAR9zAMqy\n",
              "nTGfGSdOv1lba9LfEJqMkCHFtO7e1b48VgBtRQ6Mj5OVYp63ovgXNwjCC6CXjQAAAdJBmydJ4Q8m\n",
              "UwI///yEA0u5/wBO8ExuD8qMABddMGc/iYref5Qfpf7GyRwGVHUBewcuq7LU8iw14sgSWaZFP4dK\n",
              "Wu161p10rOGfx5LPhyGLSugf2LQ+AhviPgt5dexe37XPqLEGyGUgtkNv43Mflk8CNvJY31LJX+50\n",
              "WFHrmulpz5nwvsn4JIB6wKcdh4gOuPhF8keW/XotxT53UEqpyw3yvDi2cphWDW0hfdJtB6Gjpe9d\n",
              "ibrGEOBKVqIi8Yzjrubx5bpSY5nFErJ2rhMVrEZZYxTlwctMDAs5cbMfyrKhstC5/F3MRzBZ3bVh\n",
              "aMqEreuhN+MXPbXOYLqQK8ytGJ+j8aaPAam3Kglw2gaJoWH/DGfJw5edDAwpa0F+Z4vLbAEk4Duu\n",
              "m2aco9x0ZXhDYoNnuYo2hgwU+k68cMhMQrlkggRNeZGw04m2PrGJ/d/s4gchex+ye5wP5D31CxoU\n",
              "8uaHALIpvEkQkM+Z/gSkfBxFA7vEfOkhJY0Iy22ggd/JKlc2f4yb8G+1xMH8S21KLhzDEesucBgJ\n",
              "RLOWY/Mp6yZ1lz2YtxBAW1s/g1GmtOPs2YEdQb6ZKRhEXnevwqYmTmB2bU5zx+HGnOg0r1o4J2So\n",
              "DTp3AAAB7UGbSEnhDyZTAj///IQDTvfM5qCecPgF6BZem+ilPyftZvJDjwSOkOjBcA6zGKPUoSmn\n",
              "qfV3+pBVNQO8EGdiekdGFxMqsxbR/MpMNJnmJ0hquZdkO0CMvjqsoN6lGvjTAIN/LHWVYTmz/zl8\n",
              "d3slcBPRoRX7sAb8xVVy83IN+flVIfnAmlAMfkPeC+DTs6jQPkvU6Y/cHU+e94zV6Pbq4jp0rJ8Y\n",
              "uuqfPmdzpzFtMoC11h6PTwlM7kzXgzq1yppHdmhsG/Q/Yffw1yf0ml6bz2bncxV6jOCyeiD14sit\n",
              "8CJzdGd8gQmc/ZxU/O70W8EpGYe3DzbLw1KI9xcbLW3DWXLkn7B3Dtj8vK0BHP35Wq0/bOiPHh2O\n",
              "j9lj3l+FtQ5+dV21EZzWN6TpMdVVLSUkMxBsyM8WiuewROjn+mgJU/zpQzYnuTMJOPFU6NfbQ6P6\n",
              "IIQ+pTywvhSPz8rT1TGMreJYF87zkG5Yh11hsXaK1q7y6Ee3j9UC7aSNDi3U2237kuaNpAD7fMQp\n",
              "cbb0VC7fucwxVfOdFHzPf77UxQyinWY/6LJkc7haeYYxpMTGqqJMwbqNddbQnVRJe9iKrEtpsZWY\n",
              "l8zr/0YQebXwXrYlwYLAdtyyWsxbWYfwbSz1e5s1UX0lpHInHsbEkVKkSf8AAAMsQZtsSeEPJlMC\n",
              "N//6WLyfoAdcZ+Pz0Hdw1L0Py4TaGDdTez6Pf1Pk9arEFPgXPMNcP7KavSxwp5C5vy/n4KFerOK1\n",
              "JHtm87w9gnxgSj7dVEQxuWVAYkIMzRc2H3DWhZUhb2TpFg7ipEU0DLRtfrUn5PY8G8KR9P5rCm/7\n",
              "3T3GV0x7oiPoSlz/PN1VY1LA1rHQJjvs0KeiloIRnyuFa0L+uLlQ/4HYk34KTgOPkDqKBJ9vQKbv\n",
              "QvqzQhXGsSiE+zynvVt7LzVZg3zLOP4u2BdjhbfcGc/U+Iq4Xu3yI8+JvL0nYMCBTF2EDYoLt+6i\n",
              "YZE6Nn53yPu1VPw89CR3Sq1l8pNwD1QVEeLIywlO2Oho/niSDsW5gI7+g+aN8Djrm7BeeD4Lr6Jc\n",
              "gdkeWD5mWrGxjlloa+osx81zLFS+x8+hqc3doir842e99ftSlf9vpts7gdXkuzUkzCegygYIRb7t\n",
              "wXBTxx5f8M2UQjQwJS+MrV+YcfO26fdXkoxRgQP2QQh+SPbOPIZ4kJDiVLQbsH78noJJiqnxysi6\n",
              "Mfck0p0aUZ0uCJohVZkSVq44Ul9rxV4yhQWkEsQ2M++yOOL5a4qNnA7ERdgMjxcqELwRokXKX3Tx\n",
              "OePrKb85kkFQlMuceCeY7ZzPgi8OqlfWdnr5QspX8gUotixe3zkCof5h9GHQrz0qeGfRkEDayenU\n",
              "M8JOWw+2eW568DigmZdKoDSAM/v1FuRPIzJ5QeGCG/cVNhzuP4RWpE02secMSEbj+SGolFoHhzdU\n",
              "opiYUpkU8vcaifHSLtSwxDuv1h5c/4w1chl2FaXKy3VoDHM7FKffxG9j0svPuMnCsPwl0GQFoTXk\n",
              "ZfBJSy+9PbfZX/LsybB1vsbdl8sN6AA7bUPlNgUbH2XZu879JSjFTGBmLWV+l4VXfooRuF1cL8ib\n",
              "tFpJ42jDVZ2GHdWhtiiD8aDoymyTjdzcsqHUPKmUWN9D5Q9pOIeK0h35eIS2tsrW/LT3bqulviK7\n",
              "iYZchbOy2LjDN8obEcZswkHDQ9R+9XlO0IU4m+gFhny19WHqUQbPq4DXmE7cvXQOtJ2EIoXwVCsK\n",
              "A6oJdoAAAADjQZ+KRRE8XxOLCS+X9ywV+b0cUD2UVzW+hlJ+F0TcCx1YbPKQeel/97qAApHz3BTc\n",
              "RgiVuJHPVAeAAEznSc8uSdkb2B4V8EHD7S4KkVTrNY0Be6kvQ2wJN/SwE9ePu6ZaBHuS2gDRlRfd\n",
              "oCQs8180qmWhoZdxSzfC1lIHxqTTHC8z/k0AL7Fyr4A4wt+zX2uEaDjfnBCIFcwC5UXUaCOZpWe7\n",
              "8Er7EYm9IZmruEVS29dsAUSignnVcsloWnWM6c1kOjhtRYHBGrmhM90C6E86U/RyEJTDMu8RK7FY\n",
              "ojDXNKpIUZEAAADHAZ+pdET/FVm5EBjAaz1EGtgrLOlo/dP0OJqvRUamSACIkZJ3s9s1S7DoTBon\n",
              "YzuK3isfay9anEuEKDTqxhyDp150MdMso/R6JB1u0rzQOLpL2Wa7KeIulbXu2z4PTOj27HyleEFE\n",
              "tfvfb3OUKWQjSGpVnzE006c3jyH16NGKF4vvr3YMXDFvk12lEgbars3i2NpDk/gaZsMTD7XX+3zd\n",
              "kigHLpJgSkWmjciNzeq5UUfAb+kNNtR5K5YqqxMFt/uA5hv3uqdjuAAAAGoBn6tqRP8M0+ZvTwTX\n",
              "BpoO9wDkytEAYPrPG4yoAaJ5eDDPgYbShBDWe3zBOLz58dqR8toXxl+RyVcKSfal8sHAYB4TR0Ol\n",
              "A2XUFPMEj8fvd95Wfa2/K6TIxfGBf0lOldL3mWJQeNeX4AWsAAABdEGbrUmoQWiZTAj//IQDjEOp\n",
              "hjyATB5srXldis3l8LNXWtyOVLGY9sXgEDtOdXxPqbWO5xp9R+/MJR29xYbPnmdyivPRdlfoVfto\n",
              "y7YRm8piHmM7IKqtqyz0l0bqd/gh9/QM0tf6SaeBQtVERdTWgLPxLU0Qqi/L2UARKm6AKrl66cMK\n",
              "x40LOupIoJ12UtVaWuDT/jfqCUEhU9OZ7skquveaKRhXj9U39YXcyxlkIopR6AqosYOrJjlrKpL0\n",
              "vGfhWsA5KSnVX6CyuvIp2LhW+zikjWlIqb+jTCH4Gir8UlA6uzkzPCDQjK7b99KOJ7918Cic/3ul\n",
              "sHEoMSPvWcGXxKBlSGGwyJGJCjKNVneYIiiZISVFF3eiBFY8cQ6L2r4Ht2sxF1K0QNnM+24S0YEM\n",
              "JUrgZU8iYgNEhgGF58EzfaGkkWrhFYGq2FEXLr+wO99bbm7vP9mvyI2nkKJbQ9oiJhVDwBBlc57k\n",
              "KCZ5wRmFfHfUrho8MQAAAdNBm89J4QpSZTBREsb/+lgGqTHbw44AGvLTx2qUqGFCYAJGsOF/yL6H\n",
              "tPq8C96D/C+cSr6eu6/98XwMAiYrV6qQ9Ns/9Ekw0o4MTX9xgjUaGeciMMVCVRqVdR5niTWhGNOQ\n",
              "tlDNmuzEeH8jZH30r3d+lWZ5Sp6cC0yr2+m4IT1M49hVxaPdZIjnliHZA5cF24XfQcs8l7KJm2Er\n",
              "3DVWVLEsJIZptxiyjns5AAnPo7zPbFoRCOZq8j0bnOESgmg/8byBMKnl73/9qJVF5Xw9SfFoqwQR\n",
              "7MDrf2veS7HG48Uj8x+Au3KWSiof6L68es3zhuJp5m1u60qY5t72Yk+2RJq6S1fHbiqWaq92qTY9\n",
              "AtOkuzwZgPJMc3OiHNRjRzYRU16MkSUZN/oXocosaUYAVn5u+SzRU6OwlwjKNMCVCNqdUEyPhcQK\n",
              "eUHC6bQcqQBY2fBfzep90JcQ/UvpftSurVApmnVtWhaqT8xlV4YYbg6PDivmr3BIM+RKGBkhcNHj\n",
              "l+JNCYDiZr9jtfNKm5I7G4JX3OXjwd3yh8ND16Mg4H8cJG+UStMgP1lxGqvPZvqUBfH2y6SZfQl0\n",
              "PYJ3DUphdMoZIRvh6h318C/lRygwR7pL21G9gQAAALEBn+5qRP8If2hwu9tTJhJj8ijoCLufZZ3T\n",
              "MlAEYFpXDwJLzmm3g5GayU39d/+pfutdojrMcl0/v2IvHBHWS+U5SCcWa5FDQc68MGAkCqwIiDtD\n",
              "8QuHQu0XkUY7xgBBRfB7pRi4LF+r5y+e7h7cW+L8o18RXI0BnhAkMFNUIAYABBSkWc0O744JT5sV\n",
              "N7DsyOmVU99oPwonUa64lm93+ltd7W4sCqdsHjjIo55lMUE8ldkAAAF9QZvwSeEOiZTAjf/6WBxx\n",
              "wWqBGNpR07QKZjWNFRnNO1U6rjlEBXAbLFUIkrE9AHnR1GkW4m1C/z+pabckR2Owvtde+JmOj0TY\n",
              "lA0MGXhKmhFPdkQIDLcHMhaCy9bqgPTwXB/btnwZwSORRfW9oCXFEeUr1BvvrXL9kt9a080Fl5De\n",
              "Wc4NX09X7Vfm6OWuAhKVH9XMmXKQiNcUoVwOColyawp4pD4ZAs/taYj89S4MbpZWWM8M2E0VbcvE\n",
              "K0xPg/aQG3NAvtifR7+r0L3N0maVMNi1hGHwX67PAESvslPrN5hHZn3AR+QSBNd2IfqvF6fw28o5\n",
              "ykZhwdkym6kQIYpOtsPz/unP9chgVdLuUyvlZ3cgYQEiq5BsoTyi48O/L0/0SmTCJfXpXSbAcxS8\n",
              "swFVCddsOVQejWvzhHERouzQaO+aL/pKlkgRugb2QKw+AEo/g8v7u4jms8pygbHb+k2Q0bVVgIQH\n",
              "QOyh/9ES9xntcPZwntIcMrZiyiyy7GlwAAACvUGaEUnhDyZTAj///IR3+G54CWkYhp/2qewzBshE\n",
              "IwcvdukhORbiG8f8XL+afGvvo8/DSUA6lkbJQQyWUNZqMBvBjp48FcLdbGW59KnwYWBH1pqhJhlh\n",
              "vZiJlFTTKpv+Ide+BAlAo34zRCVcTwqT+b+v9UeA7VPVy8PROnT8ES8ob37ZWO0eQWn0WsNjprak\n",
              "iJB0TYh4dsK2WCBtL7qJKVIbhw+honrZqkDtJy91b6fdmdYz4HVf5hYRdjgNfss4MdC/dy/Ff7Rx\n",
              "KSzJ+kpmRs0CSgnkQRSlj0IpdNhYV9sbVDC1jwQMFBjMKk35mKVul9zHiQ9OISs1C+wfv7E+Dpu3\n",
              "KIPjR0sxdAUKB6/bVfnzcLcnD0Gk8tb3EWZEN5STsJaEnDkM65Y/Stu01Yh7rADn4CKjQkAvUHxq\n",
              "qoUKVwmEPDzMLG0OXfgpg/1zCPIznP1Qb9njwln2Jq4vms3hxHUQ90FO8qsgiZlwjxX9pN4l5CnE\n",
              "8megFYuM9N7BeCUY7lkVZZj5yDkkwnRA4F9w/dQkCDXwNemV9hX+DeP51/FBdHwaT+yLZeqejVDV\n",
              "6hw5S9oCB+Un9VNKbwEONpIRBjMxDLhx3v1CgweFnM7GcjFwAiE9VHnen9+Bl0wsS4qGXse4QF5u\n",
              "YuWhhRayJeESiD1qIWMhTS9rQkdWgDkmACCWLX5NSrtSSx7zRBt4UsO5O6ewbMUiY875eLFC2gQm\n",
              "QMCgLi7LzeM2ZkT3FI9zWO5S5+srb1D3VotqgbTNVa7kvFS5iOEXV9Q3UCtV0P5D52zBWBXwi41t\n",
              "IGpG9WC/YGX4yhW2286SH3FWroHXgm9fFy+QXKk+QGbg6gvI2RKKzdW5ydqxChDh4EKXbdVoHWXd\n",
              "/JYZYqv9ZoOHp7fpqfkBLGdKVPIp25eGdpd3Hz0RxdmVqXGdKDekyjmdOluAAAABjkGaMknhDyZT\n",
              "Aj///IQD04QpwPiSQKFbr53ACuMXgvVmQqOYaWMYVmNzzODW1tosgqU8QDDyelIWFt2iAJsdqRw0\n",
              "996LNjxHipbtKK/8DHeYxe2efw9h+AoFsajn0xT098RckfpVJkxfWfnk118Y4mn/KFD4XGcJogwQ\n",
              "LLH5I8TDHE1Iy6qMSkHyF6uJoYnCCTCXLN3P3Qi/FiGYDWoli7i+9j1zLuib9aTgGyWZaxYXkgjW\n",
              "3JEEwB7zd9ntiqfzbxvyCl82rTviB4wdb/ra/ooRTYbX4nwN/hkTg2zozd+P7uJA+E1upgogAAGk\n",
              "yvZaejogvQalEfbM72MezsivqVrMtxFEGBUs1WiIDD+zKA5GQaUc34S6TY5daSA7pRyh8fK1PsVT\n",
              "AzNWmOWCxIQBM4P+SDUlmuBgeNjUKpDsGM/Y9I7m7XEyD7psxtUSsJ3RIBYg6bnkW621clUC+KNW\n",
              "bRbh3Qi7PnYL+gWEocEMUl22+t0BF9xzPXJ+d2wNqz9J7hFQqPCxhr2i7LJBShx/AAACi0GaVUnh\n",
              "DyZTAjf/+li8bcAcSDHcZ+jBQoVJMgrzIDz2ydwTwNkTl5Ls9tPu2SuGIVS1CFfEHa6hWoHHBQo0\n",
              "04lYv3aHzrrhSFbRSQuXPXLey6G4eMR1Z3Up98Hh/BgYRoOEX2TJuvaGW/tnuofLW73fRqMupLbr\n",
              "10n3luk98N3ua6ry4otveGg6XJN63yOc3b6DAhu6Fyv6q00133CmPqReKFdgBeeW9HL/+bXgOoPo\n",
              "kgKbhYRaw1m6hCGLx+hVmnaROqfc9tvSdbw3tsW/knnspd5E0F5TDB43U6aQbHdndivpQbP1k2fQ\n",
              "TFYn+C3oWdVJlPDslvOl+GSoXIFoMZ4Kxg39cF5sTFIYKdDgN4Aypl6PSfNHPTay4ioGxkuhzdwr\n",
              "e+ng0+6MSvwlUBm/RZ2BVkdqgW9rCIbK0utMUT+zEqMudjtvsoRIgeIWXpLS+fmGvuU9JjUstKhu\n",
              "qBXQCtQGa/Sjf3qsdR0bMlmw9z11fIyhIquh+XqbZxoinWlA3wumOqt6HC+HDFQOUfnfMFdUDBhX\n",
              "JjcQSf1+rmcVFeGgI4uOoRrtsoJDYJ83Co2kqhsPzcSz/PueP1QGBogEKRsgPbyhUhnnNRdtwLhD\n",
              "kxsNHqnziVU0o8PwUeUWuFM6ZrDLrbEjWHcmfKopfCTjVU3daxFyeM9MKKM9gKEz4OHdWI6FK6uF\n",
              "Q2dGwJK8QHuxziVXzI0l4rAFdVAyMtukuIZCiGM3nyZnTyShIadcrF2opDJXA08VBtW3nw089y+R\n",
              "zz3w9Mu7yHYY9xbNcGUGnBEcoNkSW1CsAfApU42oTfAhmHOI2m96d8SOM+trhuUWZvx8OcQnSOZk\n",
              "OuODJ/imUDsn4Vb/63v0YxMD+AAAAGtBnnNFETxPCMZD/ZrfCYVH3i37QxfBulRp+6rT1GRwtwZX\n",
              "glR7/SQV+da/O9Q2lvqmO/wOskP/sHBZYP3YDGfGGTtZwAeQXrvVkbU+WF9B3Wz/n6xVxDuH8CZc\n",
              "/n7UeK8pvz+/tXcljktzgAAAAMQBnpRqRP8Iv2hwu0JQ7BjgIHWdxAjhBT0zV3voliiIQEUyfd0q\n",
              "AIPVikxamaKgOg5YX+8xB8jvqhNiSE71WnoLEuJf9L0i3tMDvOJ0UMLHinPBoe02CqhGYlzQdFKp\n",
              "r2Vvi4fwMkrhEvCD4ejCc/UwSGFf5OkJr+GlfLlrOB0g2h7TYRkeVjVykF8aRQZjIt4pENEgAuDR\n",
              "srKz+b1jDSvmrdZdgpKcyCkZCEOe3F0BhcogLO1mMjSrWsg2/VAL1eGHB3eBAAACWkGalkmoQWiZ\n",
              "TAjf+lglYMh3/hwAXLyDY7TvLqcHDTedPmGNguihCsMe8UAV6+xMmBQmIbs+pFbL4TFdt7UUKn1d\n",
              "mT82P1TGetb3RRs94h4SFtZ01FE1P2jSNwvE+9M5XoM/dGaqWNpE9DiuLDXxpc7JT1wX4OKEl8GO\n",
              "A9j46rC+S1vnT33/TpUIU6ZxZNAU/zvpj2bvxa1G4Nf8aI4S/65Di2cJndn+zzUddl8E60UgBGFc\n",
              "uDMoezlMJe3sEq4qA2AxHYLVrm2pw8+7Zv203/xKFWhwpfhaKRMA50xUWLvuJBjSySUPHATybcOo\n",
              "8cX8mAHvsjkxxr0Sqmnuyj8HpaY5O9O09CqjMCLO/Q2Ovyap+lLFiFbehQcNBeFQD4gmkvt0kTK3\n",
              "68XfEBhzkDoTZxtkX9cf3B7/8vt2VNy2+olbmambS6kxePSFegB6TUoOaAbtwwXLquJ5Sb3qJO/b\n",
              "r4hUsMEVvw1RgRzqU6MTv+xfGBtHw2FxiI4y0jKesBbc4JbZaDC842BcyH7rYMbZMtCdztNYhS05\n",
              "9T6e822/pQOcXMRwOtQfKB1ovG0BJ5Iq8rxQNxcAzULlYjGPbbUs5oU8edWGfudvLyVClog1gy4l\n",
              "w/IZwe15XQnMfHx+xjoDf1xCvC6yQ8IJ3eY5IhhvFsPScdaJw08HSH0TOUSBsSob2dzU8tuDQ/kZ\n",
              "2uAPUMLSTxgZeMEtYXv83hcL8uVATcaOp0CMFAnoTGmlIHocQOqeCol3rx1QTn70oD/BeSA7ZUNe\n",
              "DgU8O+O5Pi02qumseMBnpgKo3fizQZugAAABqUGat0nhClJlMCP//IQEL9u7JTikXZx8I/FS26lz\n",
              "uclTu11JmeJ6jsjIgdBJ4pI7Un1Dch4djMjqCgei6MX/8cX894HixykUJTYlz+fQwRPwmTAPsjpr\n",
              "Cg+TgwBSA00axu1HI6l2/IHhZAVeIOYmA9lG5q/hefbD7xfRRLFSB4nNTw4uryA0aTyTc8LdNx0N\n",
              "ht6Q9xbkpG7yg3dCHfEil0riMVZQfa8f83W/ukOsixqd/HtO9PB1UHyuM0p9dibHBuU9eG+YHV4Z\n",
              "dMyoaQLlbuzvIAIstav2kSjZyhKfnOUalON/tz2yZCg97bP1CoOQp6+Y8Yr319T5z5lDDvaK9B7Y\n",
              "HSOlilaS8smDKZzroO1UB8SGrScY9rrL2WZ4kvoqa9PG/6XsyHEgsuBn+goZI+Q6GnNovzRvamTl\n",
              "zWbffQxOeEZpb7OYgZC7jPGFV6oKDlbK7yi2Llwug8TwGZ8h9l7sbjl/MiW/SM67SSU2VCBdECSP\n",
              "EVuD6tCkhVdJUvPv9kB2nIpKZw41Ue2nR/O7MwbVCPz0Z/qBSR4TU23/Nj5IqwnIYHMqp1MHAAAB\n",
              "tEGa2EnhDomUwI///IQEJ7MP40B1AM9QU0Oq2P/I3X++OYQcHyDZ9JLzMihioJQGX5rJzPWO98a4\n",
              "ChKMO13UEVaXD4l4lFZyHdYm8HfxIJeEmu5b5kzrCbmCwDN6aps7mK9HAPSPpV/4wY+7mwA/Lkph\n",
              "OWEfzZY96NcPNoxr3OwM/mwNxKD3uVqYZtiRdQPD9avnRC+tQF5e3qluerzIdRPBfqZrdsFU7Akx\n",
              "h6wnbrUZ6Pkd5ZfKovTYzgSIE9m8n0ydX51B7/I84ldw33voK67o7PlfFaQDSMefgZv42AQX5baK\n",
              "3M8w9jGt27mrRtXH3YLJtMZ1Mv73QX6YU9mFKakhb3S1X2WQ1l1+xrQQieDMSZcOw8juZPKFj9ns\n",
              "OATNVBl7135SLhdpmSDQhyQgI9BTh+52v0iSFdxS3YxqkMBO7vl+oO9QLqCueq/xkmiTB0TBxoCC\n",
              "lMWIKFO9iZ9Kh7mjLyTOfhUfD4GwU1vW6G/NQrJqgCI1POuRU2GBQVgKjyLadm2RjmYW2neBSOia\n",
              "VBqY5WnBHonJEwA2adWbcnH8Q+yRbDCpP7NPMAw60qHOe9seqPEAAAKlQZr7SeEPJlMCN//6WAjH\n",
              "6RIBZUj85US0yo30QOfxBgBMZFa5GL9dCuRP7h0U0qaqi5bv6bqQUpz0d9pbajrnP/M9TNtW3RXK\n",
              "86aT0/LUHtjb39fnWetdJDuCSvWeJ+lLPA8YIAKEa92dzvtx+ZqRGLbGU5Mc0eg0cKgIVHsK7qbP\n",
              "aHfcXHKH1HNbvJC+dkBr3O48EbdKTA7XBZ34srZvn/yfk43agXMO/S5KJ2kgJ7ltH/Y0FQACmsKM\n",
              "KB7KTeVfkoz6VxVAUctWcsrIPsBijyWxow1HqNGrC6WcX43iab83OKWjeV6K2+OyK/pdGLBOX32Q\n",
              "TR8ZiH0BtlssgQjX6xF8r6iaOYxxuzlkVlEfxqc5PR4U9Qep5JbdXvqIbnQTLn09y9yqiCTn0/vx\n",
              "HhrHn/fX2EwOohvdTXs3NQ9eEH8wxhjNVE3usQ0Mr5JmXXpAuPc5XCWjob/nwXucDOjKJImCGkLy\n",
              "vnjTdd4840UKauKUSYoDhy72eaMR/hhcKYPjJ6G79zQuxAFif3p5KXHrN7fVUJlH2IzfLaTf55tf\n",
              "Mm18TCQT8S6GhQ8lR7FpclDXEd5Zf+/bgTw1ORwDtkQQ+cFXUCmdj8ag8oeorZYg9MsKUwnQav4O\n",
              "B99EHjomfzhAn+TULlvCdWEjyFWVXFWlJfQUQApQKyE774J9tV9tJe2uS88uTKvCUTn3ayB5NTQ6\n",
              "N533AXVJn29bczpVr0n5NDk/ni6YiFIqjNDPukNM5bl7HIGil0g/5ccgiPz8TQecmTi8Y64Zy7er\n",
              "dcAQo7iVsi7pmrShGU2C2/GDv2xFObJtKn8oo8VkzbQpeqgawsesxGcDxGAlLFNuPbg0LgqlyxYC\n",
              "Hsic7rbGdIxsJzJeQAJa19OWc/HK3esm4E/mewAr6+JpROAAAACCQZ8ZRRE8TwlBwjdHx9qBGun5\n",
              "NCBif1sNEJSuFywSsybIU8kHzAcpaUPRE0OzQ6kkcT3Pz0H5zu90i5AVBNhqfPgvgCPYkmD7lpoF\n",
              "RCZzgRC7IKbiixpiPg8I4QRaOVLzzv4ayUC50lkA0ou3eseXWNXnYe5RAnzO55oP4ovaiGp1lwAA\n",
              "AMABnzpqRP8I/2ii6yS1UwMfevLGLPFbp8LeJCJfg8Fz17VtHagfWglzUixJJmxE+GgGU0EP/ps3\n",
              "R8N0d64AIBiRP4hzHsHBcppYs51ZW5irSw9LwoTFj/2IXedmAsx8XtGlRI7+9bqCr2iJmJSetogk\n",
              "/IJORG8gB6T21DJrlBK69vxKrTlokIYnNifq8I2v8MY5pLFZz2AxiCzEpwBtgEhqtaduUBUc3sho\n",
              "bF/JMEx9nsgEoqD0dptkIzCCHsXKl+gAAANkQZs8SahBaJlMCN/6WLylgALi4/3kr38fOM3FfPOT\n",
              "GiqVKX8/TcnEpbg93BsALWThHwzn6Y5iFW7+Mck8ke7Q8T74TYvpv7uMNQy4LmJtzQ8oBklbNCSE\n",
              "EDjOi6bKYkzNBs194FiDx/dF6SfGaHThcdihs5/FDGJbXdi7V0xsVb/sFnUttRGdrSSSox2Puc1X\n",
              "9luwIwMGQsm1n+NW4US7qW3v+CZkzqZGhLeZ9an+C5Q68FG5zSkN/1dMxNUQ/I9K/5CWVRdR9EAX\n",
              "mhW/PduW63/60v9110fzr00uZ03ifwA6/SZ1GRNr96KFMVHPEe+a8GkKMPPpl6q604ASYjb4To9N\n",
              "ujeCS4Fcf70uC0UNaTuwmecJGCcqUuQ0zPZCpThYL9C+RhoBN1VzIfdRdILBXqmHh+NZCHHBn0wU\n",
              "U1JRgvhcMPXExmH8qRwyAifGvkczD+XWGnrv4rv4WLDEHrYnBd03L3Yx9cUDEVSUrFCx7HqMHUIF\n",
              "lZHmP2MiDDlzAE2q9cuW9WdZfPKshalshx55UlZ07I8cvFJqGUDyaOpWNLxoc8ApImsEiRIjhjpj\n",
              "F0fJhDOd3ZaHSie0iQ/c4jAfA4I+ghtXKVf9Q5k4oW+dc+YihVTFPe8ZWQTN86t2ryZ5Y+uKTtjK\n",
              "RLuzBHyiybDBnrBgiRgO8Xn8/3z47oFKIUmNbc8eZyn/qg5bq45J+adpV16pfYGeKF+I21DYKPbo\n",
              "jQwDW5Q17AMERoyBn/T0JzfTtnWMpMjyHxLEwjHZ6VEy22mad+wICGExp+nq4k6brlar/tTeu7j2\n",
              "O6lMbDC09JBwgXEODBn8skkoyvhXxBX+dF7tTF/7V2E3ZVp1exMEdfoCo3p0D7PUndiU5HgGq2Jm\n",
              "HMlWo+yl+8L/jC+6kDZt1AEujOiXlIm9ZLB6VxbZB1w5BOlWvrTvS0tu41YTxgoK1Pp2eXMI+UEI\n",
              "mzKr02i85QzLsuieQNCWyDlSe5Slt4MCVgoe3l+XxG3dH0Q8ynnedfx8N/AkcQG6dlb9gcyLGT6i\n",
              "hlhgz4KjsRHyz34r56ggNT1rBw4PgFIMgztnmvTMfY6xnjJjKXCRaEO/M003n/I4DXWrKNNSrvJE\n",
              "Q7vst6xL8ezt6IjM9kLZLB2UOaRUPfDI0yk9PJ2AHe0MwLaoe419HwAAAZ9Bm11J4QpSZTAjf/pY\n",
              "CIrZG1ge71vKeErwr+7wvPcrFkyfIsBYbUsg6sEjz1okrxL44HxdNOyJ8wErV9AHyFjL/YeXb3vS\n",
              "pWxogV32Hb5I7Q24z7+75Di7CIdgW+7m8oY/aZoWyTM2Vkz7XV5kTpjaqFGdab30x/YL9OvzDFT4\n",
              "zGFuSu5KxVGhnXGqEfVURxnx87WKQ9xZIh/V3z8kiacHoo4ym+5V5fQHZYzRbyk1Akhugm8fvVKZ\n",
              "AIBCU5Vhlbh6QVOVSQvIdJLKNQvhd/LIX9txIngyWJkMt8mfh7zfxnhcQpZsX5xJOq/zdizccnAK\n",
              "tX8gFvqc8lhJ/IBr0qAJUmcRGYRSFS0itP36EPyj2c0knBbRd04QjK6wsa0TWDzZ+WeEOpisuee7\n",
              "Nw+ZPcYgRjL57jqKdc2xv5037yShlDAWA54VusQjMxSaGK3dzkowTNpzMhV8A2taLev1vg69ICVf\n",
              "nZ+CtJMkXbnEfCOH0f6hrypOHzyMUptP6EXlfE7dIRBvKLTiMsmE0u/4ASoAWdHy10S7lossFEQs\n",
              "i93ZAAABtUGbfknhDomUwI3/+lgIe0Xo2wABhFS/GRZmi/bjPrJqT5Ye9Mn/arF+3vqDzUHifGTc\n",
              "7IwbsubJyPV6v+OT4JLF66lKdZnlw1wtDkjHPCVGUr6W+t8soqYuiOgWgJbv/FXuDYYx3j0+mbDx\n",
              "cgq6c8EeICPOAH7fMcptHCLMtBn9GEhpUkgDabAMpOSQ97mBc9+ub9PLAbaTJVpv/1Wk7lpZB3Jf\n",
              "SmyJGTPyp87QzdgaRzUbxZox/03KdCeJH1MweI/+wjLU3DYBXy0dg6dqNrCp0va4HJNuc9gWySt3\n",
              "1yWPgW/68qvoyvgBz0UckthuKA/09Mu2y4+rGuNJO5fIPpGx8YRq+j52S1Y2ijWiCUjZCzmLEN1W\n",
              "p9246PNxy17xy+fLQibLdZBP6yMYu1lGN2QfeNM5vMerigpiapovlnS7++ohxe6CGEFiMSHNYhX6\n",
              "TmMZm38ajn3INRX027qkhQa1+TxoNTWRshJGxyL3tFJnx5Mftlxd7l21jRw4dAFsT9hLrvc5Zj47\n",
              "LAkHe9os3V/sjbJD2aPfSna6E2RS43QuUqDqSEWabKHMwLIxDolEKX3TZuv8AAABvEGbn0nhDyZT\n",
              "Ajf/+lgIitkL5xpzQD7PmKs+BI3492i0xGBe+RGAHLtNPXrW1jllLoFug+afAr7YhYQxynFjLwiO\n",
              "oA1hvit5zRg8xlcbE3EvCMXbzVTxr6CnScRTLNnmUAYX9gfMMA3f/bm7VinSHJWTzjMi1X+tfY6V\n",
              "/+kpITiuRXSUMpROGS+w+YmnSiBT9Lutik+0wGQ9qJfn/bCx09slBpoDcbMQSV+txbb4MMXN+ZIP\n",
              "eq0fPM9BGQRAKZci8afdvsqUZbOHDfg2nU3LhwPHZrTJ9Yi9sWPXHp7nAuzdKDX8iUfzMy0tfqAo\n",
              "XQzpRK8FB8WmnXOfrIJcKi8gd3SVoLWLiMHvFo6+H8gjusoGz8SdRxUfnQYZC4w73Vt/RCsKpQas\n",
              "4/y7JkllidniJwjQjrBTmLYY3U36RXXqbXg7w1Dn/+SNCL/039keCOAUagl+ZhyxmoBdtOmqsxJF\n",
              "E+NSmKIkzyxgJyBL76iQ+Z6yn1yaKGDfQARxZYPtcjFJqwlPEttm1yAajSK44C8FsC9+IXo3b7Fr\n",
              "04XeD3Ulu2w1WQiykzuCAjRXcFRAgZbfBTK8LUSMgCtXC7N5QAAAAfdBm6BJ4Q8mUwI3//pYvG3A\n",
              "TDf/un0P0R/tVQdBj9Egzw78UyjUFaLspdfSKIIQYoLHL4w1nnlb2cWRgNvgUyMlWBHn25tcn1qM\n",
              "HAiO4sNsZp6dJs4AA53L1ZRKMZp5sdQ8ncHvS9XLbqtdg/cd8mHQ5TfpA2iiswq8dFr9SN3qbXK5\n",
              "9Eq8oZ3kQAki4oH1VmxZPBXSDQpNuJeC+yH6YSeLTuf9kBcdnsDd+TIgE8GjswJrXbIcsM2cF/CR\n",
              "uLaQvS+kt0ewCznCV+ZhRKZW49z7nApNgsXlOuyfPsF+GrMMpE8TfDb2r++GLc7Onfoak7QClaSs\n",
              "mRRND2BFOtdNZcHTGxcerSACVBFvwa4ZtgerKXLaLdkM9jDRhrz4xvWONV1teqQWn2cFvQlt79iT\n",
              "SI+25doJ4oc7lqFXy66cN91WJwuF2i2Ah+OsHMK4Ugf5UyH0xxO9VHTSg722LZAJ7Rkm4DZ5oyKO\n",
              "PhujISHDaZnp8KmwirV2KGWdWW3VfAuqcKd7flH3Sb5kq874Q7MXDgnW0gD0bJC3Vdf7zcIRgRRl\n",
              "bL2PNqHOsfptPWpVyHPTW3UN++UvS8FJDR8isim/iFesqIVhuuBmSdBGeUZthxOsuF/wqbwIdPkL\n",
              "Eqc0cXIgi6cwLjkrrzO/Is4bcV10NnLtclUymWH44QAAAlFBm8FJ4Q8mUwI3//pYCHtF6NF4AkVD\n",
              "uzmGO89WF8i29QWDBhlZ0XHkEJKkKTWYTW/sJz0s3II6KySe/PVpbFmXK2xUKXZrul/g45rVHtTe\n",
              "W7FrBYcPsncGh1H8/susVIEfviyTfq3pj5F7M70nb3aN+YdLHGsFsGzzpmzJ6LJnYAOfVgJ3VM0Y\n",
              "7y2MKtkDAD2HHPCLqNcQG9wV7WxIY+oWCyRH/+dEnvWb7b7+4Df3Vs3fk7pCzr6EKD2p+moIokBH\n",
              "vKl8z+ayBmz/4rUJ2BNMBppZuoGukKeKzhapDkdZI6Aj3f5ZF9LOzWPuOj4agZd0m5+pPegLDeaN\n",
              "a14MVEEPY/CwU/NdEu7lOgNCWNUbZ3WLOorsi+sYvYjEGAUT8PvdD9ode2I5hAtpXFZRIP8dTz3r\n",
              "s2/MZR5n7LlmP1hsiwj34zgqHN28Tc2hiGBq9t6ANPMjvrhL4uUH7/8sDm6HRL4l7ZXYN1UbIWZM\n",
              "a1KZrLRTlNvstDffrPclhRDmiVgzShVWhVB3wNKCJoiLjosPJXHxFqLhMAbhUr33T3ZXkreMBWWq\n",
              "xHK2/7YvKXj7voRKhuf5LEFnnH7DGGzKEiPoNJZtat6cIFKBJkI+UMLC5/flZlNzDrUCdtoPEYyX\n",
              "fUr6otH+RaBjBuRAn3jZOGDuWQ26p+wErsq2SJD3nfLzatvWFF0CCqdojBJJywNfFjru9gGQr9O0\n",
              "262b5XAQE+/KbmWEbIeFUqOs3NuQGYqBJ7iq1fFH02XPWF4etvTJrAUaq51saF8x7abGDPEPG7tr\n",
              "RwAAAxxBm+JJ4Q8mUwI///yEdLd4gjR5jczBeX/CRmoQxeKd8Vm3ZvJ/gm9Ao9o3KgkyZ6NOyS7J\n",
              "8xofUf2kEhkeMYKQp3hGOolwAcw6BngFbeuZjtW+6ptZsQAXw3RvGq2LNJDs6CL6Z0Z7tEn7V7n5\n",
              "K+zk1CRD2gAH6MGBK08jsfL1TpZzQZke8A5nHDghycJO3LgzegfZ0KozgeDXZmXw4M4skdGEzLaK\n",
              "MW3J4tvAvxSeUqe2WBrkB4yjOpgFOKOr6XBc6VEsys06TLTVzZHBMceM2aYtG/sQ+Nc9dxxV7pUn\n",
              "JgRIysLtQAtrGopbPM6Q3sY7BvggEVzVqsvyD9bt3wayFYYwfXex08/Cgwg2VdxX9D6F/JUQuv9Z\n",
              "WP7JNlNKJ5HzOpaP4rxV1hwIa5n+n3SvKBBHEwHY73W595LfSxOlcSo5WUyWYcSn/12h79TIbHCB\n",
              "i0IYhccqBe6VUMEofg3jA23oht8ZG77rP3xy5XTshs71k0wwGUmzGJeQIF105VwGtV0TdABUvTNY\n",
              "6aG6dTJwjZHEDW4QmwNRqlNLybFGWQK1KkHv30qsA81ruk72kOEFt/muzkj8QA+6wCZ1DTOvU1jZ\n",
              "6Ve3SOahptuccM5E4UB0GE3k0OVBICIz1R3zzhiUW1XjV6bA5DAmDRNwCBsdf8PsK5MPxnKJ4XZ7\n",
              "NX/nr6aO6O0JXCC2cPvdcOtbc9/ohcgmbVR6IlI89xviNyf8OtAKKb3QorU1aapezUpIPK6cyEpu\n",
              "F+G1Pb8cRcHkChjRJYToUpIDLqZjP3tv6WIvXZGDhrIeF+BuNQakUkU3xCT8yrQ5uLki6ScIeB/N\n",
              "PJ72MFMJzdeF8jLwFwQ5cyBPy0pJNoJN5ZJnid4oyFLy4945ptRu5Wt4JdKMbREgaG5QyoT18kn9\n",
              "RWSAVC6vbLhmbUJwJs9Dfs5ZGVfEEWVU5nfBMkKE/UkV+eR10ZKrueh/4qdMkdG2wXepeLdzZfmk\n",
              "E6MWNvoGJrQLpwesnr8pzMxYrkaIAiLNNMOJHMt0zDn3T40P6u4et5iloLVGWqtjXYgAIIr/P+mk\n",
              "TwphAAACrEGaBEnhDyZTBRE8b/pYPgtwHU0vmo3piFZxRQKTynxTr6p2nQ8SVyQJXvokuhbCTa3s\n",
              "vdpIiVAmXwRR3PemSWZcLlMbPoBebpY6TQy16uH9Cf3FJBUuwV4iiwn3Spa6YaIOQzuAA5Ueck7z\n",
              "MoG92GW0fjhfDft1+EvNnWXx/d5w4vTJt7hzfy70Szhu4E+xV5ltyqTjD0fj0H1Hha7X2Mqwye2G\n",
              "UTCCP5Ij4LE+WUEAnv419wFI8lA7vMsK7PTvkCpJeRAGZpjqPo8y3vDuErHBeNEwS3PQxmQQLgzK\n",
              "Soq+S3VSECEtaWj0ji3/SFq2HcrqHkfdkemJ0yoUd5qRrgb4jvJye8+c2/ti+5KmzKeoN/4LE4J2\n",
              "X2dQdov3aahYFcsnp3HPLeash7JH6IdDeEcjDWrEZ9iUnmM6GYEeWEPVDMPpkjprOeAHFsjqi1Vo\n",
              "MejWiu2/Nfyh7Aqs+VchXIsN0dnwU510c7AjoZAxujN3VTwWIkvMT6/NuNhXprwY2hYPwQjZAssj\n",
              "hNraQ2e6JlcKXfAVreg3/wIPtbw2v5POmDN87Y4v6qs2NHcXNeKvxtiIDQoddqkvBx8IMPK6vYHM\n",
              "hkf2FAoe67e2S51SkFP8ndPG7YBz66a4dszQSnaMj05HW1mnY9xBoNR+nvkRM4NokEvgEYa72eqh\n",
              "rAeReBCYRTZcqqVzU10GAyIagre0W/keCH4l08V8f5msV4+/zNzZc01dVRGcUJ4vd4r8ftpI/ffB\n",
              "BOVhppp4F8gM0l/QpYJZn3xvCQSTghHuEDw1scxJCXvhQZq6TJ2LrwlRPjrF3RX/COb+fHhVYIwM\n",
              "sMcf9Oz+Ke75XzpYiG/V02CdX1uNNTw+R9mEA788cDk6e3RoExVj+9DNZnnfUjJAF3BVEzRvZ5DX\n",
              "qw2HDIp2pAAAAIQBniNqRP8Jf2hwu9sqanFcaysMdABruQ0nSc99XJdjG+GqqFQyCCgSCqqe8AEO\n",
              "CBzGy6JNKKOlJP56/9tVH3DSjhRyAROFCNyDcFQI/0nSH3QQ273GD3uLOETVsVL2xqNlhEOOQeC8\n",
              "A0qo6ROgbfk65gSl/x/xteRPz5tAfqzWdpXGfG0AAAI3QZolSeEPJlMCN//6WAlDRejTugHcqdqr\n",
              "sImeFuiB/2ePRxkJW5mESzxsk97/2Ft8dFgQYrbWLKxo8vFL41ucIjR3XsBK+OOtzKJhh6FbWV4t\n",
              "vugZm0Wdx74Q2OjoKesJCicQixY/uncV/dkfxK1lBGUBd1qJ+JtTWnNe5V8ft8ZqByqEIeHGwrKg\n",
              "OFE7nak56Vj3TTXUbfxLqMAmUv0BnXoO6ftFfO5glYk/b2+79lpkHPWgf77wo/ICJ49HvlVwcLD5\n",
              "dJqR2INH8QVuStBdRQG9LQI137TKlEAG1KMXJ6bdHL59Odxc/pu6EZ2+RiTR8ahDtNuYNT+CSvIv\n",
              "C91D601vgiNDmR3tKtfoS2uHl0BN2WTXkEciXzTiHwmDt/pdsfPUJtjNO1S4draj5iuUFAUWDjL5\n",
              "imfb1kO7XxaO8XF6sJaFZMT6fT8Dus2L8qlaW5JUis6pWSpOrlO5QFRQ8SW6SSoxurTECYTMSV2i\n",
              "/5b8Bn6pSpY9hz36ADgmRClnB+Vixy10p96L5Kln8EKyLKq3HULCniCrC4RaekUnwqHVBDobtm/J\n",
              "tmLTHRhn0i547ZVwlIMACaFYhMep1igw2jEwFqbAZR617OAopcbVDTDPCHUTPEp50Tk0duzSm8Iq\n",
              "octMh5nLgP7XewNqHFA10Hd+ydIYtfYGaRe8P/cELRODtMqr6pQLjULKLBJv+Ykdp8JxYSQZmI4M\n",
              "8QyaRVThmMIHav+4CMBFijjpHvdVHjG6jxupftLhAAACB0GaRknhDyZTAj///IQFs+7+AN2R5b+m\n",
              "pBIvgr8rIs+sMGinznCu/61sEhL6reDUCQYJhmzQcvOTdf3wdrX71p5RAALz2LL/pmjmp/fUn+YH\n",
              "2N7nokCkMak7fX143ZVkZ6RMHRkj9RjD4oLcJ6j4dH4GCs3AwvYUxlK9TrimcO2WjACs6keHofKk\n",
              "DEw/LP7jpuflBo1xQtet64exaFKRQQSRr16aZfWc7RaEo1ENhKoC4ThqPMLWtgCDXxZ4IrY4Tylq\n",
              "bvGELwW/ogYLpbZltKvv3YOoLtEB17upI7HrOUdHbZs8Kmv2IJwp3YkxIg39rVGu3/1H8mdhNOLK\n",
              "tKgnF+bg+7LG9pWb+dwuwFChIEcuR4x0QvFeryYyXPZiy+YQNnruISmN4QOxb9vhO1cnFTCpYkiq\n",
              "Fl204ebFb6LEqTcmZfy1xG6Jvz32aKVGixGLQRX+d0Bn4TzlLqQl41e3PQ8nXrc3M/1WjLMz5NbW\n",
              "R43MpKc7fNg3Y2K9pCHrOuiWhuv4EWYSvXriooZKHQTS5GSEgVVNK86C3beCe6hJpGBKMzozqodL\n",
              "nJqT34kvwIdOEI0WzArSXX7MWW6/8P42X6VTRya80cBQUwMWakbF+OknypxvHw3fftdXlWISEaz0\n",
              "E9gU8mV244KTvffXi5cynD9JiUco5K8oK1ddNERCaNddTJjKmciRHQAAAh1BmmdJ4Q8mUwI///yE\n",
              "EVXtUA3OS2Vi3/s9khzr02pdAzg+dmr5lsyBsj6n1ILpYeKWWdEoQw0cUhVfYZ01T0roQ0hP+do7\n",
              "WQ/dbCIc8V1AKzV4ywUz9y+E+VLzQKgL4/Nt6rEXSpGBZZNXtJDgcMT0r9PQJP9/nR6SF2q0Jnq0\n",
              "WKUeuYz0ge5DmikS4SR+jKMR5XMAMtM35FEKTD+Xw/gKzJrD1bQH6RlMFHE5rK9ix98G6+JMCY0y\n",
              "d//O06OtNpe+Dop01ULc+q6w+M3T3TXrOlp2Z5lVivJ73yF3Rpq3Vi3zF7T66JrjIW813H+rMn0X\n",
              "xP+SLPy09kWunFpQaFKocsGVn4l4pNS8ID+pkn/kaipFjdyI6ldBG+1hwmaZvTdMvtcU5kjxbofG\n",
              "cUAh43X3GcfA0Ag12l838akwkRDLxMKF98sSn5gErhjIDvobqJJ+rVW0wJPJQEaI+UW1mC/r00eu\n",
              "0Ig8h8Zn+7atj9MR95HCVIARstZqn7fETu67+iXg03b0AEfrWqkzdlqUpH8k2LZGIBUnT6lMGckA\n",
              "hDDfZJXuZXlZSAgUNcOWC/i6a6Vk0Oms5TBE6G7C11dRUgNHNY4VIeN5eTfurUpOnvaBHelReJrN\n",
              "ZSeLc4eYqwV6wDEtfb0h9FT4y2R7t66RFROQ2i2SByHPNrAaCx44Pj8k7x8CMKBhHuVs2QHv+ZWW\n",
              "ghV3vzhqpxg3xBsGuDWhAAACfUGaiEnhDyZTAhH//eEBh6+uxnzTCAmxH6xkvFyHC4Yfu1aE38Wp\n",
              "o2G0WhAbt6Xg7Nmwk8YnGagmoEa3kbNfLKXsu05Ng9byeC9LAIydH7fNaO67/7R0qHKMGQzRwdZ/\n",
              "snADBoRKTBEqgcAvS+3rW51Knw7yQ5xm4yw+j2b8UNMipilsslgit4jcDNGiaxMQm6xunZpBenaO\n",
              "ONEfftGVCXUIyw6CPum/Okd6FchTlLFalHHOJhxFR+KRubtk+odznQcuv33h41wvmUdlp3wCmyKC\n",
              "2tpUGyz2Orcd6B/gEi3JlKwWQsHpvVUigerXchugKI6E5c/dIXtaw4vPupqx7uc2QyLBXlcnAvIv\n",
              "ljBUdF3K10k9t99yuYU7MJanVgvlMxt8VeWbA8tFZWs1WR1rhlSf2/3mQI9e/MOic/NSKoy0J5w9\n",
              "mXlEosvgqdgeAyPZhbKZV6+yg3IHkXEolYwpSonzGa6lUkrkKgTariulPWcKXZQ7Xy3f841DCndB\n",
              "c1j6+/kQwL4g7kH0s7eE0UF40nQpTugPoujTmArIEhkgzm/xuo58U4718NyPh5fWm9Tb9pdDkegh\n",
              "VX0ftd8VMlyAha0DRv7MzI2uT9saBlSHL1EiKW1uHLE2maQPJAzBtmT81/eNZT6+yNWiGTWwYrN3\n",
              "VFSVcTVckYh2ex7KfridlgTnpnFbZbD9JgE5WL+hr5NXqKGRfZttUp5jvp4WLcUAwNdeID63SJiP\n",
              "wy7aEEcA0cU324psPo6QTmoy5iFgK1jSaYLWMyMl7rsSkPELwa3qxBYB/SZ+PrtBw6WcPqCReeMB\n",
              "yqP/B/WZmR+zSFNH9P+rSjUIEGRNWh/iLDHwpfAAAAOQQZqsSeEPJlMCEf/94SaMQwE0WPDwWHd2\n",
              "8wORLvINBlTz9WZGiHGiqh18nLYx3f4Fq61IMwgIEQWJroV3NEj2wtUYe2FEVsET3E2gfKIU39NX\n",
              "i5hxoI31uDYDMZro1EbFTwEUCRV+N6Fe3Kd6CZ+sYcWQErfN1cGUjD1B1jYUBv35qetoM4ItlIWN\n",
              "65ieI7LCJ0ReFaqgO28H7GN9ZYNumgnxpvLiPcYhXt4dlMuNT8gWTP6eIf2GtJGmg0prjwDJWoD/\n",
              "CEUb4XBvZ1dD077dF9ONcKmKWTZyG/5fYUCymrQnCgl9i2jxPhEqnGX4/Cp8H7TbVpnj3GvrVreS\n",
              "MJSUlEk3I3Qx4IzVIaM7PGe2A6T82vyWMq56sgsqVw+3bOjnvRqlEubGOL5LJE0Aas5R+99P9KZT\n",
              "iH51W3iKYc5F1jGd9O3lrugZSLBIB7r/6FoF3BqtGG/lr0UL9RRUAEvV+/tpv2guPYYHuPjgdeMB\n",
              "RB90zaZrz88pgtOBoSOOHr1OgCrV3ryJi0//9C58jP/TcSrQ7Vh4DaUQ2cG9mlIBd/nFLk8CQBSh\n",
              "kXWBGinVfLL3po31mCGYnPRY71grtA1FURALA+RvkoHPM6qMnHXHizNpRdkB0ET3uwQOM+AvsVl7\n",
              "r9SbNcxMSLXrPh+a8QU2yVhZ6Vdg5iYTXfNYwExiQ9d02vVImWTz6aOxiJGTGK9F4bBBfJgJKTq6\n",
              "T5y2/1SWPek5acMsCEAfTePgx5DDYaIJDmZtRRe+FiY4Vtl0zRZUR3szb1DPek3232GndMUGVeog\n",
              "RS61ee5WMdjrmBxJeFHkF0FSBFVfBmvAf99Ew0FnuXxM1GE1dDf2kXo6eQjjhEbMOpaHwYxaB0+p\n",
              "ix8AFl4HeZHJi8R6K01Z/WTCd7nn+N52Tw9wc7dWY4zJlSWS9+KGeUePNh9HYQVtPjLR7jzoNLNi\n",
              "tbrD3j7sOIgCweraL9LD9JnGSYgGFuSjoa7rVCHtcW+vDDObch/yYY8otkKzLl2hwRfXj1ksRpgW\n",
              "iGovvB8HOaoyrMVYE7Soie/YLl00BJAjEf+Thywcx3QPbhL8eHNSSZE5y7KdfVoiVzqtA4kkKoBE\n",
              "NZoyOntWMQ+PxpvSn/qzVdtXLVYrNYeymIm0E90CdzSdkT21m7cKFPIwACqYV1E6eJVZP0ea+k7S\n",
              "CGabtdPdTavyoTsct0s1NK7mAiNzlWoPjinat/K8h/SAAAAAP0GeykURPF8QNMU8/eXsZkIc8iJN\n",
              "Ia6QsfOI8wcIleKAmFp7LtJkSOC4Fq/Wf7Q6FLmff+gw/fHfYlCsusIiIQAAANYBnul0RP8R1EPq\n",
              "p3TkzSoqrSaNTad+g4cAOAWzIjG55M02Fs63oNO5+Cl/FRZNOpca1o/I60M7CLhU8pUrWy314s24\n",
              "wK0xjVfg6u4PFUEy8/AzpIB31fjt5L5iJNw9DEhDSzJfiu9dz/xH0NWRhHXKOagxsqkhEnKLPeFx\n",
              "yPIjYoXQj9sJj1oy2/zpyqABGrqC6SHx/dKcenIKVWha5/+OS3M12myt1LUJUg619hjj1iN8yESo\n",
              "uxTo2Sc5VHymoYhQoiQ1QR0aqmycyN1My1DCxUSbZyTAAAAAEAGe62pE/xHRKPbxs12G7hgAAAB9\n",
              "QZrwSahBaJlMCEf//eELZrwbPd79xlff/QBP+Jh4odI6Dk0MYBVfOBwooedXpJUVRXGoJym03+9+\n",
              "cqh0m57G5uFgSdZk9nc3bfsqnEbCAFGMiZer2B2ltScqmEiByeNyvduCtKd+oRwbNmlr8uNgV+ph\n",
              "gb/b9aE2musitYEAAAAaQZ8ORREsXw6NPRvEUbXHbZOYtwKMuENeVIEAAAA4AZ8tdET/AC6j9/ww\n",
              "YMx6AN7PbDMf8NqtX9vifwVmzvj6u4uS7MCcuVM9srVaSim3u+eT/ZTGOGcAAAAMAZ8vakT/AC74\n",
              "JszMAAAAdUGbNEmoQWyZTAhH//3hAAMNjCdsSOfHQAGbpnBsmI4eADhTY57Rmw5bbQXra9Ejg0B9\n",
              "IdYygDJZjwEl87Od0IqrqUKKS1Mxg4gYpA8m0SwPRrmNUHD9Lwe2WgpRdBapnsJcxbW8NCR9mR+e\n",
              "OgZhJHRVKGQ0CAAAACBBn1JFFSxfAF1OxNUImUAUR+ucKKRuKEXfaCAlaNBrWQAAAAwBn3F0RP8A\n",
              "Lv6DfJAAAAANAZ9zakT/AC7fmuZCwAAAAG1Bm3hJqEFsmUwI//yEAAv/++25vo7I8eAqE2oNZmPH\n",
              "/gBtfNysLQ5gXwX1mW8i20ezPzQMz7T4Mx/pAYQdynLITVydWfatdJdfkg/Ax3cOYwB8AH9I4xT4\n",
              "xEBwbAccI+F1Dzh+UyT/4vB/1NbpAAAAK0GflkUVLF8AXU7E0OitXMbu0AOGTCJAdYS+x24TWGzw\n",
              "UtA0X4e/yOSGRyAAAAARAZ+1dET/AC2kCkINAEQbmsEAAAAXAZ+3akT/AC2dy+cTmACrX8cTUL+3\n",
              "eTkAAAA0QZu5SahBbJlMCP/8hAALlpE/+xzjwAb/KjdELm2Ty6gZw/7PY93buXbMU0EGYPmLuQTs\n",
              "gAAAAHhBm91J4QpSZTAj//yEAAuWRMtmA2375qAENkoY0O0F/iDqdZPvjWDkTdQBLSL80Yb2LKze\n",
              "vAkDQgtUJ9KCXcDnFOI1f7Tcjvmb3PsZsIMCIu4Oe40aJ4i8vHmjXDa2k2POut2yniVKOC0+SRnL\n",
              "Gv4fb+I63ed2PSsAAAAyQZ/7RTRMXwBdQXJHHhVJ7aYJWdAE6dOU/GE7KEbsqucsJKv/MrHsjzx9\n",
              "afwzHm2fmB8AAAAZAZ4adET/AC0wmH4fd3HhQgCFi9wDQo3tQQAAACkBnhxqRP8ALTXSCJtVQBAl\n",
              "ru5vT1q/LxCDfydcaj2XjFpBLCYY9UcdkQAAAGJBmh5JqEFomUwI//yEAAui5LzDAC+EhJUATRsJ\n",
              "Ci/h2++QPv5T0EL+EOl/L/4AuslDzseTfAZY0KmAY+vUf7loJjv2ird7B6fOftTmyeHpN3/W8F2I\n",
              "LS+/hc+G5k0IGf+G3AAAALRBmj9J4QpSZTAhH/3hBgk/mWqDMQCKKifLyP9Y7gyPF/7qpzN6Og+b\n",
              "vGKb4B8yqSoUHmarBBxRHNnZwfsfuuLnoLvFRvKir+0gzOpjC32uXxKPJAuAUtrYBwWtzR2UOS8n\n",
              "EdNReBHU3OFOeMvAYsaTeEErwLZc7PfVtaEsUEaBVXWiRoHG+Ap2JyDklx1k8o9O5sPtRTs7oMuE\n",
              "uF7rfhoYJTN7rfva/7dAqJ8Z2RiXI33MOLwAAACCQZpDSeEOiZTAj//8hANfuEYUUvZAlgFmn7UA\n",
              "pJR5RgjZPyybKMrzE3T8itnx3FgVMnX+G0TNWB123wRmk2MWY0bvoUdotsKO/wct2hzx93zoBCeV\n",
              "0H2mtF6yyQDH+IG22uiHAzH5XIOSat9RneVJt+9/qITsBFSvMePweoYZSP93UQAAAFVBnmFFETxf\n",
              "B2YPCbplHC+FLmUgGWUsVXp1AnJE2CXq71BuG2dQK3gXR10W9WFsPNB9eyfjdS2Sm4eLix2ebVxu\n",
              "KyqdLi/Vrs2GnmJoAf046dBQdIzAAAAAMQGegHRE/whANiaazCuGKL1XQjADSGZiStwureRo3TOB\n",
              "PEJd0k5WfDS4j4rpVrfmrN0AAAAvAZ6CakT/AEFE8fPGZ00lvTJgCJniIZudIe6fnn/tsNGR5ENc\n",
              "m3oqRd15uLYHJCAAAAChQZqHSahBaJlMCN/6WAAhBDEF9HX1P2oAM3B8HGySNfu4EVTBMeEAVJR3\n",
              "iuwEO4x65vVRoakZjA+XQbuP+NBwgOBhkhPsDdUfCm+b3omKO9BR9K6A4jfWvhCvjhzITE2j9aiD\n",
              "mJtE8SvyGnZ7xO+yFNR2AjSruSDxE2/C4GyqDwWqKxAVEYsqb0YrqYgcpcoj1coVN7Crl69Y59DF\n",
              "NO9fNrkAAABVQZ6lRREsXwBdTsjAI2utZ0FAKYUl26sqT2R3AFAiHGtRPUNJZ/M1j3+FcuiTR0cT\n",
              "yHsJyTP7vH5lLd+S0/R5U8pyc0dB6LPCTmGrfwXFtuaHjo9t0QAAACwBnsR0RP8ALBaGKmwUqeAB\n",
              "/+kJersHBmky3H0NbtiXGWTpgmEA3LMp/g5N9QAAACIBnsZqRP8AQUTzZydPVEreKACvo7uN32qW\n",
              "F7EhZfnSTnFPAAAA3kGayUmoQWyZTBRMT/Mhb8XAAqZkQfrSq0Ki7DCDaPFQn5nsR1tDCJcvPtgp\n",
              "WZqqZk2j4fHOn4FLjVuFS2LSmieq/WoYmsJXEOBq9Kach8PIRA8pYeiKu/8IdJTRgpCulWS0ikZ3\n",
              "ZetaRWmjvJ9B/x28eH7PRMv2QjBNGmKt91EsInfQFinJgMMXUeY3/AnTcP1s4sPXoC4fZ6qiaTcV\n",
              "2cPw74m8LyWcmv15E75JLauvNgC2q5xxKsRhHjEPyN7QlvcBqq0azIexd3um0bBxykmBQxwKEn1s\n",
              "+k436DgTgAAAAFoBnuhqRP8Vir77D5KO5RVgGu9Hw1cAXlJtKO9Ijv7SxbZ8/0C+EKdUNl8rmhI7\n",
              "WVMcb+dQxeEo8KX0T4pMBtZUtTZ1dUve2DS4WB2S2vtHSCMbLWJxXeyo53AAAAjRbW9vdgAAAGxt\n",
              "dmhkAAAAAAAAAAAAAAAAAAAD6AAACPwAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAB\n",
              "AAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAAB/t0cmFrAAAA\n",
              "XHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAACPwAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAQAAAADwAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEA\n",
              "AAj8AAACAAABAAAAAAdzbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAA8AAAAigBVxAAAAAAALWhk\n",
              "bHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAHHm1pbmYAAAAUdm1oZAAA\n",
              "AAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAABt5zdGJsAAAA\n",
              "lnN0c2QAAAAAAAAAAQAAAIZhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAQAA8ABIAAAASAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAMGF2Y0MBZAAV/+EA\n",
              "F2dkABWs2UEB+hAAAAMAEAAAB4DxYtlgAQAGaOvjyyLAAAAAGHN0dHMAAAAAAAAAAQAAAIoAAAEA\n",
              "AAAAFHN0c3MAAAAAAAAAAQAAAAEAAAOoY3R0cwAAAAAAAABzAAAAAQAAAgAAAAABAAAFAAAAAAEA\n",
              "AAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAQAAAAAAgAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAA\n",
              "AgAAAAABAAAEAAAAAAIAAAEAAAAAAQAAAgAAAAABAAADAAAAAAEAAAEAAAAAAQAAAgAAAAABAAAF\n",
              "AAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEA\n",
              "AAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAA\n",
              "AAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAABQAAAAABAAACAAAA\n",
              "AAEAAAAAAAAAAQAAAQAAAAABAAADAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAUAAAAA\n",
              "AQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAwAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAAB\n",
              "AAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAABAAAEAAAAAAIA\n",
              "AAEAAAAAAQAAAwAAAAABAAABAAAAAAIAAAIAAAAAAQAAAwAAAAABAAABAAAAAAQAAAIAAAAAAQAA\n",
              "BQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAACAAAAAAEAAAMAAAAAAQAAAQAAAAADAAAC\n",
              "AAAAAAEAAAQAAAAAAgAAAQAAAAADAAACAAAAAAEAAAQAAAAAAgAAAQAAAAAHAAACAAAAAAEAAAMA\n",
              "AAAAAQAAAQAAAAAEAAACAAAAAAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAABQAA\n",
              "AAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAABAAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAA\n",
              "AAEAAAUAAAAAAQAAAgAAAAABAAAAAAAAAAEAAAEAAAAAAQAAAgAAAAABAAAFAAAAAAEAAAIAAAAA\n",
              "AQAAAAAAAAABAAABAAAAAAIAAAIAAAAAAQAABQAAAAABAAACAAAAAAEAAAAAAAAAAQAAAQAAAAAB\n",
              "AAAFAAAAAAEAAAIAAAAAAQAAAAAAAAABAAABAAAAAAEAAAMAAAAAAQAAAQAAAAAcc3RzYwAAAAAA\n",
              "AAABAAAAAQAAAIoAAAABAAACPHN0c3oAAAAAAAAAAAAAAIoAAB2HAAAAqAAAABgAAAANAAAAQgAA\n",
              "AD4AAAATAAAADQAAAG4AAAAUAAAAOAAAANsAAAAkAAAAHgAAAGEAAABCAAAAGAAAAFAAAADwAAAA\n",
              "NQAAABkAAAAyAAAA0AAAAEMAAAA3AAAAPAAAAJIAAABNAAAAMwAAADkAAAFCAAAAWgAAAC0AAABW\n",
              "AAABIAAAAEUAAAEiAAAASQAAAbQAAABuAAAAOQAAAFYAAADxAAAARAAAAQEAAAA4AAAAzQAAAHEA\n",
              "AAA7AAAASAAAAT0AAABDAAAAyQAAADwAAAB9AAAAQgAAAEIAAABDAAAArAAAADkAAAGOAAAAZAAA\n",
              "AGsAAAN9AAAAigAAAU4AAAFzAAACRQAAAHoAAAGFAAABeQAAAdYAAAHxAAADMAAAAOcAAADLAAAA\n",
              "bgAAAXgAAAHXAAAAtQAAAYEAAALBAAABkgAAAo8AAABvAAAAyAAAAl4AAAGtAAABuAAAAqkAAACG\n",
              "AAAAxAAAA2gAAAGjAAABuQAAAcAAAAH7AAACVQAAAyAAAAKwAAAAiAAAAjsAAAILAAACIQAAAoEA\n",
              "AAOUAAAAQwAAANoAAAAUAAAAgQAAAB4AAAA8AAAAEAAAAHkAAAAkAAAAEAAAABEAAABxAAAALwAA\n",
              "ABUAAAAbAAAAOAAAAHwAAAA2AAAAHQAAAC0AAABmAAAAuAAAAIYAAABZAAAANQAAADMAAAClAAAA\n",
              "WQAAADAAAAAmAAAA4gAAAF4AAAAUc3RjbwAAAAAAAAABAAAAMAAAAGJ1ZHRhAAAAWm1ldGEAAAAA\n",
              "AAAAIWhkbHIAAAAAAAAAAG1kaXJhcHBsAAAAAAAAAAAAAAAALWlsc3QAAAAlqXRvbwAAAB1kYXRh\n",
              "AAAAAQAAAABMYXZmNTcuNzIuMTAx\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "137\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import gym\n",
        "from colabgymrender.recorder import Recorder\n",
        "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT, COMPLEX_MOVEMENT\n",
        "\n",
        "# # env = gym.make(\"MontezumaRevengeDeterministic-v4\")\n",
        "# env = SparseEnv(env)\n",
        "env = gym_super_mario_bros.make('SuperMarioBros-v0')\n",
        "env = JoypadSpace(env, COMPLEX_MOVEMENT) # SIMPLE_MOVEMENT COMPLEX_MOVEMENT\n",
        "env = MarioSparse(env)\n",
        "env = MarioEarlyStop(env)\n",
        "env = Recorder(env, './video')\n",
        "\n",
        "state = env.reset()\n",
        "# device='cpu'\n",
        "# model = ActorCritic(env.observation_space.shape, env.action_space)#.to(device)\n",
        "# model.load_state_dict(shared_model.state_dict())\n",
        "# model.eval()\n",
        "# latent = None\n",
        "# torch.manual_seed(6)\n",
        "x=0\n",
        "\n",
        "# acts=[11, 11, 8, 7, 5, 1, 6, 8, 4, 0, 3, 3, 3, 8, 4, 6, 2, 7, 3, 6, 1, 11, 8, 0, 6, 3, 8, 10, 5, 1, 5, 2, 8, 10, 1, 2, 1, 4, 4, 1, 4, 1, 5, 7, 8, 4, 6, 4, 1, 6, 10, 1, 11, 6, 6, 5, 0, 0, 1, 6, 9, 7, 4, 3, 1, 7, 8, 0, 11, 11, 2, 0, 6, 5, 1, 10, 6, 4, 5, 3, 8, 1, 4, 1, 5, 6, 5, 4, 6, 10, 11, 0, 4, 1, 2, 6, 6, 3, 1, 10, 8, 8, 5, 8, 0, 10, 6, 6, 8, 0, 2, 10, 10, 8, 3, 8, 6, 4, 0, 4, 10, 6, 1, 4, 8, 10, 4, 8, 3, 8, 5, 7, 6, 0, 0, 10, 4, 5, 6, 0, 1, 10, 8, 8, 0, 6, 0, 2, 6, 1, 0, 6, 5, 0, 2, 0, 8, 7, 8, 2, 1, 7, 5, 10, 8, 4, 8, 5, 1, 6, 2, 4, 8, 4, 6, 10, 6, 5, 6, 5, 1, 0, 0, 0, 8, 1, 5, 1, 0, 8, 4, 2, 4, 8, 2, 6, 8, 1, 6, 5, 1, 2, 1, 8, 0, 4, 10, 1, 4, 5, 7, 1, 2, 1, 5, 6, 4, 6, 3, 1, 8, 1, 1, 8, 5, 9, 9, 0, 8, 8, 8, 1, 4, 6, 2, 0, 10, 10, 3, 10, 7, 11, 6, 4, 1, 8, 8, 5, 0, 1, 11, 8, 3, 11, 3, 8, 3, 1, 6, 0, 6, 5, 8, 8, 3, 2, 0, 7, 4, 2, 8, 4, 8, 8, 3, 8, 10, 1, 10, 1, 0, 1, 4, 8, 1, 8, 9, 4, 9, 4, 10, 5, 8, 1, 7, 6, 1, 3, 1, 2, 2, 8, 5, 1, 8, 5, 1, 8, 0, 1, 4, 8, 6, 8, 0, 6, 6, 11, 7, 4, 8, 8, 6, 8, 0, 0, 1, 7, 8, 8, 10, 10, 10, 8, 0, 5, 6, 5, 1, 0, 6, 7, 8, 6, 9, 8, 8, 1, 6, 10, 8, 4, 11, 8, 11, 8, 9, 6, 8, 4, 10, 4, 5, 10, 11, 1, 8, 4, 0, 6, 7, 10, 4, 0, 11, 8, 6, 1, 6, 10, 7, 0, 1, 2, 1, 8, 10, 8, 6, 8, 5, 2, 6, 0, 0, 1, 1, 3, 6, 0, 1, 8, 1, 6, 1, 7, 6, 6, 4, 5, 0, 10, 5, 8, 8, 2, 1, 7, 9, 8, 8, 7, 8, 8, 11, 1, 5, 10, 6, 10, 10, 10, 8, 1, 4, 1, 8, 1, 8, 3, 8, 10, 10, 1, 4, 6, 1, 5, 3, 5, 9, 5, 1, 3, 8, 1, 6, 2, 1, 8, 9, 5, 2, 6, 2, 0, 8, 8, 9, 2, 6, 10, 6, 6, 6, 1, 7, 6, 5, 10, 9, 0, 3, 7, 6, 7, 2, 0, 7, 0, 6, 3, 6, 6, 8, 1, 11, 10, 5, 1, 4, 8, 6, 3, 7, 6, 6, 5, 6, 4, 3, 5, 3, 4, 10, 8, 6, 6, 6, 6, 4, 1, 6, 3, 3, 1, 6, 0, 2, 4, 0, 0, 8, 6, 6, 1, 10, 7, 0, 6, 1, 5, 1, 6, 1, 4, 10, 3, 4, 5, 8, 7, 1, 0, 6, 7, 5, 10, 3, 9, 11, 1, 4, 5, 5, 1, 1, 1, 1, 10, 8, 0, 0, 6, 8, 1, 0, 6, 1, 4, 3, 6, 1, 7, 6, 5, 2, 3, 0, 10, 4, 3, 6, 6, 6, 1, 0, 1, 3, 6, 8, 5, 7, 1, 8, 9, 4, 4, 3, 6, 1, 8, 8, 6, 6, 0, 6, 10, 1, 6, 7, 3, 10, 0, 7, 6, 1, 6, 2, 4, 6, 10, 8, 6, 0, 4, 7, 10, 5, 0, 0, 2, 0, 5, 6, 8, 1, 6, 0, 8, 8, 11, 8, 5, 6, 10, 4, 8, 7, 2, 6, 8, 5, 0, 4, 2, 6, 10, 1, 8, 0, 4, 10, 7, 0, 3, 6, 1, 7, 8, 11, 1, 2, 3, 4, 6, 8, 0, 5, 0, 6, 8, 2, 6, 8, 6, 8, 6, 1, 3, 8, 9, 1, 4, 4, 6, 6, 1, 5, 4, 5, 8, 5, 6, 8, 4, 1, 0, 0, 5, 0, 1, 0, 3, 6, 2, 3, 8, 6, 8, 7, 4, 9, 0, 10, 4, 8, 9, 0, 8, 8, 6, 6, 1, 3, 5, 10, 0, 0, 3, 3, 3, 6, 10, 4, 8, 1, 1, 10, 8, 3, 6, 1, 1, 1, 1, 6, 1, 3, 0, 6, 8, 3, 3, 9, 6, 11, 8, 6, 4, 6, 1, 6, 0, 5, 3, 7, 5, 3, 2, 0, 4, 8, 6, 6, 0, 6, 2, 10, 1, 8, 0, 4, 4, 7, 8, 0, 6, 2, 1, 2, 6, 0, 8]\n",
        "# acts=[11, 11, 8, 7, 5, 1, 6, 8, 4, 0, 3, 3, 3, 8, 4, 6, 2, 7, 3, 6, 1, 11, 8, 0, 6, 3, 8, 10, 5, 1, 5, 2, 8, 10, 1, 2, 1, 4, 4, 1, 4, 1, 5, 7, 8, 4, 6, 4, 1, 6, 10, 1, 11, 6, 6, 5, 0, 0, 1, 6, 9, 7, 4, 3, 1, 7, 8, 0, 11, 11, 2, 0, 6, 5, 1, 10, 6, 4, 5, 3, 8, 1, 4, 1, 5, 6, 5, 4, 6, 10, 11, 0, 4, 1, 2, 6, 6, 3, 1, 10, 8, 8, 5, 8, 0, 10, 6, 6, 8, 0, 2, 10, 10, 8, 3, 8, 6, 4, 0, 4, 10, 6, 1, 4, 8, 10, 4, 8, 3, 8, 5, 7, 6, 0, 0, 10, 4, 5, 6, 0, 1, 10, 8, 8, 0, 6, 0, 2, 6, 1, 0, 6, 5, 0, 2, 0, 8, 7, 8, 2, 1, 7, 5, 10, 8, 4, 8, 5, 1, 6, 2, 4, 8, 4, 6, 10, 6, 5, 6, 5, 1, 0, 0, 0, 8, 1, 5, 1, 0, 8, 4, 2, 4, 8, 2, 6, 8, 1, 6, 5, 1, 2, 1, 8, 0, 4, 10, 1, 4, 5, 7, 1, 2, 1, 5, 6, 4, 6, 3, 1, 8, 1, 1, 8, 5, 9, 9, 0, 8, 8, 8, 1, 4, 6, 2, 0, 10, 10, 3, 10, 7, 11, 6, 4, 1, 8, 8, 5, 0, 1, 11, 8, 3, 11, 3, 8, 3, 1, 6, 0, 6, 5, 8, 8, 3, 2, 0, 7, 4, 2, 8, 4, 8, 8, 3, 8, 10, 1, 10, 1, 0, 1, 4, 8, 1, 8, 9, 4, 9, 4, 10, 5, 8, 1, 7, 6, 1, 3, 1, 2, 2, 8, 5, 1, 8, 5, 1, 8, 0, 1, 4, 8, 6, 8, 0, 6, 6, 11, 7, 4, 8, 8, 6, 8, 0, 0, 1, 7, 8, 8, 10, 10, 10, 8, 0, 5, 6, 5, 1, 0, 6, 7, 8, 6, 9, 8, 8, 1, 6, 10, 8, 4, 11, 8, 11, 8, 9, 6, 8, 4, 10, 4, 5, 10, 11, 1, 8, 4, 0, 6, 7, 10, 4, 0, 11, 8, 6, 1, 6, 10, 7, 0, 1, 2, 1, 8, 10, 8, 6, 8, 5, 2, 6, 0, 0, 1, 1, 3, 6, 0, 1, 8, 1, 6, 1, 7, 6, 6, 4, 5, 0, 10, 5, 8, 8, 2, 1, 7, 9, 8, 8, 7, 8, 8, 11, 1, 5, 10, 6, 10, 10, 10, 8, 1, 4, 1, 8, 1, 8, 3, 8, 10, 10, 1, 4, 6, 1, 5, 3, 5, 9, 5, 1, 3, 8, 1, 6, 2, 1, 8, 9, 5, 2, 6, 2, 0, 8, 8, 9, 2, 6, 10, 6, 6, 6, 1, 7, 6, 5, 10, 9, 0, 3, 7, 6, 7, 2, 0, 7, 0, 6, 3, 6, 6, 8, 1, 11, 10, 5, 1, 4, 8, 6, 3, 7, 6, 6, 5, 6, 4, 3, 5, 3, 4, 10, 8, 6, 6, 6, 6, 4, 1, 6, 3, 3, 1, 6, 0, 2, 4, 0, 0, 8, 6, 6, 1, 10, 7, 0, 6, 1, 5, 1, 6, 1, 4, 10, 3, 4, 5, 8, 7, 1, 0, 6, 7, 5, 10, 3, 9, 11, 1, 4, 5, 5, 1, 1, 1, 1, 10, 8, 0, 0, 6, 8, 1, 0, 6, 1, 4, 3, 6, 1, 7, 6, 5, 2, 3, 0, 10, 4, 3, 6, 6, 6, 1, 0, 1, 3, 6, 8, 5, 7, 1, 8, 9, 4, 4, 3, 6, 1, 8, 8, 6, 6, 0, 6, 10, 1, 6, 7, 3, 10, 0, 7, 6, 1, 6, 2, 4, 6, 10, 8, 6, 0, 4, 7, 10, 5, 0, 0, 2, 0, 5, 6, 8, 1, 6, 0, 8, 8, 11, 8, 5, 6, 10, 4, 8, 7, 2, 6, 8, 5, 0, 4, 2, 6, 10, 1, 8, 0, 4, 10, 7, 0, 3, 6, 1, 7, 8, 11, 1, 2, 3, 4, 6, 8, 0, 5, 0, 6, 8, 2, 6, 8, 6, 8, 6, 1, 3, 8, 9, 1, 4, 4, 6, 6, 1, 5, 4, 5, 8, 5, 6, 8, 4, 1, 0, 0, 5, 0, 1, 0, 3, 6, 2, 3, 8, 6, 8, 7, 4, 9, 0, 10, 4, 8, 9, 0, 8, 8, 6, 6, 1, 3, 5, 10, 0, 0, 3, 3, 3, 6, 10, 4, 8, 1, 1, 10, 8, 3, 6, 1, 1, 1, 1, 6, 1, 3, 0, 6, 8, 3, 3, 9, 6, 11, 8, 6, 4, 6, 1, 6, 0, 5, 3, 7, 5, 3, 2, 0, 4, 8, 6, 6, 0, 6, 2, 10, 1, 8, 0, 4, 4, 7, 8, 0, 6, 2, 1, 2, 6, 0, 8]\n",
        "acts=[8, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 7, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
        "\n",
        "\n",
        "# acts=[1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1]\n",
        "\n",
        "\n",
        "while True:\n",
        "    # state = torch.from_numpy(state.copy()).type(torch.float)#.to(device)\n",
        "    # value, logit, latent = model((state, latent), icm = False)\n",
        "    # prob = F.softmax(logit, dim=1) #from train\n",
        "    # action = prob.multinomial(1).data\n",
        "    # state, reward, done, _ = env.step(action.item())\n",
        "    try:\n",
        "        action=int(acts[x])\n",
        "    except:\n",
        "        action = 10\n",
        "    # # print(\"action\",action)\n",
        "    # # action = env.action_space.sample()\n",
        "    state, reward, done, info = env.step(action)\n",
        "    x+=1\n",
        "    if done: break\n",
        "env.play()\n",
        "print(x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_allocated(device)\n",
        "torch.cuda.memory_stats(device)\n"
      ],
      "metadata": {
        "id": "On5etZ_H-uLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del shared_model\n"
      ],
      "metadata": {
        "id": "IBF9frzpqrRX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "-qQjuJIepAvA",
        "FidkEuaA8HvK",
        "SPCCve3p2bL-",
        "sbpPda4YEv13",
        "GCHpcDteZdLS",
        "fj3tv7XHZmD9",
        "wFrRKvOwhYM_",
        "KlV2MvSK-aL_"
      ],
      "name": "curiousity_perceiverio.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}